{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5-9LB_uJP3TW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No variables match your requested type.\n"
     ]
    }
   ],
   "source": [
    "%who DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data from 2015\n",
    "# df= pd.read_pickle(\"final_data_till_1969_without_encoding.pkl\")\n",
    "df= pd.read_pickle(\"final_data_from_2015_till_1969_with_encoding.pkl\")\n",
    "\n",
    "#we create a dicitonary for id and its encodings\n",
    "id_dict= pd.read_csv(\"ids_dict.csv\")\n",
    "id_dict= dict(zip(id_dict['id'], id_dict['uid']))\n",
    "\n",
    "sales= pd.read_csv('sales_train_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uxjrfjg-RuR6"
   },
   "outputs": [],
   "source": [
    "'''here we are importing sales dataset and we are creating few column orders '''\n",
    "\n",
    "d_cols= [col for col in sales.columns if 'd_' in col] \n",
    "non_d_cols= [col for col in sales.columns if 'd_' not in col] \n",
    "\n",
    "last_28_d_cols= []\n",
    "for i in range(1942, 1970):\n",
    "    last_28_d_cols.append(\"d_\"+ str(i))\n",
    "    \n",
    "d_cols_1969= d_cols + last_28_d_cols\n",
    "\n",
    "f_cols= [ (\"F\"+str(i+1)) for i in range(28)]\n",
    "d_with_f_cols= d_cols+ f_cols\n",
    "\n",
    "col_order= d_cols + ['level', 'weights']\n",
    "col_order_with_f_cols= d_with_f_cols+['level', 'weights']\n",
    "col_order_with_f_cols_without_level= d_with_f_cols+['weights']\n",
    "\n",
    "uid= sales.id.unique() #getting all unique id's from test data\n",
    "\n",
    "# in kaggle submission file we have to predict last 56 days data from day 1885 for each item\n",
    "# getting validation ids for each item sales from day 1885 - day 1913\n",
    "validation_uid= [\"_\".join(ids.split(\"_\")[:-1] + [\"validation\"]) for ids in uid] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pkRJeZOaR9wU"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dedd410e9f48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m'''splitting to train and test dataset'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvalid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'd'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m1913\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'd'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sales'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'revenue'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'd'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1913\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'd'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m1941\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'd'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sales'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'revenue'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'd'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1941\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "'''splitting to train and test dataset'''\n",
    "\n",
    "valid = df[df['d']<=1913][['id','d','sales', 'revenue']]\n",
    "test = df[(df['d']>1913) & (df['d']<=1941)][['id','d','sales', 'revenue']]\n",
    "evaluation= df[df['d']>1941]\n",
    "\n",
    "valid['id']= valid['id'].apply(lambda x: id_dict[x])\n",
    "test['id']= test['id'].apply(lambda x: id_dict[x])\n",
    "\n",
    "valid_df= valid.groupby('id')\n",
    "test_df= test.groupby('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "5MvCO6IuVhPS",
    "outputId": "017aae28-de87-4901-f231-92b8e666c282"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>wday</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_28</th>\n",
       "      <th>rolling_mean1</th>\n",
       "      <th>rolling_mean2</th>\n",
       "      <th>rolling_mean3</th>\n",
       "      <th>rolling_mean7</th>\n",
       "      <th>rolling_mean14</th>\n",
       "      <th>rolling_mean21</th>\n",
       "      <th>rolling_mean28</th>\n",
       "      <th>rolling_mean60</th>\n",
       "      <th>rolling_mean90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>14370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1437</td>\n",
       "      <td>1434</td>\n",
       "      <td>0</td>\n",
       "      <td>11448</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333252</td>\n",
       "      <td>1.286133</td>\n",
       "      <td>0.856934</td>\n",
       "      <td>0.856934</td>\n",
       "      <td>0.785645</td>\n",
       "      <td>0.716797</td>\n",
       "      <td>0.666504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>14370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1437</td>\n",
       "      <td>1435</td>\n",
       "      <td>0</td>\n",
       "      <td>11448</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.142578</td>\n",
       "      <td>0.856934</td>\n",
       "      <td>0.856934</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.700195</td>\n",
       "      <td>0.644531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>14370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1437</td>\n",
       "      <td>1436</td>\n",
       "      <td>0</td>\n",
       "      <td>11449</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714355</td>\n",
       "      <td>0.761719</td>\n",
       "      <td>0.714355</td>\n",
       "      <td>0.700195</td>\n",
       "      <td>0.644531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>14370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1437</td>\n",
       "      <td>1437</td>\n",
       "      <td>0</td>\n",
       "      <td>11449</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285645</td>\n",
       "      <td>0.714355</td>\n",
       "      <td>0.571289</td>\n",
       "      <td>0.714355</td>\n",
       "      <td>0.700195</td>\n",
       "      <td>0.633301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>14370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1437</td>\n",
       "      <td>1438</td>\n",
       "      <td>0</td>\n",
       "      <td>11449</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142822</td>\n",
       "      <td>0.714355</td>\n",
       "      <td>0.571289</td>\n",
       "      <td>0.678711</td>\n",
       "      <td>0.700195</td>\n",
       "      <td>0.600098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  state_id  store_id  cat_id  dept_id  item_id     d  sales  \\\n",
       "1433  14370         0         0       1        3     1437  1434      0   \n",
       "1434  14370         0         0       1        3     1437  1435      0   \n",
       "1435  14370         0         0       1        3     1437  1436      0   \n",
       "1436  14370         0         0       1        3     1437  1437      0   \n",
       "1437  14370         0         0       1        3     1437  1438      0   \n",
       "\n",
       "      wm_yr_wk  wday  ...  lag_28  rolling_mean1  rolling_mean2  \\\n",
       "1433     11448     6  ...     1.0            0.0            0.0   \n",
       "1434     11448     7  ...     1.0            0.0            0.0   \n",
       "1435     11449     1  ...     1.0            0.0            0.0   \n",
       "1436     11449     2  ...     0.0            0.0            0.0   \n",
       "1437     11449     3  ...     1.0            0.0            0.0   \n",
       "\n",
       "      rolling_mean3  rolling_mean7  rolling_mean14  rolling_mean21  \\\n",
       "1433       0.333252       1.286133        0.856934        0.856934   \n",
       "1434       0.000000       1.142578        0.856934        0.856934   \n",
       "1435       0.000000       1.000000        0.714355        0.761719   \n",
       "1436       0.000000       0.285645        0.714355        0.571289   \n",
       "1437       0.000000       0.142822        0.714355        0.571289   \n",
       "\n",
       "      rolling_mean28  rolling_mean60  rolling_mean90  \n",
       "1433        0.785645        0.716797        0.666504  \n",
       "1434        0.750000        0.700195        0.644531  \n",
       "1435        0.714355        0.700195        0.644531  \n",
       "1436        0.714355        0.700195        0.633301  \n",
       "1437        0.678711        0.700195        0.600098  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sx-81LvdSMm0"
   },
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pY2v6FkfSe7O"
   },
   "outputs": [],
   "source": [
    "## correct one and currently using this finally -------------------------------------------modifications 4 finally correct\n",
    "\n",
    "def get_level_12_weights(isvalidation):\n",
    "    '''calculating last 28 day revenue and weights'''\n",
    "    #if isvalidation = True, validation data will be from day 1857 -1885\n",
    "    #if isvalidation= False, validation data will be from day 1885 -1913\n",
    "    # print(\"calculating level 12 weights...\")\n",
    "    last_28_day_revenue= []\n",
    "    weights= [] \n",
    "    \n",
    "    if isvalidation:\n",
    "        for i in uid: #uid= unique ids\n",
    "            last_28_day_revenue.append(valid_df.get_group(i)['revenue'].dropna()[-56:-28].values.sum())\n",
    "\n",
    "        for i in last_28_day_revenue:\n",
    "            weights.append(i/ sum(last_28_day_revenue))\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    else:\n",
    "        for i in uid: #uid= unique ids\n",
    "            last_28_day_revenue.append(valid_df.get_group(i)['revenue'].dropna()[-28:].values.sum())\n",
    "\n",
    "        for i in last_28_day_revenue:\n",
    "            weights.append(i/ sum(last_28_day_revenue))\n",
    "                        \n",
    "        return weights\n",
    "    \n",
    "    \n",
    "def calculate_weights(sales, prediction, aggregation_level, isvalidation):\n",
    "    '''this function will calculate weights acc to level 12'''\n",
    "    \n",
    "#     temp part\n",
    "    if isvalidation:\n",
    "        weights= valid_weights\n",
    "    else:\n",
    "        weights= test_weights\n",
    "   \n",
    "#     https://www.youtube.com/watch?v=7FwITPrBvLI&list=PLu4R9FIFLvWmRgHTH2Br-Di6koS_D7oL7&index=3\n",
    "#     weights= get_level_12_weights(isvalidation) #calling function, calculating weights\n",
    "    sales['weights']= weights #adding weights\n",
    "    sales= sales.merge(prediction, on= 'id', how='left') #sales with fcols(i.e prediction data)\n",
    "    sales2= sales[col_order_with_f_cols_without_level] #creating another dataframe bcoz this dataframe values will be used ahead\n",
    "\n",
    "    # print('calculating weights aggregate level...')\n",
    "\n",
    "    #creating new dataframe to store aggregate data weights and revenue\n",
    "    aggregation_data= pd.DataFrame(sales2.sum()).T\n",
    "    aggregation_data['level']=1\n",
    "    aggregation_data['weights']= 1/12\n",
    "    ag_df= aggregation_data[col_order_with_f_cols]\n",
    "\n",
    "    #iterating over all the agg levels\n",
    "    for i in aggregation_level.keys(): #getting weights for all other levels\n",
    "        temp= sales.groupby(aggregation_level[i]).sum().reset_index(drop=True)\n",
    "        temp['level']= i\n",
    "        temp['weights'] /= 12\n",
    "        temp= temp[col_order_with_f_cols]\n",
    "        aggregation_data= pd.concat([aggregation_data,temp])\n",
    "\n",
    "    sale= sales2.copy()\n",
    "    sale['weights'] /= 12\n",
    "        \n",
    "    return sale, aggregation_data\n",
    "\n",
    "\n",
    "\n",
    "def rmsse(actual, predicted, historical):\n",
    "    '''this function will calculate the rmsse values'''\n",
    "    \n",
    "    actual= np.array(actual)\n",
    "    predicted= np.array(predicted)\n",
    "    historical= np.array(historical)\n",
    "    h= len(actual[0])\n",
    "    n= len(historical[0])\n",
    "\n",
    "    numerator= ((actual- predicted)**2).sum(axis=1)\n",
    "    denominator= (1/n)*((historical[:, 1:] - historical[:, :-1]) ** 2).sum(axis=1)\n",
    "    rmsses= np.sqrt((numerator/denominator) * (1/ h))\n",
    "    return rmsses\n",
    "\n",
    "\n",
    "    \n",
    "def calculate_wrmsse(sale, aggregation_data, isvalidation):\n",
    "    '''this function will calculate wrmsse'''\n",
    "    \n",
    "    if isvalidation:\n",
    "        historical_cols= d_cols[:-56]\n",
    "        actual_cols= d_cols[-56:-28]\n",
    "\n",
    "        predicted_cols= f_cols\n",
    "        \n",
    "    else:\n",
    "        historical_cols= d_cols[:-28]\n",
    "        actual_cols= d_cols[-28:]\n",
    "        predicted_cols= f_cols        \n",
    "\n",
    "    # print('calculating rmsse...')\n",
    "\n",
    "    \n",
    "    rmsse_sale= rmsse(sale[actual_cols], sale[predicted_cols], sale[historical_cols])\n",
    "    rmsse_agg= rmsse(aggregation_data[actual_cols], aggregation_data[predicted_cols], aggregation_data[historical_cols])\n",
    "    \n",
    "    # print('calculating wrmsse...')\n",
    "\n",
    "    wrmsse_sale= rmsse_sale * sale['weights']\n",
    "    wrmsse_agg= rmsse_agg * aggregation_data['weights']\n",
    "\n",
    "    wrmsse= wrmsse_agg.sum() + wrmsse_sale.sum()\n",
    "    return wrmsse\n",
    "\n",
    "\n",
    "\n",
    "def wrmsse(sales, prediction, isvalidation):\n",
    "    '''this function will call all other functions as requires so as to make work easier'''\n",
    "    \n",
    "    #all the aggregation levels present in the data\n",
    "    aggregation_level = {2: [\"state_id\"], 3: [\"store_id\"], 4: [\"cat_id\"], 5: [\"dept_id\"], 6: [\"state_id\", \"cat_id\"], \n",
    "                         7: [\"state_id\", \"dept_id\"], 8: [\"store_id\", \"cat_id\"], \n",
    "                         9: [\"store_id\", \"dept_id\"], 10: [\"item_id\"], 11: [\"item_id\", \"state_id\"]}\n",
    "    \n",
    "    \n",
    "    weights= 0\n",
    "\n",
    "    sale, aggregation_data= calculate_weights(sales, prediction, aggregation_level, isvalidation)\n",
    "    wrmsses=calculate_wrmsse(sale, aggregation_data, isvalidation)\n",
    "    \n",
    "    return wrmsses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Yd5go_9OSRIr"
   },
   "outputs": [],
   "source": [
    "valid_weights= get_level_12_weights(True)\n",
    "test_weights= get_level_12_weights(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlYH331SSYzn"
   },
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate= [0.01, 0.1, 1]\n",
    "n_estimators= [900,1500,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3862\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.441474\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.218750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3700\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.139306\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4253\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 2.050931\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.213510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3321\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 0.793258\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.246821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3783\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.035966\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.410128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4086\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.244674\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.361232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3962\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.213714\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.258309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3559\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.162037\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.323145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3917\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.412089\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.327446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3881\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.108849\n",
      "for validation:\n",
      "calculating level 12 weights...\n",
      "calculating weights aggregate level...\n",
      "calculating rmsse...\n",
      "calculating wrmsse...\n",
      "n_estimators=  900 learning_rate=  0.01 WRMSSE=  0.0028342363169274877 \n",
      "\n",
      "for validation:\n",
      "calculating level 12 weights...\n",
      "calculating weights aggregate level...\n",
      "calculating rmsse...\n",
      "calculating wrmsse...\n",
      "n_estimators=  900 learning_rate=  0.01 WRMSSE=  0.8827075643907925 \n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.165257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3862\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.441474\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.225036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3700\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.139306\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.169120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4253\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 2.050931\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.321319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3321\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 0.793258\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.354865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3783\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.035966\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.208914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4086\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.244674\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.344108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3962\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.213714\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.108360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3559\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.162037\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.256262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3917\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.412089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.338562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3881\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.108849\n",
      "for validation:\n",
      "calculating level 12 weights...\n",
      "calculating weights aggregate level...\n",
      "calculating rmsse...\n",
      "calculating wrmsse...\n",
      "n_estimators=  900 learning_rate=  0.1 WRMSSE=  0.0026710105815421197 \n",
      "\n",
      "for validation:\n",
      "calculating level 12 weights...\n",
      "calculating weights aggregate level...\n",
      "calculating rmsse...\n",
      "calculating wrmsse...\n",
      "n_estimators=  900 learning_rate=  0.1 WRMSSE=  0.8829116464477424 \n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.243587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3862\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.441474\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.337545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3700\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.139306\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.217688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4253\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 2.050931\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.381401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3321\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 0.793258\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.313826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3783\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.035966\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.332922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4086\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.244674\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.363879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3962\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.213714\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.172255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3559\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.162037\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.340190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3917\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.412089\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.332197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3881\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.108849\n",
      "for validation:\n",
      "calculating level 12 weights...\n",
      "calculating weights aggregate level...\n",
      "calculating rmsse...\n",
      "calculating wrmsse...\n",
      "n_estimators=  900 learning_rate=  1 WRMSSE=  0.004310924821640772 \n",
      "\n",
      "for validation:\n",
      "calculating level 12 weights...\n",
      "calculating weights aggregate level...\n",
      "calculating rmsse...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating wrmsse...\n",
      "n_estimators=  900 learning_rate=  1 WRMSSE=  0.8829742740632018 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████                                                    | 1/3 [1:48:17<3:36:34, 6497.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.164269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3862\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.441474\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.398082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3700\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.139306\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.174129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4253\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 2.050931\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.334213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3321\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 0.793258\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.248369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3783\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.035966\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.668686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4086\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.244674\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.334288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3962\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.213714\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.202798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3559\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.162037\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.332714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3917\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.412089\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.335466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3881\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.108849\n",
      "for validation:\n",
      "calculating level 12 weights...\n",
      "calculating weights aggregate level...\n",
      "calculating rmsse...\n",
      "calculating wrmsse...\n",
      "n_estimators=  1500 learning_rate=  0.01 WRMSSE=  0.0023808920104207345 \n",
      "\n",
      "for validation:\n",
      "calculating level 12 weights...\n",
      "calculating weights aggregate level...\n",
      "calculating rmsse...\n",
      "calculating wrmsse...\n",
      "n_estimators=  1500 learning_rate=  0.01 WRMSSE=  0.882844911243343 \n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.195192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3862\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.441474\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.243590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3700\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.139306\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.167295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4253\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 2.050931\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.367513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3321\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 0.793258\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.314553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3783\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.035966\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.366398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4086\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.244674\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.348994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3962\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.213714\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.207640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3559\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.162037\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.330008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3917\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.412089\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.373389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3881\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.108849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for validation:\n",
      "calculating level 12 weights...\n",
      "calculating weights aggregate level...\n",
      "calculating rmsse...\n",
      "calculating wrmsse...\n",
      "n_estimators=  1500 learning_rate=  0.1 WRMSSE=  0.00272168651474456 \n",
      "\n",
      "for validation:\n",
      "calculating level 12 weights...\n",
      "calculating weights aggregate level...\n",
      "calculating rmsse...\n",
      "calculating wrmsse...\n",
      "n_estimators=  1500 learning_rate=  0.1 WRMSSE=  0.8828716753671811 \n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.184554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3862\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.441474\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.210438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3700\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.139306\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.182942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4253\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 2.050931\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.336921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3321\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 0.793258\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.320455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3783\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.035966\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.319875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4086\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.244674\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.328701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3962\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.213714\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.216017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3559\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.162037\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.236044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3917\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.412089\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.389172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3881\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.108849\n",
      "for validation:\n",
      "calculating level 12 weights...\n",
      "calculating weights aggregate level...\n",
      "calculating rmsse...\n",
      "calculating wrmsse...\n",
      "n_estimators=  1500 learning_rate=  1 WRMSSE=  0.004311782088110123 \n",
      "\n",
      "for validation:\n",
      "calculating level 12 weights...\n",
      "calculating weights aggregate level...\n",
      "calculating rmsse...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|████████████████████████████████████████████████████                          | 2/3 [4:33:59<2:05:30, 7530.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating wrmsse...\n",
      "n_estimators=  1500 learning_rate=  1 WRMSSE=  0.8829684490100296 \n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.167907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3862\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.441474\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.324508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3700\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.139306\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.198226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4253\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 2.050931\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.312833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3321\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 0.793258\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.307291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3783\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.035966\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.322219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4086\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.244674\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.313759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3962\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.213714\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.171529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3559\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.162037\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.352081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3917\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.412089\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.319233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3881\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.108849\n",
      "for validation:\n",
      "calculating level 12 weights...\n",
      "calculating weights aggregate level...\n",
      "calculating rmsse...\n",
      "calculating wrmsse...\n",
      "n_estimators=  100 learning_rate=  0.01 WRMSSE=  0.9733475643080318 \n",
      "\n",
      "for validation:\n",
      "calculating level 12 weights...\n",
      "calculating weights aggregate level...\n",
      "calculating rmsse...\n",
      "calculating wrmsse...\n",
      "n_estimators=  100 learning_rate=  0.01 WRMSSE=  1.1782596150271745 \n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.171561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3862\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.441474\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.328435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3700\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.139306\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.165631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4253\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 2.050931\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.327047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3321\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 0.793258\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.319276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3783\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.035966\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.330543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4086\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.244674\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.348981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3962\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.213714\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.201204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3559\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.162037\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.427415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3917\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.412089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.323589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3881\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.108849\n",
      "for validation:\n",
      "calculating level 12 weights...\n",
      "calculating weights aggregate level...\n",
      "calculating rmsse...\n",
      "calculating wrmsse...\n",
      "n_estimators=  100 learning_rate=  0.1 WRMSSE=  0.0024409277044324215 \n",
      "\n",
      "for validation:\n",
      "calculating level 12 weights...\n",
      "calculating weights aggregate level...\n",
      "calculating rmsse...\n",
      "calculating wrmsse...\n",
      "n_estimators=  100 learning_rate=  0.1 WRMSSE=  0.8829129573659653 \n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.674060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3862\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.441474\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.325954 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3700\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.139306\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.166342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4253\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 2.050931\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.319491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3321\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 0.793258\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.338180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3783\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.035966\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.335390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4086\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.244674\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.342069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3962\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.213714\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.237843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3559\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.162037\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.343491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3917\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.412089\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.379804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3881\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378148, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.108849\n",
      "for validation:\n",
      "calculating level 12 weights...\n",
      "calculating weights aggregate level...\n",
      "calculating rmsse...\n",
      "calculating wrmsse...\n",
      "n_estimators=  100 learning_rate=  1 WRMSSE=  0.0040200780602895935 \n",
      "\n",
      "for validation:\n",
      "calculating level 12 weights...\n",
      "calculating weights aggregate level...\n",
      "calculating rmsse...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 3/3 [5:08:38<00:00, 6172.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating wrmsse...\n",
      "n_estimators=  100 learning_rate=  1 WRMSSE=  0.8830959081473213 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unique_store= list(df_df.store_id.unique())\n",
    "valid_prediction= []\n",
    "test_prediction= []\n",
    "\n",
    "for estimator in tqdm(n_estimators):\n",
    "    for eta in learning_rate:\n",
    "        params = {\n",
    "            'objective': 'regression',\n",
    "            'num_iterations' : estimator,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'metric': 'rmse',\n",
    "            'n_jobs': -1,\n",
    "            'learning_rate': eta\n",
    "                      }\n",
    "\n",
    "        valid_pred= pd.DataFrame(columns= ['id']+ f_cols)\n",
    "        test_pred= pd.DataFrame(columns= ['id']+ f_cols)\n",
    "\n",
    "        for store in unique_store:\n",
    "            valid_temp= pd.DataFrame(columns= ['id']+ f_cols)\n",
    "\n",
    "            test_temp= pd.DataFrame(columns= ['id']+ f_cols)\n",
    "\n",
    "            ############################################\n",
    "            data= df_df[df_df['store_id']== store]\n",
    "\n",
    "            train_data= data[data['d'] <= 1885]\n",
    "            valid_data= data[(data['d'] >1885) & (data['d']<1914)]\n",
    "            test_data= data[data['d']>= 1914]\n",
    "\n",
    "            X_train, y_train= train_data.drop('sales', axis= 1), train_data['sales']\n",
    "            X_valid, y_valid= valid_data.drop('sales', axis= 1), valid_data['sales']\n",
    "            X_test, y_test= test_data.drop('sales', axis= 1), test_data['sales']\n",
    "\n",
    "            train_set = lgb.Dataset(X_train, label= y_train)\n",
    "            val_set = lgb.Dataset(X_valid, label= y_valid)\n",
    "            ############################################\n",
    "\n",
    "            model = lgb.train(params, train_set)#, valid_sets=[val_set])#, verbose_eval=20)\n",
    "            ###########################################################\n",
    "            valid_temp = model.predict(X_valid)\n",
    "            valid_temp= valid_temp.reshape(-1,28)\n",
    "\n",
    "\n",
    "            prediction= pd.DataFrame(valid_temp, columns= f_cols)\n",
    "            prediction['id']= valid_data.id.unique()\n",
    "            cols= ['id'] + f_cols\n",
    "            prediction= prediction[cols]\n",
    "\n",
    "            valid_pred= pd.concat([valid_pred, prediction])\n",
    "            ###############################################\n",
    "            test_temp = model.predict(X_test)\n",
    "            test_temp = test_temp.reshape(-1,28)\n",
    "\n",
    "            prediction= pd.DataFrame(test_temp, columns= f_cols)\n",
    "            prediction['id']= test_data.id.unique()\n",
    "            cols= ['id'] + f_cols\n",
    "            prediction= prediction[cols]\n",
    "\n",
    "            test_pred= pd.concat([test_pred, prediction])\n",
    "            ###########################################################\n",
    "\n",
    "        valid_pred.reset_index(drop= True, inplace= True)\n",
    "        test_pred.reset_index(drop= True, inplace= True)\n",
    "\n",
    "        for i in valid_pred.columns[1:]:\n",
    "            valid_pred[i]= valid_pred[i].apply(lambda x: int(np.round(x,0)))\n",
    "\n",
    "        for i in test_pred.columns[1:]:\n",
    "            test_pred[i]= test_pred[i].apply(lambda x: int(np.round(x,0)))\n",
    "\n",
    "        print(\"for validation:\")\n",
    "        wrmss= wrmsse(sales, valid_pred, aggregation_level)\n",
    "        print(\"n_estimators= \", estimator, 'learning_rate= ', eta, 'WRMSSE= ',wrmss, '\\n')    \n",
    "\n",
    "        print(\"for validation:\")\n",
    "        wrmss= wrmsse(sales, test_pred, aggregation_level)\n",
    "        print(\"n_estimators= \", estimator, 'learning_rate= ', eta, 'WRMSSE= ',wrmss, '\\n')                        \n",
    "\n",
    "        valid_prediction.append(valid_pred)\n",
    "        test_prediction.append(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating level 12 weights...\n",
      "calculating weights aggregate level...\n",
      "calculating rmsse...\n",
      "calculating wrmsse...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0040200780602895935"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrmss= wrmsse(sales, valid_pred, True)\n",
    "wrmss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28e2e486d08>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting feature importances\n",
    "lgb.plot_importance(model, height=1.8, figsize=(15,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating level 12 weights...\n",
      "calculating weights aggregate level...\n",
      "calculating rmsse...\n",
      "calculating wrmsse...\n"
     ]
    }
   ],
   "source": [
    "wrmss= wrmsse(sales, test_pred, aggregation_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After Removing few features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fJFFL2zEYqC3"
   },
   "outputs": [],
   "source": [
    "df_df= df.drop(['wm_yr_wk', 'lag_1', 'lag_2', 'lag_3', 'lag_14', 'lag_21', 'rolling_mean1', 'rolling_mean2',\n",
    "       'rolling_mean3', 'rolling_mean14', 'rolling_mean21'], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective= ['poisson', 'regression']\n",
    "learning_rate= [0.005, 0.075, 0.01, 0.1]\n",
    "num_iterations= [2000, 1400, 1200, 1000, 800, 600, 400]\n",
    "max_depth= [-1, 11, 9, 7, 5, 3]\n",
    "num_leaves= [100, 150, 200, 250, 300, 400, 500, 600, 700]\n",
    "min_data_in_leaf= [100, 200, 300, 500, 1000, 2000]\n",
    "max_bins= [100, 150, 200, 250, 300, 400, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_dict= dict(zip(df_df.store_id.unique(), sales.store_id.unique()))\n",
    "uid_df= pd.DataFrame(uid, columns=['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of times remaining: 19\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.075, num_iterations: 1400, max_depth: 3, num_leaves: 300, min_data_in_leaf: 1000, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.953529\tvalid_1's rmse: 0.92725\n",
      "[400]\ttraining's rmse: 0.661466\tvalid_1's rmse: 0.640295\n",
      "[600]\ttraining's rmse: 0.528496\tvalid_1's rmse: 0.524064\n",
      "[800]\ttraining's rmse: 0.457798\tvalid_1's rmse: 0.458067\n",
      "[1000]\ttraining's rmse: 0.417838\tvalid_1's rmse: 0.419374\n",
      "[1200]\ttraining's rmse: 0.395994\tvalid_1's rmse: 0.401168\n",
      "Early stopping, best iteration is:\n",
      "[1230]\ttraining's rmse: 0.393541\tvalid_1's rmse: 0.397429\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.075, num_iterations: 1000, max_depth: 7, num_leaves: 500, min_data_in_leaf: 200, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.354261\tvalid_1's rmse: 0.406675\n",
      "[400]\ttraining's rmse: 0.305646\tvalid_1's rmse: 0.382838\n",
      "Early stopping, best iteration is:\n",
      "[428]\ttraining's rmse: 0.30144\tvalid_1's rmse: 0.379471\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.01, num_iterations: 2000, max_depth: 9, num_leaves: 250, min_data_in_leaf: 1000, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.32225\tvalid_1's rmse: 1.92831\n",
      "[400]\ttraining's rmse: 1.26063\tvalid_1's rmse: 0.914529\n",
      "[600]\ttraining's rmse: 0.941866\tvalid_1's rmse: 0.691265\n",
      "[800]\ttraining's rmse: 0.825601\tvalid_1's rmse: 0.654622\n",
      "[1000]\ttraining's rmse: 0.771074\tvalid_1's rmse: 0.643669\n",
      "[1200]\ttraining's rmse: 0.737758\tvalid_1's rmse: 0.637966\n",
      "[1400]\ttraining's rmse: 0.714765\tvalid_1's rmse: 0.632208\n",
      "[1600]\ttraining's rmse: 0.696993\tvalid_1's rmse: 0.627801\n",
      "[1800]\ttraining's rmse: 0.681538\tvalid_1's rmse: 0.62381\n",
      "[2000]\ttraining's rmse: 0.662937\tvalid_1's rmse: 0.621189\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.662937\tvalid_1's rmse: 0.621189\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.01, num_iterations: 600, max_depth: 5, num_leaves: 250, min_data_in_leaf: 1000, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.881188\tvalid_1's rmse: 0.826491\n",
      "[400]\ttraining's rmse: 0.485731\tvalid_1's rmse: 0.429806\n",
      "[600]\ttraining's rmse: 0.361725\tvalid_1's rmse: 0.314095\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 0.361725\tvalid_1's rmse: 0.314095\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 800, max_depth: 3, num_leaves: 200, min_data_in_leaf: 100, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.12215\tvalid_1's rmse: 2.15507\n",
      "[400]\ttraining's rmse: 1.60768\tvalid_1's rmse: 1.59119\n",
      "[600]\ttraining's rmse: 1.2907\tvalid_1's rmse: 1.24163\n",
      "[800]\ttraining's rmse: 1.10233\tvalid_1's rmse: 1.03403\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 1.10233\tvalid_1's rmse: 1.03403\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 800, max_depth: 7, num_leaves: 250, min_data_in_leaf: 1000, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.43255\tvalid_1's rmse: 2.17898\n",
      "[400]\ttraining's rmse: 1.60866\tvalid_1's rmse: 1.3393\n",
      "[600]\ttraining's rmse: 1.14827\tvalid_1's rmse: 0.86125\n",
      "[800]\ttraining's rmse: 0.902819\tvalid_1's rmse: 0.610842\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.902819\tvalid_1's rmse: 0.610842\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 800, max_depth: 9, num_leaves: 150, min_data_in_leaf: 1000, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.3131\tvalid_1's rmse: 2.03689\n",
      "[400]\ttraining's rmse: 1.51312\tvalid_1's rmse: 1.28769\n",
      "[600]\ttraining's rmse: 1.02997\tvalid_1's rmse: 0.846623\n",
      "[800]\ttraining's rmse: 0.759864\tvalid_1's rmse: 0.602075\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.759864\tvalid_1's rmse: 0.602075\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.075, num_iterations: 400, max_depth: 11, num_leaves: 700, min_data_in_leaf: 200, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.266688\tvalid_1's rmse: 0.266151\n",
      "Early stopping, best iteration is:\n",
      "[340]\ttraining's rmse: 0.243564\tvalid_1's rmse: 0.259293\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 600, max_depth: -1, num_leaves: 300, min_data_in_leaf: 500, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.58746\tvalid_1's rmse: 3.11064\n",
      "[400]\ttraining's rmse: 1.66653\tvalid_1's rmse: 1.9902\n",
      "[600]\ttraining's rmse: 1.13456\tvalid_1's rmse: 1.33451\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 1.13456\tvalid_1's rmse: 1.33451\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 800, max_depth: 11, num_leaves: 250, min_data_in_leaf: 100, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.15293\tvalid_1's rmse: 2.34393\n",
      "[400]\ttraining's rmse: 1.33653\tvalid_1's rmse: 1.44191\n",
      "[600]\ttraining's rmse: 0.84914\tvalid_1's rmse: 0.902125\n",
      "[800]\ttraining's rmse: 0.56611\tvalid_1's rmse: 0.584695\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.56611\tvalid_1's rmse: 0.584695\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 250, min_data_in_leaf: 100, WRMSSE:0.2422552763894455\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 250, min_data_in_leaf: 100, WRMSSE:0.2522607915944221\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "No of times remaining: 18\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.075, num_iterations: 1200, max_depth: 5, num_leaves: 100, min_data_in_leaf: 500, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.664329\tvalid_1's rmse: 0.609663\n",
      "[400]\ttraining's rmse: 0.559051\tvalid_1's rmse: 0.514883\n",
      "[600]\ttraining's rmse: 0.517887\tvalid_1's rmse: 0.482052\n",
      "[800]\ttraining's rmse: 0.486294\tvalid_1's rmse: 0.463841\n",
      "[1000]\ttraining's rmse: 0.464988\tvalid_1's rmse: 0.451704\n",
      "[1200]\ttraining's rmse: 0.449422\tvalid_1's rmse: 0.443667\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.449422\tvalid_1's rmse: 0.443667\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.005, num_iterations: 2000, max_depth: 3, num_leaves: 700, min_data_in_leaf: 200, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.08873\tvalid_1's rmse: 2.20838\n",
      "[400]\ttraining's rmse: 1.60413\tvalid_1's rmse: 1.65791\n",
      "[600]\ttraining's rmse: 1.28953\tvalid_1's rmse: 1.30637\n",
      "[800]\ttraining's rmse: 1.09644\tvalid_1's rmse: 1.09834\n",
      "[1000]\ttraining's rmse: 0.975761\tvalid_1's rmse: 0.972886\n",
      "[1200]\ttraining's rmse: 0.89851\tvalid_1's rmse: 0.895503\n",
      "[1400]\ttraining's rmse: 0.845826\tvalid_1's rmse: 0.842597\n",
      "[1600]\ttraining's rmse: 0.806744\tvalid_1's rmse: 0.806035\n",
      "[1800]\ttraining's rmse: 0.77895\tvalid_1's rmse: 0.778155\n",
      "[2000]\ttraining's rmse: 0.755144\tvalid_1's rmse: 0.752182\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.755144\tvalid_1's rmse: 0.752182\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.1, num_iterations: 2000, max_depth: 7, num_leaves: 250, min_data_in_leaf: 500, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.748873\tvalid_1's rmse: 0.701791\n",
      "[400]\ttraining's rmse: 0.639585\tvalid_1's rmse: 0.662844\n",
      "Early stopping, best iteration is:\n",
      "[404]\ttraining's rmse: 0.637598\tvalid_1's rmse: 0.662403\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.1, num_iterations: 600, max_depth: 5, num_leaves: 700, min_data_in_leaf: 200, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.224836\tvalid_1's rmse: 0.209202\n",
      "[400]\ttraining's rmse: 0.16279\tvalid_1's rmse: 0.16311\n",
      "[600]\ttraining's rmse: 0.144176\tvalid_1's rmse: 0.157529\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 0.144176\tvalid_1's rmse: 0.157529\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 1200, max_depth: 3, num_leaves: 200, min_data_in_leaf: 300, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.11791\tvalid_1's rmse: 2.15227\n",
      "[400]\ttraining's rmse: 1.60418\tvalid_1's rmse: 1.58644\n",
      "[600]\ttraining's rmse: 1.27813\tvalid_1's rmse: 1.22754\n",
      "[800]\ttraining's rmse: 1.08264\tvalid_1's rmse: 1.01352\n",
      "[1000]\ttraining's rmse: 0.962904\tvalid_1's rmse: 0.884592\n",
      "[1200]\ttraining's rmse: 0.890225\tvalid_1's rmse: 0.811263\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.890225\tvalid_1's rmse: 0.811263\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.01, num_iterations: 1000, max_depth: -1, num_leaves: 600, min_data_in_leaf: 200, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.49716\tvalid_1's rmse: 1.33349\n",
      "[400]\ttraining's rmse: 0.732368\tvalid_1's rmse: 0.561315\n",
      "[600]\ttraining's rmse: 0.516618\tvalid_1's rmse: 0.33315\n",
      "[800]\ttraining's rmse: 0.45679\tvalid_1's rmse: 0.283891\n",
      "[1000]\ttraining's rmse: 0.425872\tvalid_1's rmse: 0.273957\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.425872\tvalid_1's rmse: 0.273957\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 800, max_depth: 11, num_leaves: 400, min_data_in_leaf: 200, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.24286\tvalid_1's rmse: 2.01489\n",
      "[400]\ttraining's rmse: 1.40367\tvalid_1's rmse: 1.24914\n",
      "[600]\ttraining's rmse: 0.908011\tvalid_1's rmse: 0.795958\n",
      "[800]\ttraining's rmse: 0.626432\tvalid_1's rmse: 0.53818\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.626432\tvalid_1's rmse: 0.53818\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 1400, max_depth: 5, num_leaves: 150, min_data_in_leaf: 500, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.69659\tvalid_1's rmse: 1.65124\n",
      "[400]\ttraining's rmse: 1.15891\tvalid_1's rmse: 1.1128\n",
      "[600]\ttraining's rmse: 0.822114\tvalid_1's rmse: 0.778881\n",
      "[800]\ttraining's rmse: 0.608675\tvalid_1's rmse: 0.571163\n",
      "[1000]\ttraining's rmse: 0.490564\tvalid_1's rmse: 0.455608\n",
      "[1200]\ttraining's rmse: 0.418928\tvalid_1's rmse: 0.388699\n",
      "[1400]\ttraining's rmse: 0.373238\tvalid_1's rmse: 0.346202\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1400]\ttraining's rmse: 0.373238\tvalid_1's rmse: 0.346202\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.1, num_iterations: 1000, max_depth: 11, num_leaves: 150, min_data_in_leaf: 1000, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.524778\tvalid_1's rmse: 0.575454\n",
      "[400]\ttraining's rmse: 0.373641\tvalid_1's rmse: 0.503184\n",
      "Early stopping, best iteration is:\n",
      "[498]\ttraining's rmse: 0.339821\tvalid_1's rmse: 0.490266\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.075, num_iterations: 2000, max_depth: 11, num_leaves: 200, min_data_in_leaf: 500, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.329113\tvalid_1's rmse: 0.326091\n",
      "[400]\ttraining's rmse: 0.247038\tvalid_1's rmse: 0.278074\n",
      "[600]\ttraining's rmse: 0.202411\tvalid_1's rmse: 0.261985\n",
      "[800]\ttraining's rmse: 0.178624\tvalid_1's rmse: 0.252862\n",
      "[1000]\ttraining's rmse: 0.162514\tvalid_1's rmse: 0.245938\n",
      "[1200]\ttraining's rmse: 0.151578\tvalid_1's rmse: 0.241776\n",
      "[1400]\ttraining's rmse: 0.143199\tvalid_1's rmse: 0.23815\n",
      "[1600]\ttraining's rmse: 0.136249\tvalid_1's rmse: 0.235654\n",
      "Early stopping, best iteration is:\n",
      "[1700]\ttraining's rmse: 0.133195\tvalid_1's rmse: 0.234214\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.075, num_iterations: <built-in function iter>, num_leaves: 200, min_data_in_leaf: 500, WRMSSE:0.13424869970153694\n",
      "for evaluation= \n",
      " eta: 0.075, num_iterations: <built-in function iter>, num_leaves: 200, min_data_in_leaf: 500, WRMSSE:0.14113203232791718\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "No of times remaining: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 800, max_depth: 7, num_leaves: 300, min_data_in_leaf: 100, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.26625\tvalid_1's rmse: 2.17957\n",
      "[400]\ttraining's rmse: 1.44004\tvalid_1's rmse: 1.39197\n",
      "[600]\ttraining's rmse: 0.945731\tvalid_1's rmse: 0.924276\n",
      "[800]\ttraining's rmse: 0.660496\tvalid_1's rmse: 0.658509\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.660496\tvalid_1's rmse: 0.658509\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.075, num_iterations: 800, max_depth: 3, num_leaves: 100, min_data_in_leaf: 1000, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.724168\tvalid_1's rmse: 0.755098\n",
      "[400]\ttraining's rmse: 0.469707\tvalid_1's rmse: 0.476077\n",
      "[600]\ttraining's rmse: 0.362979\tvalid_1's rmse: 0.3676\n",
      "[800]\ttraining's rmse: 0.309277\tvalid_1's rmse: 0.312439\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.309277\tvalid_1's rmse: 0.312439\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.075, num_iterations: 600, max_depth: 9, num_leaves: 100, min_data_in_leaf: 300, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.698751\tvalid_1's rmse: 0.654046\n",
      "Early stopping, best iteration is:\n",
      "[373]\ttraining's rmse: 0.599786\tvalid_1's rmse: 0.628266\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.075, num_iterations: 400, max_depth: 11, num_leaves: 150, min_data_in_leaf: 100, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.113706\tvalid_1's rmse: 0.139824\n",
      "[400]\ttraining's rmse: 0.087229\tvalid_1's rmse: 0.13007\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.087229\tvalid_1's rmse: 0.13007\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.075, num_iterations: 1000, max_depth: 3, num_leaves: 100, min_data_in_leaf: 500, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.799284\tvalid_1's rmse: 0.749471\n",
      "[400]\ttraining's rmse: 0.524649\tvalid_1's rmse: 0.477592\n",
      "[600]\ttraining's rmse: 0.388624\tvalid_1's rmse: 0.327934\n",
      "[800]\ttraining's rmse: 0.32347\tvalid_1's rmse: 0.25847\n",
      "[1000]\ttraining's rmse: 0.293445\tvalid_1's rmse: 0.231001\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.293445\tvalid_1's rmse: 0.231001\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.075, num_iterations: 1200, max_depth: 7, num_leaves: 600, min_data_in_leaf: 100, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.382019\tvalid_1's rmse: 0.353101\n",
      "[400]\ttraining's rmse: 0.274108\tvalid_1's rmse: 0.286116\n",
      "[600]\ttraining's rmse: 0.230973\tvalid_1's rmse: 0.265173\n",
      "Early stopping, best iteration is:\n",
      "[623]\ttraining's rmse: 0.227259\tvalid_1's rmse: 0.263885\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 600, max_depth: -1, num_leaves: 150, min_data_in_leaf: 200, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.25223\tvalid_1's rmse: 2.01561\n",
      "[400]\ttraining's rmse: 1.41724\tvalid_1's rmse: 1.25319\n",
      "[600]\ttraining's rmse: 0.926472\tvalid_1's rmse: 0.806321\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 0.926472\tvalid_1's rmse: 0.806321\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 800, max_depth: -1, num_leaves: 200, min_data_in_leaf: 1000, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.61429\tvalid_1's rmse: 1.56829\n",
      "[400]\ttraining's rmse: 1.02957\tvalid_1's rmse: 0.983499\n",
      "[600]\ttraining's rmse: 0.682835\tvalid_1's rmse: 0.635586\n",
      "[800]\ttraining's rmse: 0.486834\tvalid_1's rmse: 0.437705\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.486834\tvalid_1's rmse: 0.437705\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.075, num_iterations: 600, max_depth: 11, num_leaves: 150, min_data_in_leaf: 100, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.325096\tvalid_1's rmse: 0.748549\n",
      "Early stopping, best iteration is:\n",
      "[233]\ttraining's rmse: 0.3108\tvalid_1's rmse: 0.74177\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.1, num_iterations: 1400, max_depth: 11, num_leaves: 100, min_data_in_leaf: 100, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.369708\tvalid_1's rmse: 0.476757\n",
      "[400]\ttraining's rmse: 0.266722\tvalid_1's rmse: 0.418712\n",
      "[600]\ttraining's rmse: 0.217246\tvalid_1's rmse: 0.396579\n",
      "[800]\ttraining's rmse: 0.185548\tvalid_1's rmse: 0.382682\n",
      "[1000]\ttraining's rmse: 0.164036\tvalid_1's rmse: 0.374913\n",
      "[1200]\ttraining's rmse: 0.149266\tvalid_1's rmse: 0.370823\n",
      "Early stopping, best iteration is:\n",
      "[1249]\ttraining's rmse: 0.146426\tvalid_1's rmse: 0.369867\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.1, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 100, WRMSSE:0.1319874540673662\n",
      "for evaluation= \n",
      " eta: 0.1, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 100, WRMSSE:0.1404903889009727\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "No of times remaining: 16\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 2000, max_depth: 5, num_leaves: 100, min_data_in_leaf: 200, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.38115\tvalid_1's rmse: 2.27374\n",
      "[400]\ttraining's rmse: 1.63536\tvalid_1's rmse: 1.55126\n",
      "[600]\ttraining's rmse: 1.19306\tvalid_1's rmse: 1.12762\n",
      "[800]\ttraining's rmse: 0.918803\tvalid_1's rmse: 0.873467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttraining's rmse: 0.768165\tvalid_1's rmse: 0.735077\n",
      "[1200]\ttraining's rmse: 0.682237\tvalid_1's rmse: 0.655624\n",
      "[1400]\ttraining's rmse: 0.619479\tvalid_1's rmse: 0.59885\n",
      "[1600]\ttraining's rmse: 0.574918\tvalid_1's rmse: 0.55776\n",
      "[1800]\ttraining's rmse: 0.539919\tvalid_1's rmse: 0.526035\n",
      "[2000]\ttraining's rmse: 0.512141\tvalid_1's rmse: 0.501133\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.512141\tvalid_1's rmse: 0.501133\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.075, num_iterations: 1400, max_depth: 9, num_leaves: 300, min_data_in_leaf: 500, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.316761\tvalid_1's rmse: 0.332256\n",
      "[400]\ttraining's rmse: 0.2679\tvalid_1's rmse: 0.308649\n",
      "Early stopping, best iteration is:\n",
      "[409]\ttraining's rmse: 0.266538\tvalid_1's rmse: 0.308209\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.1, num_iterations: 600, max_depth: 5, num_leaves: 500, min_data_in_leaf: 200, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.910719\tvalid_1's rmse: 0.884722\n",
      "[400]\ttraining's rmse: 0.68141\tvalid_1's rmse: 0.679751\n",
      "Early stopping, best iteration is:\n",
      "[497]\ttraining's rmse: 0.631386\tvalid_1's rmse: 0.651388\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.075, num_iterations: 600, max_depth: 5, num_leaves: 250, min_data_in_leaf: 100, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.236356\tvalid_1's rmse: 0.241337\n",
      "[400]\ttraining's rmse: 0.153677\tvalid_1's rmse: 0.173707\n",
      "[600]\ttraining's rmse: 0.128191\tvalid_1's rmse: 0.158384\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 0.128191\tvalid_1's rmse: 0.158384\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.075, num_iterations: 1000, max_depth: 11, num_leaves: 150, min_data_in_leaf: 200, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.254493\tvalid_1's rmse: 0.300198\n",
      "Early stopping, best iteration is:\n",
      "[267]\ttraining's rmse: 0.234826\tvalid_1's rmse: 0.292087\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 800, max_depth: 9, num_leaves: 150, min_data_in_leaf: 1000, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.42528\tvalid_1's rmse: 2.18401\n",
      "[400]\ttraining's rmse: 1.58389\tvalid_1's rmse: 1.35223\n",
      "[600]\ttraining's rmse: 1.09617\tvalid_1's rmse: 0.855763\n",
      "[800]\ttraining's rmse: 0.833516\tvalid_1's rmse: 0.577723\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.833516\tvalid_1's rmse: 0.577723\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.1, num_iterations: 1200, max_depth: 9, num_leaves: 500, min_data_in_leaf: 500, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.409329\tvalid_1's rmse: 0.386418\n",
      "[400]\ttraining's rmse: 0.351173\tvalid_1's rmse: 0.360582\n",
      "Early stopping, best iteration is:\n",
      "[475]\ttraining's rmse: 0.338091\tvalid_1's rmse: 0.357531\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.01, num_iterations: 800, max_depth: 7, num_leaves: 200, min_data_in_leaf: 100, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.01151\tvalid_1's rmse: 0.987536\n",
      "[400]\ttraining's rmse: 0.46116\tvalid_1's rmse: 0.440124\n",
      "[600]\ttraining's rmse: 0.295165\tvalid_1's rmse: 0.274903\n",
      "[800]\ttraining's rmse: 0.24601\tvalid_1's rmse: 0.228902\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.24601\tvalid_1's rmse: 0.228902\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.01, num_iterations: 800, max_depth: -1, num_leaves: 300, min_data_in_leaf: 300, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.62251\tvalid_1's rmse: 1.94168\n",
      "[400]\ttraining's rmse: 0.76185\tvalid_1's rmse: 0.890968\n",
      "[600]\ttraining's rmse: 0.495628\tvalid_1's rmse: 0.57401\n",
      "[800]\ttraining's rmse: 0.409303\tvalid_1's rmse: 0.479997\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.409303\tvalid_1's rmse: 0.479997\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 400, max_depth: 7, num_leaves: 400, min_data_in_leaf: 1000, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.26691\tvalid_1's rmse: 2.45936\n",
      "[400]\ttraining's rmse: 1.51006\tvalid_1's rmse: 1.60908\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 1.51006\tvalid_1's rmse: 1.60908\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 400, min_data_in_leaf: 1000, WRMSSE:0.1613928874223387\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 400, min_data_in_leaf: 1000, WRMSSE:0.16657621461950428\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "No of times remaining: 15\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 1400, max_depth: 9, num_leaves: 700, min_data_in_leaf: 1000, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.31506\tvalid_1's rmse: 2.19414\n",
      "[400]\ttraining's rmse: 1.52416\tvalid_1's rmse: 1.4197\n",
      "[600]\ttraining's rmse: 1.07137\tvalid_1's rmse: 0.978148\n",
      "[800]\ttraining's rmse: 0.830291\tvalid_1's rmse: 0.744185\n",
      "[1000]\ttraining's rmse: 0.711416\tvalid_1's rmse: 0.629905\n",
      "[1200]\ttraining's rmse: 0.65516\tvalid_1's rmse: 0.577801\n",
      "[1400]\ttraining's rmse: 0.626632\tvalid_1's rmse: 0.552664\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1400]\ttraining's rmse: 0.626632\tvalid_1's rmse: 0.552664\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.1, num_iterations: 800, max_depth: 9, num_leaves: 500, min_data_in_leaf: 500, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.27107\tvalid_1's rmse: 0.33358\n",
      "[400]\ttraining's rmse: 0.211876\tvalid_1's rmse: 0.293623\n",
      "[600]\ttraining's rmse: 0.185402\tvalid_1's rmse: 0.279519\n",
      "Early stopping, best iteration is:\n",
      "[609]\ttraining's rmse: 0.184459\tvalid_1's rmse: 0.278772\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.075, num_iterations: 400, max_depth: 9, num_leaves: 300, min_data_in_leaf: 500, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.690349\tvalid_1's rmse: 0.661555\n",
      "[400]\ttraining's rmse: 0.595524\tvalid_1's rmse: 0.637079\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.595524\tvalid_1's rmse: 0.637079\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 2000, max_depth: 5, num_leaves: 600, min_data_in_leaf: 2000, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.28671\tvalid_1's rmse: 1.23823\n",
      "[400]\ttraining's rmse: 0.892967\tvalid_1's rmse: 0.834228\n",
      "[600]\ttraining's rmse: 0.643243\tvalid_1's rmse: 0.581816\n",
      "[800]\ttraining's rmse: 0.507504\tvalid_1's rmse: 0.447131\n",
      "[1000]\ttraining's rmse: 0.431118\tvalid_1's rmse: 0.375401\n",
      "[1200]\ttraining's rmse: 0.385893\tvalid_1's rmse: 0.33678\n",
      "[1400]\ttraining's rmse: 0.355764\tvalid_1's rmse: 0.311003\n",
      "[1600]\ttraining's rmse: 0.334325\tvalid_1's rmse: 0.292756\n",
      "[1800]\ttraining's rmse: 0.31765\tvalid_1's rmse: 0.279195\n",
      "[2000]\ttraining's rmse: 0.303469\tvalid_1's rmse: 0.267926\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.303469\tvalid_1's rmse: 0.267926\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.075, num_iterations: 1200, max_depth: 9, num_leaves: 100, min_data_in_leaf: 300, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.246988\tvalid_1's rmse: 0.257318\n",
      "[400]\ttraining's rmse: 0.182241\tvalid_1's rmse: 0.21252\n",
      "[600]\ttraining's rmse: 0.158956\tvalid_1's rmse: 0.193348\n",
      "Early stopping, best iteration is:\n",
      "[687]\ttraining's rmse: 0.152428\tvalid_1's rmse: 0.18959\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.075, num_iterations: 600, max_depth: 5, num_leaves: 250, min_data_in_leaf: 200, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.71446\tvalid_1's rmse: 0.59675\n",
      "[400]\ttraining's rmse: 0.549098\tvalid_1's rmse: 0.452588\n",
      "[600]\ttraining's rmse: 0.487603\tvalid_1's rmse: 0.409575\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 0.487603\tvalid_1's rmse: 0.409575\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.075, num_iterations: 1200, max_depth: 7, num_leaves: 500, min_data_in_leaf: 300, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.499043\tvalid_1's rmse: 0.45569\n",
      "[400]\ttraining's rmse: 0.427592\tvalid_1's rmse: 0.41782\n",
      "[600]\ttraining's rmse: 0.392223\tvalid_1's rmse: 0.40452\n",
      "[800]\ttraining's rmse: 0.367238\tvalid_1's rmse: 0.398301\n",
      "Early stopping, best iteration is:\n",
      "[871]\ttraining's rmse: 0.360338\tvalid_1's rmse: 0.396109\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.01, num_iterations: 2000, max_depth: 3, num_leaves: 200, min_data_in_leaf: 100, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.44891\tvalid_1's rmse: 1.38671\n",
      "[400]\ttraining's rmse: 1.00069\tvalid_1's rmse: 0.943558\n",
      "[600]\ttraining's rmse: 0.824123\tvalid_1's rmse: 0.776827\n",
      "[800]\ttraining's rmse: 0.749719\tvalid_1's rmse: 0.705155\n",
      "[1000]\ttraining's rmse: 0.699275\tvalid_1's rmse: 0.655664\n",
      "[1200]\ttraining's rmse: 0.65734\tvalid_1's rmse: 0.61408\n",
      "[1400]\ttraining's rmse: 0.598871\tvalid_1's rmse: 0.556186\n",
      "[1600]\ttraining's rmse: 0.545669\tvalid_1's rmse: 0.504664\n",
      "[1800]\ttraining's rmse: 0.502253\tvalid_1's rmse: 0.462889\n",
      "[2000]\ttraining's rmse: 0.464177\tvalid_1's rmse: 0.426046\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.464177\tvalid_1's rmse: 0.426046\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 1000, max_depth: 3, num_leaves: 500, min_data_in_leaf: 300, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.96297\tvalid_1's rmse: 3.55417\n",
      "[400]\ttraining's rmse: 2.28848\tvalid_1's rmse: 2.73104\n",
      "[600]\ttraining's rmse: 1.87531\tvalid_1's rmse: 2.22213\n",
      "[800]\ttraining's rmse: 1.61479\tvalid_1's rmse: 1.89023\n",
      "[1000]\ttraining's rmse: 1.44748\tvalid_1's rmse: 1.67553\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 1.44748\tvalid_1's rmse: 1.67553\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.01, num_iterations: 600, max_depth: 7, num_leaves: 200, min_data_in_leaf: 500, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.41045\tvalid_1's rmse: 1.50269\n",
      "[400]\ttraining's rmse: 0.679136\tvalid_1's rmse: 0.677023\n",
      "[600]\ttraining's rmse: 0.454982\tvalid_1's rmse: 0.436015\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 0.454982\tvalid_1's rmse: 0.436015\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.01, num_iterations: <built-in function iter>, num_leaves: 200, min_data_in_leaf: 500, WRMSSE:0.15255845941600554\n",
      "for evaluation= \n",
      " eta: 0.01, num_iterations: <built-in function iter>, num_leaves: 200, min_data_in_leaf: 500, WRMSSE:0.15057944316194602\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "No of times remaining: 14\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.075, num_iterations: 800, max_depth: -1, num_leaves: 300, min_data_in_leaf: 2000, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.434267\tvalid_1's rmse: 0.444833\n",
      "[400]\ttraining's rmse: 0.332765\tvalid_1's rmse: 0.378198\n",
      "[600]\ttraining's rmse: 0.280815\tvalid_1's rmse: 0.339612\n",
      "[800]\ttraining's rmse: 0.251337\tvalid_1's rmse: 0.320102\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.251337\tvalid_1's rmse: 0.320102\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.01, num_iterations: 800, max_depth: 11, num_leaves: 700, min_data_in_leaf: 500, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.14122\tvalid_1's rmse: 1.17375\n",
      "[400]\ttraining's rmse: 0.550118\tvalid_1's rmse: 0.505655\n",
      "[600]\ttraining's rmse: 0.382454\tvalid_1's rmse: 0.32373\n",
      "[800]\ttraining's rmse: 0.331186\tvalid_1's rmse: 0.285764\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.331186\tvalid_1's rmse: 0.285764\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.01, num_iterations: 2000, max_depth: 5, num_leaves: 200, min_data_in_leaf: 500, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.50112\tvalid_1's rmse: 2.17091\n",
      "[400]\ttraining's rmse: 1.47926\tvalid_1's rmse: 1.2303\n",
      "[600]\ttraining's rmse: 1.16494\tvalid_1's rmse: 0.980746\n",
      "[800]\ttraining's rmse: 1.02462\tvalid_1's rmse: 0.883765\n",
      "[1000]\ttraining's rmse: 0.936342\tvalid_1's rmse: 0.817538\n",
      "[1200]\ttraining's rmse: 0.873138\tvalid_1's rmse: 0.768502\n",
      "[1400]\ttraining's rmse: 0.827807\tvalid_1's rmse: 0.730753\n",
      "[1600]\ttraining's rmse: 0.788011\tvalid_1's rmse: 0.695969\n",
      "[1800]\ttraining's rmse: 0.74299\tvalid_1's rmse: 0.658885\n",
      "[2000]\ttraining's rmse: 0.709259\tvalid_1's rmse: 0.63193\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.709259\tvalid_1's rmse: 0.63193\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 1400, max_depth: -1, num_leaves: 100, min_data_in_leaf: 500, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.20697\tvalid_1's rmse: 1.16248\n",
      "[400]\ttraining's rmse: 0.773082\tvalid_1's rmse: 0.722477\n",
      "[600]\ttraining's rmse: 0.518827\tvalid_1's rmse: 0.461216\n",
      "[800]\ttraining's rmse: 0.374632\tvalid_1's rmse: 0.312446\n",
      "[1000]\ttraining's rmse: 0.297172\tvalid_1's rmse: 0.233922\n",
      "[1200]\ttraining's rmse: 0.256942\tvalid_1's rmse: 0.195977\n",
      "[1400]\ttraining's rmse: 0.234503\tvalid_1's rmse: 0.178661\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1400]\ttraining's rmse: 0.234503\tvalid_1's rmse: 0.178661\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.075, num_iterations: 1400, max_depth: -1, num_leaves: 150, min_data_in_leaf: 200, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.279263\tvalid_1's rmse: 0.268401\n",
      "Early stopping, best iteration is:\n",
      "[320]\ttraining's rmse: 0.230351\tvalid_1's rmse: 0.257242\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 800, max_depth: 3, num_leaves: 300, min_data_in_leaf: 200, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.65539\tvalid_1's rmse: 2.38967\n",
      "[400]\ttraining's rmse: 1.99216\tvalid_1's rmse: 1.71435\n",
      "[600]\ttraining's rmse: 1.58417\tvalid_1's rmse: 1.30657\n",
      "[800]\ttraining's rmse: 1.34935\tvalid_1's rmse: 1.08452\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 1.34935\tvalid_1's rmse: 1.08452\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.1, num_iterations: 600, max_depth: 3, num_leaves: 500, min_data_in_leaf: 300, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.952051\tvalid_1's rmse: 0.777107\n",
      "[400]\ttraining's rmse: 0.564652\tvalid_1's rmse: 0.457449\n",
      "[600]\ttraining's rmse: 0.424237\tvalid_1's rmse: 0.349623\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 0.424237\tvalid_1's rmse: 0.349623\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.01, num_iterations: 1200, max_depth: 9, num_leaves: 250, min_data_in_leaf: 1000, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.02458\tvalid_1's rmse: 0.983606\n",
      "[400]\ttraining's rmse: 0.478101\tvalid_1's rmse: 0.436812\n",
      "[600]\ttraining's rmse: 0.316243\tvalid_1's rmse: 0.273489\n",
      "[800]\ttraining's rmse: 0.273362\tvalid_1's rmse: 0.230033\n",
      "[1000]\ttraining's rmse: 0.255698\tvalid_1's rmse: 0.214774\n",
      "[1200]\ttraining's rmse: 0.246456\tvalid_1's rmse: 0.208155\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.246456\tvalid_1's rmse: 0.208155\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.1, num_iterations: 1400, max_depth: 3, num_leaves: 400, min_data_in_leaf: 500, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.912506\tvalid_1's rmse: 1.07414\n",
      "[400]\ttraining's rmse: 0.508709\tvalid_1's rmse: 0.571117\n",
      "[600]\ttraining's rmse: 0.384723\tvalid_1's rmse: 0.430722\n",
      "[800]\ttraining's rmse: 0.336212\tvalid_1's rmse: 0.388099\n",
      "Early stopping, best iteration is:\n",
      "[886]\ttraining's rmse: 0.323186\tvalid_1's rmse: 0.378076\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.01, num_iterations: 400, max_depth: 11, num_leaves: 300, min_data_in_leaf: 500, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.44649\tvalid_1's rmse: 1.52653\n",
      "[400]\ttraining's rmse: 0.78496\tvalid_1's rmse: 0.769566\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.78496\tvalid_1's rmse: 0.769566\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.01, num_iterations: <built-in function iter>, num_leaves: 300, min_data_in_leaf: 500, WRMSSE:0.12528706601217238\n",
      "for evaluation= \n",
      " eta: 0.01, num_iterations: <built-in function iter>, num_leaves: 300, min_data_in_leaf: 500, WRMSSE:0.12778537752326855\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "No of times remaining: 13\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.01, num_iterations: 800, max_depth: 5, num_leaves: 700, min_data_in_leaf: 500, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.63662\tvalid_1's rmse: 1.54837\n",
      "[400]\ttraining's rmse: 0.9245\tvalid_1's rmse: 0.874714\n",
      "[600]\ttraining's rmse: 0.689652\tvalid_1's rmse: 0.662291\n",
      "[800]\ttraining's rmse: 0.585063\tvalid_1's rmse: 0.56777\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.585063\tvalid_1's rmse: 0.56777\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.01, num_iterations: 1000, max_depth: 5, num_leaves: 400, min_data_in_leaf: 100, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.27532\tvalid_1's rmse: 1.30239\n",
      "[400]\ttraining's rmse: 0.674775\tvalid_1's rmse: 0.629797\n",
      "[600]\ttraining's rmse: 0.474866\tvalid_1's rmse: 0.432185\n",
      "[800]\ttraining's rmse: 0.392621\tvalid_1's rmse: 0.362825\n",
      "[1000]\ttraining's rmse: 0.345925\tvalid_1's rmse: 0.325105\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.345925\tvalid_1's rmse: 0.325105\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.1, num_iterations: 2000, max_depth: 3, num_leaves: 250, min_data_in_leaf: 2000, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.29514\tvalid_1's rmse: 1.19059\n",
      "[400]\ttraining's rmse: 0.789131\tvalid_1's rmse: 0.76614\n",
      "[600]\ttraining's rmse: 0.619985\tvalid_1's rmse: 0.604633\n",
      "[800]\ttraining's rmse: 0.547707\tvalid_1's rmse: 0.531303\n",
      "Early stopping, best iteration is:\n",
      "[896]\ttraining's rmse: 0.528113\tvalid_1's rmse: 0.519951\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.1, num_iterations: 400, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.208527\tvalid_1's rmse: 0.224147\n",
      "Early stopping, best iteration is:\n",
      "[246]\ttraining's rmse: 0.1891\tvalid_1's rmse: 0.219459\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.1, num_iterations: 2000, max_depth: 11, num_leaves: 100, min_data_in_leaf: 2000, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.427597\tvalid_1's rmse: 0.361428\n",
      "[400]\ttraining's rmse: 0.335181\tvalid_1's rmse: 0.312868\n",
      "Early stopping, best iteration is:\n",
      "[395]\ttraining's rmse: 0.336542\tvalid_1's rmse: 0.312241\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.075, num_iterations: 1000, max_depth: 9, num_leaves: 400, min_data_in_leaf: 100, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.485026\tvalid_1's rmse: 0.411645\n",
      "Early stopping, best iteration is:\n",
      "[301]\ttraining's rmse: 0.442249\tvalid_1's rmse: 0.405154\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 800, max_depth: 9, num_leaves: 250, min_data_in_leaf: 500, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.28885\tvalid_1's rmse: 2.02702\n",
      "[400]\ttraining's rmse: 1.49379\tvalid_1's rmse: 1.2768\n",
      "[600]\ttraining's rmse: 1.04239\tvalid_1's rmse: 0.850392\n",
      "[800]\ttraining's rmse: 0.802209\tvalid_1's rmse: 0.624687\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.802209\tvalid_1's rmse: 0.624687\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.1, num_iterations: 2000, max_depth: 5, num_leaves: 300, min_data_in_leaf: 200, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.242818\tvalid_1's rmse: 0.233667\n",
      "[400]\ttraining's rmse: 0.177676\tvalid_1's rmse: 0.177844\n",
      "[600]\ttraining's rmse: 0.159808\tvalid_1's rmse: 0.166957\n",
      "[800]\ttraining's rmse: 0.149029\tvalid_1's rmse: 0.160158\n",
      "Early stopping, best iteration is:\n",
      "[835]\ttraining's rmse: 0.14778\tvalid_1's rmse: 0.15953\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.075, num_iterations: 1200, max_depth: 3, num_leaves: 250, min_data_in_leaf: 1000, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.111\tvalid_1's rmse: 1.31746\n",
      "[400]\ttraining's rmse: 0.717967\tvalid_1's rmse: 0.896582\n",
      "[600]\ttraining's rmse: 0.591348\tvalid_1's rmse: 0.781885\n",
      "[800]\ttraining's rmse: 0.539111\tvalid_1's rmse: 0.744737\n",
      "Early stopping, best iteration is:\n",
      "[944]\ttraining's rmse: 0.516547\tvalid_1's rmse: 0.732203\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 600, max_depth: 7, num_leaves: 600, min_data_in_leaf: 1000, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.25666\tvalid_1's rmse: 2.45185\n",
      "[400]\ttraining's rmse: 1.47792\tvalid_1's rmse: 1.58206\n",
      "[600]\ttraining's rmse: 1.0253\tvalid_1's rmse: 1.07484\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 1.0253\tvalid_1's rmse: 1.07484\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 600, min_data_in_leaf: 1000, WRMSSE:0.1342795989667484\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 600, min_data_in_leaf: 1000, WRMSSE:0.1391754403095298\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "No of times remaining: 12\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.1, num_iterations: 1200, max_depth: 7, num_leaves: 400, min_data_in_leaf: 200, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.391247\tvalid_1's rmse: 0.446504\n",
      "[400]\ttraining's rmse: 0.305329\tvalid_1's rmse: 0.394365\n",
      "[600]\ttraining's rmse: 0.265925\tvalid_1's rmse: 0.370242\n",
      "Early stopping, best iteration is:\n",
      "[695]\ttraining's rmse: 0.253315\tvalid_1's rmse: 0.365353\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.1, num_iterations: 1400, max_depth: 9, num_leaves: 600, min_data_in_leaf: 2000, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.447267\tvalid_1's rmse: 0.437694\n",
      "[400]\ttraining's rmse: 0.387982\tvalid_1's rmse: 0.393888\n",
      "[600]\ttraining's rmse: 0.362939\tvalid_1's rmse: 0.384109\n",
      "Early stopping, best iteration is:\n",
      "[765]\ttraining's rmse: 0.350344\tvalid_1's rmse: 0.379028\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.075, num_iterations: 400, max_depth: -1, num_leaves: 400, min_data_in_leaf: 1000, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.917641\tvalid_1's rmse: 0.817339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttraining's rmse: 0.780335\tvalid_1's rmse: 0.772645\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.780335\tvalid_1's rmse: 0.772645\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.1, num_iterations: 600, max_depth: 9, num_leaves: 700, min_data_in_leaf: 500, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.242986\tvalid_1's rmse: 0.246793\n",
      "[400]\ttraining's rmse: 0.196724\tvalid_1's rmse: 0.227474\n",
      "Early stopping, best iteration is:\n",
      "[452]\ttraining's rmse: 0.190813\tvalid_1's rmse: 0.225058\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.1, num_iterations: 600, max_depth: 11, num_leaves: 600, min_data_in_leaf: 300, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.407935\tvalid_1's rmse: 0.4392\n",
      "Early stopping, best iteration is:\n",
      "[255]\ttraining's rmse: 0.382113\tvalid_1's rmse: 0.433196\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.1, num_iterations: 2000, max_depth: 7, num_leaves: 400, min_data_in_leaf: 300, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.426442\tvalid_1's rmse: 0.370431\n",
      "Early stopping, best iteration is:\n",
      "[314]\ttraining's rmse: 0.354881\tvalid_1's rmse: 0.335679\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.1, num_iterations: 1400, max_depth: 3, num_leaves: 200, min_data_in_leaf: 1000, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.879549\tvalid_1's rmse: 0.733079\n",
      "[400]\ttraining's rmse: 0.459503\tvalid_1's rmse: 0.367545\n",
      "[600]\ttraining's rmse: 0.313632\tvalid_1's rmse: 0.254296\n",
      "[800]\ttraining's rmse: 0.253069\tvalid_1's rmse: 0.207616\n",
      "[1000]\ttraining's rmse: 0.22169\tvalid_1's rmse: 0.183976\n",
      "[1200]\ttraining's rmse: 0.205327\tvalid_1's rmse: 0.172865\n",
      "[1400]\ttraining's rmse: 0.195915\tvalid_1's rmse: 0.166974\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1400]\ttraining's rmse: 0.195915\tvalid_1's rmse: 0.166974\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 1000, max_depth: 7, num_leaves: 700, min_data_in_leaf: 100, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.60127\tvalid_1's rmse: 1.57525\n",
      "[400]\ttraining's rmse: 1.00415\tvalid_1's rmse: 0.98721\n",
      "[600]\ttraining's rmse: 0.644401\tvalid_1's rmse: 0.634064\n",
      "[800]\ttraining's rmse: 0.431989\tvalid_1's rmse: 0.424171\n",
      "[1000]\ttraining's rmse: 0.309728\tvalid_1's rmse: 0.303558\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.309728\tvalid_1's rmse: 0.303558\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.01, num_iterations: 1000, max_depth: 5, num_leaves: 500, min_data_in_leaf: 500, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.89176\tvalid_1's rmse: 2.24648\n",
      "[400]\ttraining's rmse: 1.1225\tvalid_1's rmse: 1.29313\n",
      "[600]\ttraining's rmse: 0.860627\tvalid_1's rmse: 0.979886\n",
      "[800]\ttraining's rmse: 0.736225\tvalid_1's rmse: 0.835521\n",
      "[1000]\ttraining's rmse: 0.664596\tvalid_1's rmse: 0.761001\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.664596\tvalid_1's rmse: 0.761001\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 800, max_depth: 5, num_leaves: 200, min_data_in_leaf: 2000, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.33816\tvalid_1's rmse: 2.54539\n",
      "[400]\ttraining's rmse: 1.63286\tvalid_1's rmse: 1.75811\n",
      "[600]\ttraining's rmse: 1.22143\tvalid_1's rmse: 1.2962\n",
      "[800]\ttraining's rmse: 1.0119\tvalid_1's rmse: 1.06282\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 1.0119\tvalid_1's rmse: 1.06282\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 200, min_data_in_leaf: 2000, WRMSSE:0.1157065153660169\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 200, min_data_in_leaf: 2000, WRMSSE:0.1141373904152557\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "No of times remaining: 11\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 1200, max_depth: 11, num_leaves: 100, min_data_in_leaf: 500, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.27374\tvalid_1's rmse: 2.16479\n",
      "[400]\ttraining's rmse: 1.45103\tvalid_1's rmse: 1.36721\n",
      "[600]\ttraining's rmse: 0.956406\tvalid_1's rmse: 0.889209\n",
      "[800]\ttraining's rmse: 0.668156\tvalid_1's rmse: 0.613992\n",
      "[1000]\ttraining's rmse: 0.513077\tvalid_1's rmse: 0.469929\n",
      "[1200]\ttraining's rmse: 0.430169\tvalid_1's rmse: 0.399803\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.430169\tvalid_1's rmse: 0.399803\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.01, num_iterations: 1200, max_depth: -1, num_leaves: 250, min_data_in_leaf: 200, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.12539\tvalid_1's rmse: 1.16657\n",
      "[400]\ttraining's rmse: 0.531943\tvalid_1's rmse: 0.494671\n",
      "[600]\ttraining's rmse: 0.360514\tvalid_1's rmse: 0.315506\n",
      "[800]\ttraining's rmse: 0.315316\tvalid_1's rmse: 0.288673\n",
      "[1000]\ttraining's rmse: 0.295301\tvalid_1's rmse: 0.283422\n",
      "[1200]\ttraining's rmse: 0.281054\tvalid_1's rmse: 0.281046\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.281054\tvalid_1's rmse: 0.281046\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 400, max_depth: -1, num_leaves: 300, min_data_in_leaf: 200, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.41136\tvalid_1's rmse: 3.07015\n",
      "[400]\ttraining's rmse: 2.19887\tvalid_1's rmse: 1.91794\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 2.19887\tvalid_1's rmse: 1.91794\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.01, num_iterations: 1400, max_depth: 5, num_leaves: 300, min_data_in_leaf: 300, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.874544\tvalid_1's rmse: 0.82411\n",
      "[400]\ttraining's rmse: 0.469036\tvalid_1's rmse: 0.428108\n",
      "[600]\ttraining's rmse: 0.334692\tvalid_1's rmse: 0.303524\n",
      "[800]\ttraining's rmse: 0.274557\tvalid_1's rmse: 0.253904\n",
      "[1000]\ttraining's rmse: 0.239399\tvalid_1's rmse: 0.227066\n",
      "[1200]\ttraining's rmse: 0.214058\tvalid_1's rmse: 0.2067\n",
      "[1400]\ttraining's rmse: 0.194111\tvalid_1's rmse: 0.190199\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1400]\ttraining's rmse: 0.194111\tvalid_1's rmse: 0.190199\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.01, num_iterations: 400, max_depth: 3, num_leaves: 300, min_data_in_leaf: 500, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.59591\tvalid_1's rmse: 1.57781\n",
      "[400]\ttraining's rmse: 1.07763\tvalid_1's rmse: 1.00854\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 1.07763\tvalid_1's rmse: 1.00854\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.1, num_iterations: 400, max_depth: 3, num_leaves: 200, min_data_in_leaf: 200, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.04774\tvalid_1's rmse: 0.912147\n",
      "[400]\ttraining's rmse: 0.620266\tvalid_1's rmse: 0.514131\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.620266\tvalid_1's rmse: 0.514131\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.1, num_iterations: 1400, max_depth: 5, num_leaves: 100, min_data_in_leaf: 200, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.520006\tvalid_1's rmse: 0.44841\n",
      "[400]\ttraining's rmse: 0.378937\tvalid_1's rmse: 0.338302\n",
      "[600]\ttraining's rmse: 0.338606\tvalid_1's rmse: 0.312017\n",
      "Early stopping, best iteration is:\n",
      "[692]\ttraining's rmse: 0.326766\tvalid_1's rmse: 0.30515\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.075, num_iterations: 1400, max_depth: 9, num_leaves: 700, min_data_in_leaf: 1000, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.232516\tvalid_1's rmse: 0.227743\n",
      "[400]\ttraining's rmse: 0.195494\tvalid_1's rmse: 0.196783\n",
      "[600]\ttraining's rmse: 0.175638\tvalid_1's rmse: 0.178524\n",
      "[800]\ttraining's rmse: 0.16421\tvalid_1's rmse: 0.171714\n",
      "Early stopping, best iteration is:\n",
      "[928]\ttraining's rmse: 0.158372\tvalid_1's rmse: 0.168416\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.01, num_iterations: 1200, max_depth: 11, num_leaves: 500, min_data_in_leaf: 300, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.63307\tvalid_1's rmse: 1.95131\n",
      "[400]\ttraining's rmse: 0.779971\tvalid_1's rmse: 0.900244\n",
      "[600]\ttraining's rmse: 0.521945\tvalid_1's rmse: 0.58738\n",
      "[800]\ttraining's rmse: 0.443199\tvalid_1's rmse: 0.500446\n",
      "[1000]\ttraining's rmse: 0.406536\tvalid_1's rmse: 0.464313\n",
      "[1200]\ttraining's rmse: 0.381861\tvalid_1's rmse: 0.441066\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.381861\tvalid_1's rmse: 0.441066\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.1, num_iterations: 800, max_depth: 11, num_leaves: 150, min_data_in_leaf: 500, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.417035\tvalid_1's rmse: 0.46079\n",
      "Early stopping, best iteration is:\n",
      "[328]\ttraining's rmse: 0.352622\tvalid_1's rmse: 0.44272\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.1, num_iterations: <built-in function iter>, num_leaves: 150, min_data_in_leaf: 500, WRMSSE:0.21518130271162583\n",
      "for evaluation= \n",
      " eta: 0.1, num_iterations: <built-in function iter>, num_leaves: 150, min_data_in_leaf: 500, WRMSSE:0.20814072501644093\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "No of times remaining: 10\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.1, num_iterations: 600, max_depth: -1, num_leaves: 500, min_data_in_leaf: 200, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.315681\tvalid_1's rmse: 0.371573\n",
      "Early stopping, best iteration is:\n",
      "[344]\ttraining's rmse: 0.251667\tvalid_1's rmse: 0.354867\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.005, num_iterations: 1400, max_depth: 11, num_leaves: 100, min_data_in_leaf: 2000, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.8495\tvalid_1's rmse: 1.94533\n",
      "[400]\ttraining's rmse: 1.21805\tvalid_1's rmse: 1.23628\n",
      "[600]\ttraining's rmse: 0.84651\tvalid_1's rmse: 0.818913\n",
      "[800]\ttraining's rmse: 0.635801\tvalid_1's rmse: 0.584852\n",
      "[1000]\ttraining's rmse: 0.517339\tvalid_1's rmse: 0.457723\n",
      "[1200]\ttraining's rmse: 0.446707\tvalid_1's rmse: 0.386212\n",
      "[1400]\ttraining's rmse: 0.403032\tvalid_1's rmse: 0.349314\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1400]\ttraining's rmse: 0.403032\tvalid_1's rmse: 0.349314\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.075, num_iterations: 1000, max_depth: -1, num_leaves: 700, min_data_in_leaf: 1000, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.917641\tvalid_1's rmse: 0.817339\n",
      "[400]\ttraining's rmse: 0.781013\tvalid_1's rmse: 0.770748\n",
      "Early stopping, best iteration is:\n",
      "[572]\ttraining's rmse: 0.721317\tvalid_1's rmse: 0.753962\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.01, num_iterations: 1000, max_depth: -1, num_leaves: 400, min_data_in_leaf: 200, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.753121\tvalid_1's rmse: 0.711936\n",
      "[400]\ttraining's rmse: 0.352084\tvalid_1's rmse: 0.302342\n",
      "[600]\ttraining's rmse: 0.23519\tvalid_1's rmse: 0.182195\n",
      "[800]\ttraining's rmse: 0.203226\tvalid_1's rmse: 0.156625\n",
      "[1000]\ttraining's rmse: 0.186115\tvalid_1's rmse: 0.150391\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.186115\tvalid_1's rmse: 0.150391\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.075, num_iterations: 600, max_depth: 7, num_leaves: 400, min_data_in_leaf: 100, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.2914\tvalid_1's rmse: 0.350301\n",
      "[400]\ttraining's rmse: 0.223804\tvalid_1's rmse: 0.29786\n",
      "[600]\ttraining's rmse: 0.190703\tvalid_1's rmse: 0.277371\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 0.190703\tvalid_1's rmse: 0.277371\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.075, num_iterations: 1200, max_depth: 11, num_leaves: 400, min_data_in_leaf: 2000, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.457635\tvalid_1's rmse: 0.370957\n",
      "[400]\ttraining's rmse: 0.336457\tvalid_1's rmse: 0.276737\n",
      "[600]\ttraining's rmse: 0.279652\tvalid_1's rmse: 0.255014\n",
      "Early stopping, best iteration is:\n",
      "[620]\ttraining's rmse: 0.27647\tvalid_1's rmse: 0.253428\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.01, num_iterations: 1400, max_depth: 11, num_leaves: 700, min_data_in_leaf: 200, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.40624\tvalid_1's rmse: 1.24997\n",
      "[400]\ttraining's rmse: 0.647007\tvalid_1's rmse: 0.543603\n",
      "[600]\ttraining's rmse: 0.429434\tvalid_1's rmse: 0.334837\n",
      "[800]\ttraining's rmse: 0.373586\tvalid_1's rmse: 0.288488\n",
      "[1000]\ttraining's rmse: 0.35077\tvalid_1's rmse: 0.275294\n",
      "[1200]\ttraining's rmse: 0.335481\tvalid_1's rmse: 0.269499\n",
      "[1400]\ttraining's rmse: 0.324158\tvalid_1's rmse: 0.266155\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1400]\ttraining's rmse: 0.324158\tvalid_1's rmse: 0.266155\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.1, num_iterations: 1400, max_depth: 3, num_leaves: 250, min_data_in_leaf: 1000, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.514765\tvalid_1's rmse: 0.477356\n",
      "[400]\ttraining's rmse: 0.324488\tvalid_1's rmse: 0.288674\n",
      "[600]\ttraining's rmse: 0.268621\tvalid_1's rmse: 0.241839\n",
      "[800]\ttraining's rmse: 0.246468\tvalid_1's rmse: 0.224261\n",
      "[1000]\ttraining's rmse: 0.234238\tvalid_1's rmse: 0.213926\n",
      "Early stopping, best iteration is:\n",
      "[1146]\ttraining's rmse: 0.228364\tvalid_1's rmse: 0.209446\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.075, num_iterations: 800, max_depth: 9, num_leaves: 500, min_data_in_leaf: 100, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[104]\ttraining's rmse: 0.587756\tvalid_1's rmse: 0.880493\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.01, num_iterations: 1200, max_depth: 5, num_leaves: 200, min_data_in_leaf: 2000, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.60769\tvalid_1's rmse: 1.7319\n",
      "[400]\ttraining's rmse: 0.939878\tvalid_1's rmse: 0.984326\n",
      "[600]\ttraining's rmse: 0.742031\tvalid_1's rmse: 0.76424\n",
      "[800]\ttraining's rmse: 0.659254\tvalid_1's rmse: 0.675856\n",
      "[1000]\ttraining's rmse: 0.607031\tvalid_1's rmse: 0.619154\n",
      "[1200]\ttraining's rmse: 0.571287\tvalid_1's rmse: 0.581175\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.571287\tvalid_1's rmse: 0.581175\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.01, num_iterations: <built-in function iter>, num_leaves: 200, min_data_in_leaf: 2000, WRMSSE:0.06085349114160468\n",
      "for evaluation= \n",
      " eta: 0.01, num_iterations: <built-in function iter>, num_leaves: 200, min_data_in_leaf: 2000, WRMSSE:0.06384238450340779\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "No of times remaining: 9\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.1, num_iterations: 400, max_depth: 7, num_leaves: 250, min_data_in_leaf: 2000, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.485846\tvalid_1's rmse: 0.489955\n",
      "[400]\ttraining's rmse: 0.414435\tvalid_1's rmse: 0.434343\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.414435\tvalid_1's rmse: 0.434343\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.1, num_iterations: 1400, max_depth: 7, num_leaves: 400, min_data_in_leaf: 200, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.286023\tvalid_1's rmse: 0.354181\n",
      "[400]\ttraining's rmse: 0.217604\tvalid_1's rmse: 0.317644\n",
      "Early stopping, best iteration is:\n",
      "[449]\ttraining's rmse: 0.209317\tvalid_1's rmse: 0.31441\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.075, num_iterations: 2000, max_depth: 11, num_leaves: 250, min_data_in_leaf: 100, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.575045\tvalid_1's rmse: 0.633957\n",
      "Early stopping, best iteration is:\n",
      "[216]\ttraining's rmse: 0.565766\tvalid_1's rmse: 0.631679\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.01, num_iterations: 1400, max_depth: 7, num_leaves: 700, min_data_in_leaf: 1000, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.800422\tvalid_1's rmse: 0.744098\n",
      "[400]\ttraining's rmse: 0.417649\tvalid_1's rmse: 0.351528\n",
      "[600]\ttraining's rmse: 0.292967\tvalid_1's rmse: 0.237296\n",
      "[800]\ttraining's rmse: 0.251325\tvalid_1's rmse: 0.209418\n",
      "[1000]\ttraining's rmse: 0.233631\tvalid_1's rmse: 0.200375\n",
      "[1200]\ttraining's rmse: 0.223113\tvalid_1's rmse: 0.195219\n",
      "[1400]\ttraining's rmse: 0.214922\tvalid_1's rmse: 0.190942\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1400]\ttraining's rmse: 0.214922\tvalid_1's rmse: 0.190942\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.01, num_iterations: 1200, max_depth: 9, num_leaves: 250, min_data_in_leaf: 300, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.2004\tvalid_1's rmse: 1.18167\n",
      "[400]\ttraining's rmse: 0.614254\tvalid_1's rmse: 0.536498\n",
      "[600]\ttraining's rmse: 0.458493\tvalid_1's rmse: 0.377053\n",
      "[800]\ttraining's rmse: 0.416821\tvalid_1's rmse: 0.348658\n",
      "Early stopping, best iteration is:\n",
      "[951]\ttraining's rmse: 0.40132\tvalid_1's rmse: 0.343352\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.075, num_iterations: 1000, max_depth: 3, num_leaves: 200, min_data_in_leaf: 100, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.14613\tvalid_1's rmse: 1.03194\n",
      "[400]\ttraining's rmse: 0.7392\tvalid_1's rmse: 0.587663\n",
      "[600]\ttraining's rmse: 0.540789\tvalid_1's rmse: 0.412746\n",
      "[800]\ttraining's rmse: 0.436445\tvalid_1's rmse: 0.336982\n",
      "[1000]\ttraining's rmse: 0.376232\tvalid_1's rmse: 0.297528\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.376232\tvalid_1's rmse: 0.297528\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.075, num_iterations: 1400, max_depth: 7, num_leaves: 600, min_data_in_leaf: 1000, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.506908\tvalid_1's rmse: 0.423536\n",
      "[400]\ttraining's rmse: 0.44433\tvalid_1's rmse: 0.385967\n",
      "[600]\ttraining's rmse: 0.413748\tvalid_1's rmse: 0.372971\n",
      "[800]\ttraining's rmse: 0.39226\tvalid_1's rmse: 0.366155\n",
      "Early stopping, best iteration is:\n",
      "[885]\ttraining's rmse: 0.38445\tvalid_1's rmse: 0.362385\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.01, num_iterations: 800, max_depth: 11, num_leaves: 100, min_data_in_leaf: 1000, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.02655\tvalid_1's rmse: 0.980805\n",
      "[400]\ttraining's rmse: 0.486438\tvalid_1's rmse: 0.437389\n",
      "[600]\ttraining's rmse: 0.331247\tvalid_1's rmse: 0.286447\n",
      "[800]\ttraining's rmse: 0.291722\tvalid_1's rmse: 0.254664\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.291722\tvalid_1's rmse: 0.254664\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.1, num_iterations: 1200, max_depth: 5, num_leaves: 500, min_data_in_leaf: 200, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.657515\tvalid_1's rmse: 1.01342\n",
      "Early stopping, best iteration is:\n",
      "[277]\ttraining's rmse: 0.492067\tvalid_1's rmse: 0.873959\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.01, num_iterations: 1200, max_depth: 7, num_leaves: 700, min_data_in_leaf: 500, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.41539\tvalid_1's rmse: 1.51538\n",
      "[400]\ttraining's rmse: 0.689925\tvalid_1's rmse: 0.697666\n",
      "[600]\ttraining's rmse: 0.473761\tvalid_1's rmse: 0.464491\n",
      "[800]\ttraining's rmse: 0.408666\tvalid_1's rmse: 0.405213\n",
      "[1000]\ttraining's rmse: 0.381373\tvalid_1's rmse: 0.383194\n",
      "[1200]\ttraining's rmse: 0.363652\tvalid_1's rmse: 0.368332\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.363652\tvalid_1's rmse: 0.368332\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.01, num_iterations: <built-in function iter>, num_leaves: 700, min_data_in_leaf: 500, WRMSSE:0.056036430514777955\n",
      "for evaluation= \n",
      " eta: 0.01, num_iterations: <built-in function iter>, num_leaves: 700, min_data_in_leaf: 500, WRMSSE:0.06253485297676926\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "No of times remaining: 8\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.1, num_iterations: 600, max_depth: 11, num_leaves: 400, min_data_in_leaf: 500, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.482239\tvalid_1's rmse: 0.447271\n",
      "Early stopping, best iteration is:\n",
      "[355]\ttraining's rmse: 0.422935\tvalid_1's rmse: 0.423777\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.1, num_iterations: 600, max_depth: 7, num_leaves: 150, min_data_in_leaf: 100, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.310684\tvalid_1's rmse: 0.371177\n",
      "Early stopping, best iteration is:\n",
      "[375]\ttraining's rmse: 0.255455\tvalid_1's rmse: 0.343051\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.01, num_iterations: 1200, max_depth: 7, num_leaves: 100, min_data_in_leaf: 2000, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.43048\tvalid_1's rmse: 2.01258\n",
      "[400]\ttraining's rmse: 1.42563\tvalid_1's rmse: 1.05413\n",
      "[600]\ttraining's rmse: 1.08477\tvalid_1's rmse: 0.790243\n",
      "[800]\ttraining's rmse: 0.935446\tvalid_1's rmse: 0.707004\n",
      "[1000]\ttraining's rmse: 0.844095\tvalid_1's rmse: 0.650392\n",
      "[1200]\ttraining's rmse: 0.777873\tvalid_1's rmse: 0.603107\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.777873\tvalid_1's rmse: 0.603107\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 800, max_depth: 7, num_leaves: 200, min_data_in_leaf: 500, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.21612\tvalid_1's rmse: 1.1752\n",
      "[400]\ttraining's rmse: 0.783449\tvalid_1's rmse: 0.740389\n",
      "[600]\ttraining's rmse: 0.529296\tvalid_1's rmse: 0.483674\n",
      "[800]\ttraining's rmse: 0.384448\tvalid_1's rmse: 0.338269\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.384448\tvalid_1's rmse: 0.338269\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.01, num_iterations: 600, max_depth: 3, num_leaves: 100, min_data_in_leaf: 500, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.59769\tvalid_1's rmse: 1.57748\n",
      "[400]\ttraining's rmse: 1.08234\tvalid_1's rmse: 1.0077\n",
      "[600]\ttraining's rmse: 0.896601\tvalid_1's rmse: 0.810339\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 0.896601\tvalid_1's rmse: 0.810339\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 600, max_depth: -1, num_leaves: 150, min_data_in_leaf: 500, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.38324\tvalid_1's rmse: 2.1571\n",
      "[400]\ttraining's rmse: 1.5271\tvalid_1's rmse: 1.31879\n",
      "[600]\ttraining's rmse: 1.0301\tvalid_1's rmse: 0.823585\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 1.0301\tvalid_1's rmse: 0.823585\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.1, num_iterations: 1400, max_depth: -1, num_leaves: 150, min_data_in_leaf: 100, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.361488\tvalid_1's rmse: 0.428405\n",
      "Early stopping, best iteration is:\n",
      "[188]\ttraining's rmse: 0.369616\tvalid_1's rmse: 0.427781\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.01, num_iterations: 600, max_depth: 5, num_leaves: 700, min_data_in_leaf: 2000, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.17308\tvalid_1's rmse: 1.11872\n",
      "[400]\ttraining's rmse: 0.63079\tvalid_1's rmse: 0.587636\n",
      "[600]\ttraining's rmse: 0.448805\tvalid_1's rmse: 0.415153\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 0.448805\tvalid_1's rmse: 0.415153\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.075, num_iterations: 1200, max_depth: 11, num_leaves: 200, min_data_in_leaf: 500, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.515652\tvalid_1's rmse: 0.677415\n",
      "[400]\ttraining's rmse: 0.412324\tvalid_1's rmse: 0.60515\n",
      "Early stopping, best iteration is:\n",
      "[533]\ttraining's rmse: 0.37632\tvalid_1's rmse: 0.590634\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.01, num_iterations: 2000, max_depth: 5, num_leaves: 200, min_data_in_leaf: 100, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.53296\tvalid_1's rmse: 1.63165\n",
      "[400]\ttraining's rmse: 0.833104\tvalid_1's rmse: 0.847747\n",
      "[600]\ttraining's rmse: 0.614103\tvalid_1's rmse: 0.614399\n",
      "[800]\ttraining's rmse: 0.518791\tvalid_1's rmse: 0.525137\n",
      "[1000]\ttraining's rmse: 0.467556\tvalid_1's rmse: 0.472416\n",
      "[1200]\ttraining's rmse: 0.430901\tvalid_1's rmse: 0.43326\n",
      "[1400]\ttraining's rmse: 0.399392\tvalid_1's rmse: 0.399664\n",
      "[1600]\ttraining's rmse: 0.372079\tvalid_1's rmse: 0.370056\n",
      "[1800]\ttraining's rmse: 0.347465\tvalid_1's rmse: 0.34389\n",
      "[2000]\ttraining's rmse: 0.321638\tvalid_1's rmse: 0.316312\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.321638\tvalid_1's rmse: 0.316312\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.01, num_iterations: <built-in function iter>, num_leaves: 200, min_data_in_leaf: 100, WRMSSE:0.14872524320210018\n",
      "for evaluation= \n",
      " eta: 0.01, num_iterations: <built-in function iter>, num_leaves: 200, min_data_in_leaf: 100, WRMSSE:0.15215672391802845\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "No of times remaining: 7\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 2000, max_depth: 11, num_leaves: 500, min_data_in_leaf: 100, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.23141\tvalid_1's rmse: 2.14155\n",
      "[400]\ttraining's rmse: 1.39502\tvalid_1's rmse: 1.34235\n",
      "[600]\ttraining's rmse: 0.898875\tvalid_1's rmse: 0.870565\n",
      "[800]\ttraining's rmse: 0.615666\tvalid_1's rmse: 0.601866\n",
      "[1000]\ttraining's rmse: 0.463702\tvalid_1's rmse: 0.458114\n",
      "[1200]\ttraining's rmse: 0.387169\tvalid_1's rmse: 0.385765\n",
      "[1400]\ttraining's rmse: 0.349176\tvalid_1's rmse: 0.350815\n",
      "[1600]\ttraining's rmse: 0.329932\tvalid_1's rmse: 0.333958\n",
      "[1800]\ttraining's rmse: 0.318247\tvalid_1's rmse: 0.325559\n",
      "[2000]\ttraining's rmse: 0.310262\tvalid_1's rmse: 0.320299\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.310262\tvalid_1's rmse: 0.320299\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.075, num_iterations: 800, max_depth: 5, num_leaves: 600, min_data_in_leaf: 1000, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.498475\tvalid_1's rmse: 0.502375\n",
      "[400]\ttraining's rmse: 0.399806\tvalid_1's rmse: 0.400773\n",
      "[600]\ttraining's rmse: 0.37545\tvalid_1's rmse: 0.387581\n",
      "Early stopping, best iteration is:\n",
      "[765]\ttraining's rmse: 0.361938\tvalid_1's rmse: 0.381342\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.075, num_iterations: 1000, max_depth: -1, num_leaves: 200, min_data_in_leaf: 2000, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.979282\tvalid_1's rmse: 0.81884\n",
      "[400]\ttraining's rmse: 0.848281\tvalid_1's rmse: 0.773532\n",
      "Early stopping, best iteration is:\n",
      "[496]\ttraining's rmse: 0.816773\tvalid_1's rmse: 0.763682\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 1200, max_depth: 7, num_leaves: 400, min_data_in_leaf: 200, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.2086\tvalid_1's rmse: 1.17278\n",
      "[400]\ttraining's rmse: 0.770334\tvalid_1's rmse: 0.735534\n",
      "[600]\ttraining's rmse: 0.508997\tvalid_1's rmse: 0.474852\n",
      "[800]\ttraining's rmse: 0.357704\tvalid_1's rmse: 0.325873\n",
      "[1000]\ttraining's rmse: 0.272079\tvalid_1's rmse: 0.244354\n",
      "[1200]\ttraining's rmse: 0.223178\tvalid_1's rmse: 0.199496\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.223178\tvalid_1's rmse: 0.199496\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 1000, max_depth: 3, num_leaves: 500, min_data_in_leaf: 200, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.11824\tvalid_1's rmse: 2.15209\n",
      "[400]\ttraining's rmse: 1.6049\tvalid_1's rmse: 1.58724\n",
      "[600]\ttraining's rmse: 1.27981\tvalid_1's rmse: 1.22949\n",
      "[800]\ttraining's rmse: 1.08571\tvalid_1's rmse: 1.01599\n",
      "[1000]\ttraining's rmse: 0.966824\tvalid_1's rmse: 0.887427\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.966824\tvalid_1's rmse: 0.887427\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.075, num_iterations: 1000, max_depth: 7, num_leaves: 300, min_data_in_leaf: 300, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.398388\tvalid_1's rmse: 0.316962\n",
      "[400]\ttraining's rmse: 0.296661\tvalid_1's rmse: 0.263328\n",
      "Early stopping, best iteration is:\n",
      "[571]\ttraining's rmse: 0.263271\tvalid_1's rmse: 0.253368\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.1, num_iterations: 2000, max_depth: 5, num_leaves: 250, min_data_in_leaf: 100, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.54594\tvalid_1's rmse: 0.412179\n",
      "[400]\ttraining's rmse: 0.371355\tvalid_1's rmse: 0.315624\n",
      "[600]\ttraining's rmse: 0.317099\tvalid_1's rmse: 0.288375\n",
      "[800]\ttraining's rmse: 0.291196\tvalid_1's rmse: 0.278141\n",
      "[1000]\ttraining's rmse: 0.268868\tvalid_1's rmse: 0.269787\n",
      "Early stopping, best iteration is:\n",
      "[1087]\ttraining's rmse: 0.261932\tvalid_1's rmse: 0.267256\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.075, num_iterations: 400, max_depth: 7, num_leaves: 700, min_data_in_leaf: 500, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.228763\tvalid_1's rmse: 0.209146\n",
      "[400]\ttraining's rmse: 0.195564\tvalid_1's rmse: 0.184971\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.195564\tvalid_1's rmse: 0.184971\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 1200, max_depth: 11, num_leaves: 700, min_data_in_leaf: 300, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.56414\tvalid_1's rmse: 3.08124\n",
      "[400]\ttraining's rmse: 1.63966\tvalid_1's rmse: 1.96107\n",
      "[600]\ttraining's rmse: 1.09414\tvalid_1's rmse: 1.28865\n",
      "[800]\ttraining's rmse: 0.788166\tvalid_1's rmse: 0.905462\n",
      "[1000]\ttraining's rmse: 0.622372\tvalid_1's rmse: 0.698363\n",
      "[1200]\ttraining's rmse: 0.533152\tvalid_1's rmse: 0.592174\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.533152\tvalid_1's rmse: 0.592174\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 1200, max_depth: 5, num_leaves: 400, min_data_in_leaf: 500, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.28617\tvalid_1's rmse: 2.48479\n",
      "[400]\ttraining's rmse: 1.54819\tvalid_1's rmse: 1.65749\n",
      "[600]\ttraining's rmse: 1.09335\tvalid_1's rmse: 1.14355\n",
      "[800]\ttraining's rmse: 0.842356\tvalid_1's rmse: 0.861075\n",
      "[1000]\ttraining's rmse: 0.705921\tvalid_1's rmse: 0.709711\n",
      "[1200]\ttraining's rmse: 0.619442\tvalid_1's rmse: 0.618971\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.619442\tvalid_1's rmse: 0.618971\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 400, min_data_in_leaf: 500, WRMSSE:0.11120381089879557\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 400, min_data_in_leaf: 500, WRMSSE:0.11573103239901876\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "No of times remaining: 6\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.1, num_iterations: 600, max_depth: 9, num_leaves: 100, min_data_in_leaf: 500, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.357\tvalid_1's rmse: 0.400679\n",
      "[400]\ttraining's rmse: 0.2852\tvalid_1's rmse: 0.351542\n",
      "[600]\ttraining's rmse: 0.248876\tvalid_1's rmse: 0.331174\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 0.248876\tvalid_1's rmse: 0.331174\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.1, num_iterations: 400, max_depth: -1, num_leaves: 250, min_data_in_leaf: 2000, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.308409\tvalid_1's rmse: 0.316753\n",
      "[400]\ttraining's rmse: 0.233433\tvalid_1's rmse: 0.270027\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.233433\tvalid_1's rmse: 0.270027\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.1, num_iterations: 1200, max_depth: 5, num_leaves: 200, min_data_in_leaf: 200, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.902186\tvalid_1's rmse: 0.82846\n",
      "[400]\ttraining's rmse: 0.704373\tvalid_1's rmse: 0.670112\n",
      "Early stopping, best iteration is:\n",
      "[499]\ttraining's rmse: 0.665781\tvalid_1's rmse: 0.657371\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 600, max_depth: 5, num_leaves: 600, min_data_in_leaf: 100, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.27603\tvalid_1's rmse: 1.23774\n",
      "[400]\ttraining's rmse: 0.878376\tvalid_1's rmse: 0.834283\n",
      "[600]\ttraining's rmse: 0.631392\tvalid_1's rmse: 0.584482\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 0.631392\tvalid_1's rmse: 0.584482\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.1, num_iterations: 600, max_depth: -1, num_leaves: 200, min_data_in_leaf: 2000, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.417313\tvalid_1's rmse: 0.355322\n",
      "[400]\ttraining's rmse: 0.317995\tvalid_1's rmse: 0.300191\n",
      "Early stopping, best iteration is:\n",
      "[445]\ttraining's rmse: 0.307613\tvalid_1's rmse: 0.296301\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.1, num_iterations: 600, max_depth: 5, num_leaves: 300, min_data_in_leaf: 2000, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.532861\tvalid_1's rmse: 0.396249\n",
      "[400]\ttraining's rmse: 0.34882\tvalid_1's rmse: 0.267455\n",
      "Early stopping, best iteration is:\n",
      "[525]\ttraining's rmse: 0.305847\tvalid_1's rmse: 0.24583\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.1, num_iterations: 1000, max_depth: -1, num_leaves: 250, min_data_in_leaf: 2000, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.460923\tvalid_1's rmse: 0.379713\n",
      "[400]\ttraining's rmse: 0.376702\tvalid_1's rmse: 0.339703\n",
      "Early stopping, best iteration is:\n",
      "[544]\ttraining's rmse: 0.348965\tvalid_1's rmse: 0.332697\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 1000, max_depth: 9, num_leaves: 600, min_data_in_leaf: 2000, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.6399\tvalid_1's rmse: 1.58915\n",
      "[400]\ttraining's rmse: 1.0618\tvalid_1's rmse: 1.01062\n",
      "[600]\ttraining's rmse: 0.720972\tvalid_1's rmse: 0.672536\n",
      "[800]\ttraining's rmse: 0.525772\tvalid_1's rmse: 0.482764\n",
      "[1000]\ttraining's rmse: 0.417775\tvalid_1's rmse: 0.380848\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.417775\tvalid_1's rmse: 0.380848\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.075, num_iterations: 800, max_depth: 5, num_leaves: 700, min_data_in_leaf: 2000, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.656553\tvalid_1's rmse: 0.755079\n",
      "[400]\ttraining's rmse: 0.451947\tvalid_1's rmse: 0.486416\n",
      "[600]\ttraining's rmse: 0.395986\tvalid_1's rmse: 0.437485\n",
      "[800]\ttraining's rmse: 0.366269\tvalid_1's rmse: 0.421803\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.366269\tvalid_1's rmse: 0.421803\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.1, num_iterations: 600, max_depth: -1, num_leaves: 500, min_data_in_leaf: 500, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.400761\tvalid_1's rmse: 0.443637\n",
      "Early stopping, best iteration is:\n",
      "[331]\ttraining's rmse: 0.32469\tvalid_1's rmse: 0.425181\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.1, num_iterations: <built-in function iter>, num_leaves: 500, min_data_in_leaf: 500, WRMSSE:0.08420460927548765\n",
      "for evaluation= \n",
      " eta: 0.1, num_iterations: <built-in function iter>, num_leaves: 500, min_data_in_leaf: 500, WRMSSE:0.0872911946949317\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "No of times remaining: 5\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.1, num_iterations: 600, max_depth: -1, num_leaves: 700, min_data_in_leaf: 200, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.261799\tvalid_1's rmse: 0.343885\n",
      "[400]\ttraining's rmse: 0.178318\tvalid_1's rmse: 0.315442\n",
      "[600]\ttraining's rmse: 0.13967\tvalid_1's rmse: 0.29851\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 0.13967\tvalid_1's rmse: 0.29851\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.1, num_iterations: 2000, max_depth: -1, num_leaves: 250, min_data_in_leaf: 1000, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.325271\tvalid_1's rmse: 0.303782\n",
      "[400]\ttraining's rmse: 0.244142\tvalid_1's rmse: 0.271861\n",
      "Early stopping, best iteration is:\n",
      "[433]\ttraining's rmse: 0.237622\tvalid_1's rmse: 0.269797\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 800, max_depth: 9, num_leaves: 250, min_data_in_leaf: 2000, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.56428\tvalid_1's rmse: 3.15764\n",
      "[400]\ttraining's rmse: 2.45118\tvalid_1's rmse: 2.03742\n",
      "[600]\ttraining's rmse: 1.81737\tvalid_1's rmse: 1.42081\n",
      "[800]\ttraining's rmse: 1.47816\tvalid_1's rmse: 1.10988\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 1.47816\tvalid_1's rmse: 1.10988\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.01, num_iterations: 1400, max_depth: 7, num_leaves: 600, min_data_in_leaf: 2000, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.827293\tvalid_1's rmse: 0.764471\n",
      "[400]\ttraining's rmse: 0.456624\tvalid_1's rmse: 0.384503\n",
      "[600]\ttraining's rmse: 0.330931\tvalid_1's rmse: 0.268289\n",
      "[800]\ttraining's rmse: 0.286916\tvalid_1's rmse: 0.234679\n",
      "[1000]\ttraining's rmse: 0.264725\tvalid_1's rmse: 0.219671\n",
      "[1200]\ttraining's rmse: 0.249613\tvalid_1's rmse: 0.210864\n",
      "[1400]\ttraining's rmse: 0.238317\tvalid_1's rmse: 0.205562\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1400]\ttraining's rmse: 0.238317\tvalid_1's rmse: 0.205562\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.01, num_iterations: 600, max_depth: 9, num_leaves: 400, min_data_in_leaf: 100, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.13537\tvalid_1's rmse: 1.14456\n",
      "[400]\ttraining's rmse: 0.479445\tvalid_1's rmse: 0.457443\n",
      "[600]\ttraining's rmse: 0.266474\tvalid_1's rmse: 0.238171\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 0.266474\tvalid_1's rmse: 0.238171\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.1, num_iterations: 1200, max_depth: 11, num_leaves: 150, min_data_in_leaf: 500, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.404189\tvalid_1's rmse: 0.324817\n",
      "Early stopping, best iteration is:\n",
      "[314]\ttraining's rmse: 0.346039\tvalid_1's rmse: 0.305754\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 800, max_depth: 9, num_leaves: 400, min_data_in_leaf: 2000, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.35782\tvalid_1's rmse: 2.06062\n",
      "[400]\ttraining's rmse: 1.5661\tvalid_1's rmse: 1.31223\n",
      "[600]\ttraining's rmse: 1.10609\tvalid_1's rmse: 0.883865\n",
      "[800]\ttraining's rmse: 0.850608\tvalid_1's rmse: 0.656551\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.850608\tvalid_1's rmse: 0.656551\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.1, num_iterations: 400, max_depth: 5, num_leaves: 100, min_data_in_leaf: 1000, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.307137\tvalid_1's rmse: 0.279582\n",
      "[400]\ttraining's rmse: 0.256516\tvalid_1's rmse: 0.242964\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.256516\tvalid_1's rmse: 0.242964\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.075, num_iterations: 1000, max_depth: -1, num_leaves: 150, min_data_in_leaf: 200, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[148]\ttraining's rmse: 0.426785\tvalid_1's rmse: 0.896004\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.075, num_iterations: 1200, max_depth: 7, num_leaves: 400, min_data_in_leaf: 500, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.444494\tvalid_1's rmse: 0.486593\n",
      "[400]\ttraining's rmse: 0.35051\tvalid_1's rmse: 0.410112\n",
      "Early stopping, best iteration is:\n",
      "[487]\ttraining's rmse: 0.331036\tvalid_1's rmse: 0.4038\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.075, num_iterations: <built-in function iter>, num_leaves: 400, min_data_in_leaf: 500, WRMSSE:0.11728473486019386\n",
      "for evaluation= \n",
      " eta: 0.075, num_iterations: <built-in function iter>, num_leaves: 400, min_data_in_leaf: 500, WRMSSE:0.1174828036258017\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "No of times remaining: 4\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.1, num_iterations: 600, max_depth: 11, num_leaves: 700, min_data_in_leaf: 1000, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.56802\tvalid_1's rmse: 0.527539\n",
      "[400]\ttraining's rmse: 0.494359\tvalid_1's rmse: 0.491485\n",
      "Early stopping, best iteration is:\n",
      "[481]\ttraining's rmse: 0.477267\tvalid_1's rmse: 0.484099\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.01, num_iterations: 1200, max_depth: 11, num_leaves: 200, min_data_in_leaf: 500, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.13171\tvalid_1's rmse: 1.16678\n",
      "[400]\ttraining's rmse: 0.519453\tvalid_1's rmse: 0.479872\n",
      "[600]\ttraining's rmse: 0.330873\tvalid_1's rmse: 0.271338\n",
      "[800]\ttraining's rmse: 0.26536\tvalid_1's rmse: 0.218399\n",
      "[1000]\ttraining's rmse: 0.238958\tvalid_1's rmse: 0.20756\n",
      "[1200]\ttraining's rmse: 0.222907\tvalid_1's rmse: 0.204373\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.222907\tvalid_1's rmse: 0.204373\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 800, max_depth: 11, num_leaves: 500, min_data_in_leaf: 300, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.43304\tvalid_1's rmse: 3.06982\n",
      "[400]\ttraining's rmse: 2.23211\tvalid_1's rmse: 1.91515\n",
      "[600]\ttraining's rmse: 1.54172\tvalid_1's rmse: 1.2623\n",
      "[800]\ttraining's rmse: 1.16603\tvalid_1's rmse: 0.924327\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 1.16603\tvalid_1's rmse: 0.924327\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.01, num_iterations: 2000, max_depth: 9, num_leaves: 400, min_data_in_leaf: 100, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.754893\tvalid_1's rmse: 0.716593\n",
      "[400]\ttraining's rmse: 0.356387\tvalid_1's rmse: 0.318567\n",
      "[600]\ttraining's rmse: 0.243161\tvalid_1's rmse: 0.220062\n",
      "[800]\ttraining's rmse: 0.212966\tvalid_1's rmse: 0.205641\n",
      "[1000]\ttraining's rmse: 0.196725\tvalid_1's rmse: 0.202217\n",
      "Early stopping, best iteration is:\n",
      "[997]\ttraining's rmse: 0.196908\tvalid_1's rmse: 0.20221\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 600, max_depth: 3, num_leaves: 400, min_data_in_leaf: 2000, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.12079\tvalid_1's rmse: 2.15273\n",
      "[400]\ttraining's rmse: 1.60655\tvalid_1's rmse: 1.58527\n",
      "[600]\ttraining's rmse: 1.28214\tvalid_1's rmse: 1.22757\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 1.28214\tvalid_1's rmse: 1.22757\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 600, max_depth: 7, num_leaves: 150, min_data_in_leaf: 1000, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.41614\tvalid_1's rmse: 2.17665\n",
      "[400]\ttraining's rmse: 1.56743\tvalid_1's rmse: 1.33292\n",
      "[600]\ttraining's rmse: 1.07618\tvalid_1's rmse: 0.84191\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 1.07618\tvalid_1's rmse: 0.84191\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.075, num_iterations: 800, max_depth: 11, num_leaves: 500, min_data_in_leaf: 300, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.320395\tvalid_1's rmse: 0.283524\n",
      "[400]\ttraining's rmse: 0.250497\tvalid_1's rmse: 0.251088\n",
      "[600]\ttraining's rmse: 0.217643\tvalid_1's rmse: 0.241501\n",
      "[800]\ttraining's rmse: 0.197027\tvalid_1's rmse: 0.237435\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.197027\tvalid_1's rmse: 0.237435\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 2000, max_depth: 9, num_leaves: 700, min_data_in_leaf: 2000, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.63924\tvalid_1's rmse: 1.58797\n",
      "[400]\ttraining's rmse: 1.05951\tvalid_1's rmse: 1.01048\n",
      "[600]\ttraining's rmse: 0.718455\tvalid_1's rmse: 0.67208\n",
      "[800]\ttraining's rmse: 0.52242\tvalid_1's rmse: 0.480386\n",
      "[1000]\ttraining's rmse: 0.412423\tvalid_1's rmse: 0.375954\n",
      "[1200]\ttraining's rmse: 0.35102\tvalid_1's rmse: 0.320748\n",
      "[1400]\ttraining's rmse: 0.312278\tvalid_1's rmse: 0.288882\n",
      "[1600]\ttraining's rmse: 0.288333\tvalid_1's rmse: 0.269443\n",
      "[1800]\ttraining's rmse: 0.272592\tvalid_1's rmse: 0.257107\n",
      "[2000]\ttraining's rmse: 0.261868\tvalid_1's rmse: 0.24893\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.261868\tvalid_1's rmse: 0.24893\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 2000, max_depth: 7, num_leaves: 200, min_data_in_leaf: 200, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.59481\tvalid_1's rmse: 3.12379\n",
      "[400]\ttraining's rmse: 1.66791\tvalid_1's rmse: 1.99269\n",
      "[600]\ttraining's rmse: 1.12514\tvalid_1's rmse: 1.32994\n",
      "[800]\ttraining's rmse: 0.816637\tvalid_1's rmse: 0.955504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttraining's rmse: 0.643142\tvalid_1's rmse: 0.753511\n",
      "[1200]\ttraining's rmse: 0.540758\tvalid_1's rmse: 0.640181\n",
      "[1400]\ttraining's rmse: 0.475982\tvalid_1's rmse: 0.570164\n",
      "[1600]\ttraining's rmse: 0.43138\tvalid_1's rmse: 0.52344\n",
      "[1800]\ttraining's rmse: 0.400956\tvalid_1's rmse: 0.491057\n",
      "[2000]\ttraining's rmse: 0.37998\tvalid_1's rmse: 0.468804\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.37998\tvalid_1's rmse: 0.468804\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.075, num_iterations: 600, max_depth: 3, num_leaves: 400, min_data_in_leaf: 100, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.987885\tvalid_1's rmse: 0.978399\n",
      "[400]\ttraining's rmse: 0.592622\tvalid_1's rmse: 0.575394\n",
      "[600]\ttraining's rmse: 0.392192\tvalid_1's rmse: 0.392145\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 0.392192\tvalid_1's rmse: 0.392145\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.075, num_iterations: <built-in function iter>, num_leaves: 400, min_data_in_leaf: 100, WRMSSE:0.18436980458142385\n",
      "for evaluation= \n",
      " eta: 0.075, num_iterations: <built-in function iter>, num_leaves: 400, min_data_in_leaf: 100, WRMSSE:0.1819242272633681\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "No of times remaining: 3\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.075, num_iterations: 800, max_depth: 7, num_leaves: 400, min_data_in_leaf: 200, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.372556\tvalid_1's rmse: 0.418505\n",
      "[400]\ttraining's rmse: 0.298905\tvalid_1's rmse: 0.364332\n",
      "[600]\ttraining's rmse: 0.263136\tvalid_1's rmse: 0.339433\n",
      "[800]\ttraining's rmse: 0.238288\tvalid_1's rmse: 0.32427\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.238288\tvalid_1's rmse: 0.32427\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.01, num_iterations: 600, max_depth: 3, num_leaves: 100, min_data_in_leaf: 200, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.59866\tvalid_1's rmse: 1.65349\n",
      "[400]\ttraining's rmse: 1.09015\tvalid_1's rmse: 1.09133\n",
      "[600]\ttraining's rmse: 0.887349\tvalid_1's rmse: 0.883707\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 0.887349\tvalid_1's rmse: 0.883707\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.01, num_iterations: 800, max_depth: -1, num_leaves: 300, min_data_in_leaf: 1000, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.30422\tvalid_1's rmse: 1.9175\n",
      "[400]\ttraining's rmse: 1.23832\tvalid_1's rmse: 0.889091\n",
      "[600]\ttraining's rmse: 0.891128\tvalid_1's rmse: 0.628669\n",
      "[800]\ttraining's rmse: 0.767179\tvalid_1's rmse: 0.572434\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.767179\tvalid_1's rmse: 0.572434\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.1, num_iterations: 1000, max_depth: 5, num_leaves: 600, min_data_in_leaf: 1000, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.278468\tvalid_1's rmse: 0.249861\n",
      "Early stopping, best iteration is:\n",
      "[369]\ttraining's rmse: 0.226272\tvalid_1's rmse: 0.21942\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 2000, max_depth: 5, num_leaves: 150, min_data_in_leaf: 200, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.94094\tvalid_1's rmse: 1.96385\n",
      "[400]\ttraining's rmse: 1.31617\tvalid_1's rmse: 1.28882\n",
      "[600]\ttraining's rmse: 0.927488\tvalid_1's rmse: 0.872057\n",
      "[800]\ttraining's rmse: 0.704437\tvalid_1's rmse: 0.637477\n",
      "[1000]\ttraining's rmse: 0.581377\tvalid_1's rmse: 0.513545\n",
      "[1200]\ttraining's rmse: 0.505765\tvalid_1's rmse: 0.440485\n",
      "[1400]\ttraining's rmse: 0.455676\tvalid_1's rmse: 0.394796\n",
      "[1600]\ttraining's rmse: 0.419201\tvalid_1's rmse: 0.363186\n",
      "[1800]\ttraining's rmse: 0.390987\tvalid_1's rmse: 0.339187\n",
      "[2000]\ttraining's rmse: 0.368415\tvalid_1's rmse: 0.320234\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.368415\tvalid_1's rmse: 0.320234\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.1, num_iterations: 1200, max_depth: 5, num_leaves: 150, min_data_in_leaf: 200, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.564855\tvalid_1's rmse: 0.585855\n",
      "[400]\ttraining's rmse: 0.320648\tvalid_1's rmse: 0.375802\n",
      "[600]\ttraining's rmse: 0.251027\tvalid_1's rmse: 0.322956\n",
      "[800]\ttraining's rmse: 0.218613\tvalid_1's rmse: 0.301554\n",
      "Early stopping, best iteration is:\n",
      "[854]\ttraining's rmse: 0.212113\tvalid_1's rmse: 0.296834\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.1, num_iterations: 1000, max_depth: 5, num_leaves: 150, min_data_in_leaf: 500, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.520475\tvalid_1's rmse: 0.460979\n",
      "[400]\ttraining's rmse: 0.338148\tvalid_1's rmse: 0.323772\n",
      "[600]\ttraining's rmse: 0.28785\tvalid_1's rmse: 0.283095\n",
      "[800]\ttraining's rmse: 0.265351\tvalid_1's rmse: 0.26594\n",
      "[1000]\ttraining's rmse: 0.250527\tvalid_1's rmse: 0.257984\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.250527\tvalid_1's rmse: 0.257984\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.075, num_iterations: 2000, max_depth: -1, num_leaves: 200, min_data_in_leaf: 300, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.145704\tvalid_1's rmse: 0.141416\n",
      "[400]\ttraining's rmse: 0.107827\tvalid_1's rmse: 0.124611\n",
      "Early stopping, best iteration is:\n",
      "[556]\ttraining's rmse: 0.0920046\tvalid_1's rmse: 0.119128\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.01, num_iterations: 1200, max_depth: 9, num_leaves: 200, min_data_in_leaf: 200, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.60756\tvalid_1's rmse: 1.91909\n",
      "[400]\ttraining's rmse: 0.724606\tvalid_1's rmse: 0.847437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttraining's rmse: 0.439792\tvalid_1's rmse: 0.518377\n",
      "[800]\ttraining's rmse: 0.354327\tvalid_1's rmse: 0.434721\n",
      "[1000]\ttraining's rmse: 0.312765\tvalid_1's rmse: 0.398662\n",
      "[1200]\ttraining's rmse: 0.288233\tvalid_1's rmse: 0.377423\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.288233\tvalid_1's rmse: 0.377423\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 1200, max_depth: 11, num_leaves: 250, min_data_in_leaf: 200, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.16459\tvalid_1's rmse: 2.35568\n",
      "[400]\ttraining's rmse: 1.35721\tvalid_1's rmse: 1.45965\n",
      "[600]\ttraining's rmse: 0.88142\tvalid_1's rmse: 0.927025\n",
      "[800]\ttraining's rmse: 0.612025\tvalid_1's rmse: 0.620544\n",
      "[1000]\ttraining's rmse: 0.469116\tvalid_1's rmse: 0.454881\n",
      "[1200]\ttraining's rmse: 0.395578\tvalid_1's rmse: 0.37189\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.395578\tvalid_1's rmse: 0.37189\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 250, min_data_in_leaf: 200, WRMSSE:0.10112181308685358\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 250, min_data_in_leaf: 200, WRMSSE:0.10714884018323848\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "No of times remaining: 2\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.1, num_iterations: 400, max_depth: 11, num_leaves: 150, min_data_in_leaf: 1000, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.372524\tvalid_1's rmse: 0.414618\n",
      "[400]\ttraining's rmse: 0.290306\tvalid_1's rmse: 0.35763\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.290306\tvalid_1's rmse: 0.35763\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.01, num_iterations: 600, max_depth: 5, num_leaves: 400, min_data_in_leaf: 300, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.27906\tvalid_1's rmse: 1.30474\n",
      "[400]\ttraining's rmse: 0.688242\tvalid_1's rmse: 0.643221\n",
      "[600]\ttraining's rmse: 0.494189\tvalid_1's rmse: 0.449621\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 0.494189\tvalid_1's rmse: 0.449621\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 800, max_depth: -1, num_leaves: 500, min_data_in_leaf: 300, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.42218\tvalid_1's rmse: 3.05807\n",
      "[400]\ttraining's rmse: 2.19668\tvalid_1's rmse: 1.88204\n",
      "[600]\ttraining's rmse: 1.47457\tvalid_1's rmse: 1.19758\n",
      "[800]\ttraining's rmse: 1.06568\tvalid_1's rmse: 0.816824\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 1.06568\tvalid_1's rmse: 0.816824\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 1200, max_depth: 5, num_leaves: 600, min_data_in_leaf: 200, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.27702\tvalid_1's rmse: 1.23838\n",
      "[400]\ttraining's rmse: 0.879744\tvalid_1's rmse: 0.8351\n",
      "[600]\ttraining's rmse: 0.632546\tvalid_1's rmse: 0.585015\n",
      "[800]\ttraining's rmse: 0.488861\tvalid_1's rmse: 0.439177\n",
      "[1000]\ttraining's rmse: 0.41366\tvalid_1's rmse: 0.363312\n",
      "[1200]\ttraining's rmse: 0.368625\tvalid_1's rmse: 0.319685\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.368625\tvalid_1's rmse: 0.319685\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 1000, max_depth: 11, num_leaves: 100, min_data_in_leaf: 1000, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.88939\tvalid_1's rmse: 1.91894\n",
      "[400]\ttraining's rmse: 1.22961\tvalid_1's rmse: 1.20142\n",
      "[600]\ttraining's rmse: 0.842918\tvalid_1's rmse: 0.772343\n",
      "[800]\ttraining's rmse: 0.628421\tvalid_1's rmse: 0.530897\n",
      "[1000]\ttraining's rmse: 0.515791\tvalid_1's rmse: 0.409088\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.515791\tvalid_1's rmse: 0.409088\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.075, num_iterations: 600, max_depth: 7, num_leaves: 300, min_data_in_leaf: 1000, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.503295\tvalid_1's rmse: 0.355766\n",
      "[400]\ttraining's rmse: 0.378071\tvalid_1's rmse: 0.291118\n",
      "Early stopping, best iteration is:\n",
      "[552]\ttraining's rmse: 0.337775\tvalid_1's rmse: 0.277394\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.1, num_iterations: 2000, max_depth: 5, num_leaves: 200, min_data_in_leaf: 100, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.568135\tvalid_1's rmse: 0.44595\n",
      "[400]\ttraining's rmse: 0.39506\tvalid_1's rmse: 0.331129\n",
      "[600]\ttraining's rmse: 0.339822\tvalid_1's rmse: 0.301174\n",
      "Early stopping, best iteration is:\n",
      "[690]\ttraining's rmse: 0.325189\tvalid_1's rmse: 0.294821\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 600, max_depth: 9, num_leaves: 600, min_data_in_leaf: 200, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.58664\tvalid_1's rmse: 1.55154\n",
      "[400]\ttraining's rmse: 0.993569\tvalid_1's rmse: 0.962077\n",
      "[600]\ttraining's rmse: 0.642318\tvalid_1's rmse: 0.612216\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 0.642318\tvalid_1's rmse: 0.612216\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.01, num_iterations: 800, max_depth: 9, num_leaves: 150, min_data_in_leaf: 200, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.61804\tvalid_1's rmse: 1.94066\n",
      "[400]\ttraining's rmse: 0.749211\tvalid_1's rmse: 0.876841\n",
      "[600]\ttraining's rmse: 0.482807\tvalid_1's rmse: 0.554359\n",
      "[800]\ttraining's rmse: 0.409003\tvalid_1's rmse: 0.476047\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 0.409003\tvalid_1's rmse: 0.476047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.1, num_iterations: 1400, max_depth: 11, num_leaves: 250, min_data_in_leaf: 500, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.342524\tvalid_1's rmse: 0.357328\n",
      "[400]\ttraining's rmse: 0.248713\tvalid_1's rmse: 0.322386\n",
      "[600]\ttraining's rmse: 0.208102\tvalid_1's rmse: 0.311447\n",
      "Early stopping, best iteration is:\n",
      "[744]\ttraining's rmse: 0.191903\tvalid_1's rmse: 0.306075\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.1, num_iterations: <built-in function iter>, num_leaves: 250, min_data_in_leaf: 500, WRMSSE:0.1601139189379075\n",
      "for evaluation= \n",
      " eta: 0.1, num_iterations: <built-in function iter>, num_leaves: 250, min_data_in_leaf: 500, WRMSSE:0.15985303527679703\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "No of times remaining: 1\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 600, max_depth: 11, num_leaves: 700, min_data_in_leaf: 1000, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.30622\tvalid_1's rmse: 2.18818\n",
      "[400]\ttraining's rmse: 1.49682\tvalid_1's rmse: 1.40146\n",
      "[600]\ttraining's rmse: 1.01556\tvalid_1's rmse: 0.937288\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 1.01556\tvalid_1's rmse: 0.937288\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.1, num_iterations: 1000, max_depth: 5, num_leaves: 150, min_data_in_leaf: 2000, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.343928\tvalid_1's rmse: 0.327026\n",
      "[400]\ttraining's rmse: 0.246254\tvalid_1's rmse: 0.24888\n",
      "[600]\ttraining's rmse: 0.224846\tvalid_1's rmse: 0.234706\n",
      "Early stopping, best iteration is:\n",
      "[704]\ttraining's rmse: 0.218665\tvalid_1's rmse: 0.229896\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 1000, max_depth: 9, num_leaves: 400, min_data_in_leaf: 2000, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.55011\tvalid_1's rmse: 3.13609\n",
      "[400]\ttraining's rmse: 2.41704\tvalid_1's rmse: 1.99409\n",
      "[600]\ttraining's rmse: 1.75421\tvalid_1's rmse: 1.34658\n",
      "[800]\ttraining's rmse: 1.38202\tvalid_1's rmse: 1.00108\n",
      "[1000]\ttraining's rmse: 1.17368\tvalid_1's rmse: 0.829131\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 1.17368\tvalid_1's rmse: 0.829131\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 1000, max_depth: -1, num_leaves: 250, min_data_in_leaf: 200, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.1901\tvalid_1's rmse: 1.15077\n",
      "[400]\ttraining's rmse: 0.748459\tvalid_1's rmse: 0.707717\n",
      "[600]\ttraining's rmse: 0.483863\tvalid_1's rmse: 0.439913\n",
      "[800]\ttraining's rmse: 0.328234\tvalid_1's rmse: 0.280696\n",
      "[1000]\ttraining's rmse: 0.239817\tvalid_1's rmse: 0.189699\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.239817\tvalid_1's rmse: 0.189699\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 1200, max_depth: 7, num_leaves: 250, min_data_in_leaf: 2000, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.92015\tvalid_1's rmse: 1.94916\n",
      "[400]\ttraining's rmse: 1.2826\tvalid_1's rmse: 1.26258\n",
      "[600]\ttraining's rmse: 0.91289\tvalid_1's rmse: 0.857648\n",
      "[800]\ttraining's rmse: 0.707286\tvalid_1's rmse: 0.630031\n",
      "[1000]\ttraining's rmse: 0.588287\tvalid_1's rmse: 0.503465\n",
      "[1200]\ttraining's rmse: 0.519795\tvalid_1's rmse: 0.434059\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.519795\tvalid_1's rmse: 0.434059\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 400, max_depth: 5, num_leaves: 100, min_data_in_leaf: 1000, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.50569\tvalid_1's rmse: 2.23589\n",
      "[400]\ttraining's rmse: 1.75\tvalid_1's rmse: 1.45765\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 1.75\tvalid_1's rmse: 1.45765\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 1400, max_depth: 7, num_leaves: 400, min_data_in_leaf: 100, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.26266\tvalid_1's rmse: 2.04302\n",
      "[400]\ttraining's rmse: 1.42811\tvalid_1's rmse: 1.27632\n",
      "[600]\ttraining's rmse: 0.93064\tvalid_1's rmse: 0.818284\n",
      "[800]\ttraining's rmse: 0.642259\tvalid_1's rmse: 0.552974\n",
      "[1000]\ttraining's rmse: 0.481798\tvalid_1's rmse: 0.405406\n",
      "[1200]\ttraining's rmse: 0.394278\tvalid_1's rmse: 0.327822\n",
      "[1400]\ttraining's rmse: 0.34604\tvalid_1's rmse: 0.285253\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1400]\ttraining's rmse: 0.34604\tvalid_1's rmse: 0.285253\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.1, num_iterations: 600, max_depth: 9, num_leaves: 200, min_data_in_leaf: 100, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.21934\tvalid_1's rmse: 0.250555\n",
      "Early stopping, best iteration is:\n",
      "[187]\ttraining's rmse: 0.222584\tvalid_1's rmse: 0.249743\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.01, num_iterations: 400, max_depth: -1, num_leaves: 500, min_data_in_leaf: 100, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.59475\tvalid_1's rmse: 1.84846\n",
      "[400]\ttraining's rmse: 0.74154\tvalid_1's rmse: 0.876208\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.74154\tvalid_1's rmse: 0.876208\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.075, num_iterations: 1200, max_depth: 11, num_leaves: 600, min_data_in_leaf: 100, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 0.335822\tvalid_1's rmse: 0.382468\n",
      "[400]\ttraining's rmse: 0.244663\tvalid_1's rmse: 0.327832\n",
      "[600]\ttraining's rmse: 0.197131\tvalid_1's rmse: 0.304427\n",
      "[800]\ttraining's rmse: 0.166518\tvalid_1's rmse: 0.293441\n",
      "[1000]\ttraining's rmse: 0.144766\tvalid_1's rmse: 0.286811\n",
      "[1200]\ttraining's rmse: 0.128724\tvalid_1's rmse: 0.282634\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.128724\tvalid_1's rmse: 0.282634\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.075, num_iterations: <built-in function iter>, num_leaves: 600, min_data_in_leaf: 100, WRMSSE:0.25789456816607315\n",
      "for evaluation= \n",
      " eta: 0.075, num_iterations: <built-in function iter>, num_leaves: 600, min_data_in_leaf: 100, WRMSSE:0.2581852075271389\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "No of times remaining: 0\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.075, num_iterations: 1000, max_depth: 9, num_leaves: 150, min_data_in_leaf: 300, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.405594\tvalid_1's rmse: 0.427572\n",
      "[400]\ttraining's rmse: 0.338949\tvalid_1's rmse: 0.391905\n",
      "Early stopping, best iteration is:\n",
      "[454]\ttraining's rmse: 0.326778\tvalid_1's rmse: 0.384666\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.1, num_iterations: 800, max_depth: 11, num_leaves: 500, min_data_in_leaf: 2000, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.322423\tvalid_1's rmse: 0.309381\n",
      "[400]\ttraining's rmse: 0.245583\tvalid_1's rmse: 0.26267\n",
      "[600]\ttraining's rmse: 0.221517\tvalid_1's rmse: 0.250659\n",
      "Early stopping, best iteration is:\n",
      "[618]\ttraining's rmse: 0.220292\tvalid_1's rmse: 0.249526\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 800, max_depth: 9, num_leaves: 600, min_data_in_leaf: 2000, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.56428\tvalid_1's rmse: 3.15764\n",
      "[400]\ttraining's rmse: 2.45118\tvalid_1's rmse: 2.03742\n",
      "[600]\ttraining's rmse: 1.81737\tvalid_1's rmse: 1.42081\n",
      "[800]\ttraining's rmse: 1.47816\tvalid_1's rmse: 1.10988\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's rmse: 1.47816\tvalid_1's rmse: 1.10988\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.075, num_iterations: 2000, max_depth: 9, num_leaves: 300, min_data_in_leaf: 500, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.209928\tvalid_1's rmse: 0.19133\n",
      "[400]\ttraining's rmse: 0.144057\tvalid_1's rmse: 0.16198\n",
      "[600]\ttraining's rmse: 0.12362\tvalid_1's rmse: 0.151737\n",
      "[800]\ttraining's rmse: 0.113519\tvalid_1's rmse: 0.148669\n",
      "[1000]\ttraining's rmse: 0.106695\tvalid_1's rmse: 0.146503\n",
      "[1200]\ttraining's rmse: 0.100921\tvalid_1's rmse: 0.145011\n",
      "Early stopping, best iteration is:\n",
      "[1283]\ttraining's rmse: 0.0989161\tvalid_1's rmse: 0.144457\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 600, max_depth: 3, num_leaves: 200, min_data_in_leaf: 1000, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.11913\tvalid_1's rmse: 2.15299\n",
      "[400]\ttraining's rmse: 1.6062\tvalid_1's rmse: 1.58817\n",
      "[600]\ttraining's rmse: 1.28173\tvalid_1's rmse: 1.23085\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's rmse: 1.28173\tvalid_1's rmse: 1.23085\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.01, num_iterations: 1400, max_depth: 5, num_leaves: 250, min_data_in_leaf: 200, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.6457\tvalid_1's rmse: 1.44498\n",
      "[400]\ttraining's rmse: 0.870709\tvalid_1's rmse: 0.70281\n",
      "[600]\ttraining's rmse: 0.621402\tvalid_1's rmse: 0.493736\n",
      "[800]\ttraining's rmse: 0.520344\tvalid_1's rmse: 0.418731\n",
      "[1000]\ttraining's rmse: 0.462259\tvalid_1's rmse: 0.374567\n",
      "[1200]\ttraining's rmse: 0.421724\tvalid_1's rmse: 0.342044\n",
      "[1400]\ttraining's rmse: 0.389417\tvalid_1's rmse: 0.31512\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1400]\ttraining's rmse: 0.389417\tvalid_1's rmse: 0.31512\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.1, num_iterations: 1000, max_depth: 9, num_leaves: 600, min_data_in_leaf: 1000, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.583295\tvalid_1's rmse: 0.465866\n",
      "Early stopping, best iteration is:\n",
      "[323]\ttraining's rmse: 0.540293\tvalid_1's rmse: 0.439334\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.075, num_iterations: 400, max_depth: 3, num_leaves: 600, min_data_in_leaf: 2000, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.592264\tvalid_1's rmse: 0.56107\n",
      "[400]\ttraining's rmse: 0.344442\tvalid_1's rmse: 0.318627\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.344442\tvalid_1's rmse: 0.318627\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.01, num_iterations: 1000, max_depth: 11, num_leaves: 600, min_data_in_leaf: 500, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.65756\tvalid_1's rmse: 1.96436\n",
      "[400]\ttraining's rmse: 0.833622\tvalid_1's rmse: 0.941788\n",
      "[600]\ttraining's rmse: 0.573207\tvalid_1's rmse: 0.63143\n",
      "[800]\ttraining's rmse: 0.488864\tvalid_1's rmse: 0.541294\n",
      "[1000]\ttraining's rmse: 0.444984\tvalid_1's rmse: 0.500687\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.444984\tvalid_1's rmse: 0.500687\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.075, num_iterations: 2000, max_depth: 7, num_leaves: 600, min_data_in_leaf: 200, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 0.466019\tvalid_1's rmse: 0.496529\n",
      "[400]\ttraining's rmse: 0.379371\tvalid_1's rmse: 0.454556\n",
      "Early stopping, best iteration is:\n",
      "[472]\ttraining's rmse: 0.363574\tvalid_1's rmse: 0.449093\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.075, num_iterations: <built-in function iter>, num_leaves: 600, min_data_in_leaf: 200, WRMSSE:0.14720266878646232\n",
      "for evaluation= \n",
      " eta: 0.075, num_iterations: <built-in function iter>, num_leaves: 600, min_data_in_leaf: 200, WRMSSE:0.14645887752430561\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models=[] #will store models for all iterations\n",
    "predicted_values_validation=[]\n",
    "for i in range(20):\n",
    "    mod=[] #will store models for this iteration\n",
    "    print(f\"No of times remaining: {20 - (i+1)}\")\n",
    "    validation_prediction= pd.DataFrame(columns= ['id']+ f_cols)\n",
    "    test_prediction= pd.DataFrame(columns= ['id']+ f_cols)\n",
    "\n",
    "    for store in list(df_df.store_id.unique()):\n",
    "        eta= random.choice(learning_rate)\n",
    "        iterations= random.choice(num_iterations)\n",
    "        depth= random.choice(max_depth)\n",
    "        leaves= random.choice(num_leaves)\n",
    "        min_data= random.choice(min_data_in_leaf)\n",
    "        bins= random.choice(max_bins)\n",
    "\n",
    "\n",
    "        print(\"-\"*110)\n",
    "        print(f\"store {store + 1}: {store_dict[store]}, eta: {eta}, num_iterations: {iterations}, max_depth: {depth}, num_leaves: {leaves}, min_data_in_leaf: {min_data}, max_bins: {bins}\")\n",
    "        print(\"-\"*110)\n",
    "\n",
    "\n",
    "        params={\n",
    "          'objective':'poisson',\n",
    "          'metric':'rmse',\n",
    "          'force_row_wise':True,\n",
    "          'learning_rate': eta,\n",
    "          'max_bin': bins,\n",
    "          'verbosity': -1,  #with this it stops giving warnings\n",
    "          'num_iterations':iterations, \n",
    "          'num_leaves': leaves, \n",
    "          'min_data_in_leaf': min_data,\n",
    "          'max_depth': depth,\n",
    "          'n_jobs': -1\n",
    "        }\n",
    "\n",
    "        data= df_df[df_df['store_id']== store] #getting data by store\n",
    "\n",
    "        #creating train and test datasets\n",
    "        train= data[data['d'] <= 1885].drop(['id','d'], axis= 1)\n",
    "        valid= data[(data['d'] >1885) & (data['d']<1914)].drop('d', axis= 1)\n",
    "        test= data[(data['d']>= 1914) & (data['d'] <= 1941)].drop('d', axis= 1)\n",
    "\n",
    "        #getting the ids of valid and test datasets so as to sort them afterwords\n",
    "        valid_id= list(valid['id'].values)\n",
    "        test_id= list(test['id'].values)\n",
    "\n",
    "        #dropping id now \n",
    "        valid.drop('id', axis= 1, inplace= True)\n",
    "        test.drop('id', axis= 1, inplace= True)\n",
    "\n",
    "        X_train, y_train= train.drop('sales', axis= 1), train['sales']\n",
    "        X_valid, y_valid= valid.drop('sales', axis= 1), valid['sales']\n",
    "        X_test, y_test= test.drop('sales', axis= 1), test['sales']\n",
    "#         X_eval, y_eval= evaluation.drop('sales', axis= 1), evaluation['sales']\n",
    "        \n",
    "\n",
    "        # Defining categorical features\n",
    "        categories = ['item_id', 'dept_id','store_id', 'cat_id', 'state_id'] + \\\n",
    "                   [\"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\"]\n",
    "\n",
    "        trainData = lgb.Dataset(X_train, label = y_train, categorical_feature = categories, free_raw_data = False)\n",
    "        validData = lgb.Dataset(X_valid, label = y_valid, categorical_feature = categories, free_raw_data = False)\n",
    "\n",
    "        #training model\n",
    "        model = lgb.train(params, trainData, valid_sets = [trainData, validData], verbose_eval = 200, early_stopping_rounds=20)\n",
    "        mod.append(model) #appending model\n",
    "\n",
    "        #predicting validation and test data\n",
    "        valid_predict= model.predict(X_valid).reshape(-1,28)\n",
    "        valid_predict= pd.DataFrame(valid_predict, columns= f_cols)\n",
    "        valid_predict['id']= valid_id[::28] #adding ids\n",
    "        cols= ['id'] + f_cols\n",
    "        valid_predict= valid_predict[cols]\n",
    "\n",
    "        #concatinating it with larger dataset for computing WRMSSE\n",
    "        validation_prediction= pd.concat([validation_prediction, valid_predict]) \n",
    "\n",
    "\n",
    "        test_predict= model.predict(X_test).reshape(-1,28)\n",
    "        test_predict= pd.DataFrame(test_predict, columns= f_cols)\n",
    "        test_predict['id']= test_id[::28] #adding ids\n",
    "        cols= ['id'] + f_cols\n",
    "        test_predict= test_predict[cols]\n",
    "\n",
    "        #concatinating it with larger dataset for computing WRMSSE\n",
    "        test_prediction= pd.concat([test_prediction, test_predict]) \n",
    "        \n",
    "    models.append(mod)#appending all models in this iteration\n",
    "\n",
    "    #sorting them by ids \n",
    "#     validation_prediction= validation_prediction.sort_values(by= 'id')\n",
    "    validation_prediction['id']= validation_prediction['id'].apply(lambda x: id_dict[x])\n",
    "    validation_prediction= uid_df.merge(validation_prediction, on= 'id', how= 'left')\n",
    "\n",
    "#     test_prediction= test_prediction.sort_values(by= 'id')\n",
    "    test_prediction['id']= test_prediction['id'].apply(lambda x: id_dict[x])\n",
    "    test_prediction= uid_df.merge(test_prediction, on= 'id', how= 'left')\n",
    "    \n",
    "    predicted_values_validation.append(test_prediction)\n",
    "\n",
    "    print('calculating WRMSSE')\n",
    "    #calculating validation and evaluation wrmsse\n",
    "    valid_wrmsse= wrmsse(sales, validation_prediction, True)\n",
    "\n",
    "    eval_wrmsse= wrmsse(sales, test_prediction, False)\n",
    "\n",
    "    print('\\n')\n",
    "    print(\"#\"*100)\n",
    "    print(f\"for validation= \\n eta: {eta}, num_iterations: {iter}, num_leaves: {leaves}, min_data_in_leaf: {min_data}, WRMSSE:{valid_wrmsse}\")\n",
    "    print(f\"for evaluation= \\n eta: {eta}, num_iterations: {iter}, num_leaves: {leaves}, min_data_in_leaf: {min_data}, WRMSSE:{eval_wrmsse}\")\n",
    "    print(\"#\"*100)\n",
    "    print('\\n')\n",
    "    print(\"-+-\"*35)\n",
    "    print(\"-+-\"*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prediction(best_model_no, data, models):\n",
    "    '''this function will make predictions for data'''\n",
    "    prediction= pd.DataFrame(columns= ['id']+ f_cols)\n",
    "    stores= list(df_df.store_id.unique())\n",
    "    for i in range(len(stores)):\n",
    "        evals= data[data['store_id']== stores[i]]\n",
    "        X_eval= evals.drop(['sales', 'd'], axis= 1)\n",
    "        pred_ids= list(X_eval['id'].values)\n",
    "        X_eval= X_eval.drop('id', axis= 1)\n",
    "                               \n",
    "        pred= models[best_model_no][i].predict(X_eval).reshape(-1,28)\n",
    "        pred= pd.DataFrame(pred, columns=f_cols)\n",
    "        pred['id']= pred_ids[::28] #adding ids\n",
    "        cols= ['id'] + f_cols\n",
    "        pred= pred[cols]        \n",
    "        \n",
    "        prediction= pd.concat([prediction, pred]) \n",
    "        \n",
    "    prediction['id']= prediction['id'].apply(lambda x: id_dict[x])\n",
    "    prediciton= uid_df.merge(prediction, on= 'id', how= 'left')\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= df_df[(df_df['d']>= 1914) & (df_df['d'] <= 1941)]\n",
    "evaluation= df_df[df_df['d'] > 1941]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions\n",
    "test_predict= eval_prediction(0,test, models)\n",
    "eval_predict= eval_prediction(0, evaluation, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>1.880498</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>3.030398</td>\n",
       "      <td>4.621647</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>...</td>\n",
       "      <td>1.939531</td>\n",
       "      <td>4.117524</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>3.042609</td>\n",
       "      <td>3.033335</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>1.024084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>1.001732</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>1.003518</td>\n",
       "      <td>1.969140</td>\n",
       "      <td>1.001732</td>\n",
       "      <td>1.010278</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.992314</td>\n",
       "      <td>1.002797</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>1.992155</td>\n",
       "      <td>1.003484</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006051</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>1.977720</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>1.993228</td>\n",
       "      <td>2.991651</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>1.008778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>1.012975</td>\n",
       "      <td>2.047757</td>\n",
       "      <td>3.996007</td>\n",
       "      <td>1.028895</td>\n",
       "      <td>5.874891</td>\n",
       "      <td>4.003906</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992817</td>\n",
       "      <td>1.022793</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>3.868635</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>1.015019</td>\n",
       "      <td>2.850651</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>2.037276</td>\n",
       "      <td>6.078503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>0.992628</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>1.952486</td>\n",
       "      <td>3.041530</td>\n",
       "      <td>0.990624</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>3.030260</td>\n",
       "      <td>2.007784</td>\n",
       "      <td>3.055126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>2.009975</td>\n",
       "      <td>1.008902</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>2.002091</td>\n",
       "      <td>1.012737</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3044</th>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>1.878083</td>\n",
       "      <td>1.878083</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>1.878083</td>\n",
       "      <td>...</td>\n",
       "      <td>1.014884</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>2.743079</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>1.014884</td>\n",
       "      <td>1.014884</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>1.014884</td>\n",
       "      <td>1.014884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3045</th>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>1.014918</td>\n",
       "      <td>1.014918</td>\n",
       "      <td>1.014918</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>1.014918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>1.014918</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>1.014918</td>\n",
       "      <td>0.152131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3046</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>1.014943</td>\n",
       "      <td>1.014943</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>1.878205</td>\n",
       "      <td>1.014943</td>\n",
       "      <td>1.014943</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>1.014943</td>\n",
       "      <td>1.877935</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>1.014943</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>1.014943</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>1.878205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>1.014605</td>\n",
       "      <td>2.841173</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>1.014765</td>\n",
       "      <td>1.876438</td>\n",
       "      <td>1.014768</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>1.876932</td>\n",
       "      <td>1.014585</td>\n",
       "      <td>...</td>\n",
       "      <td>1.014585</td>\n",
       "      <td>1.014585</td>\n",
       "      <td>1.014585</td>\n",
       "      <td>3.617819</td>\n",
       "      <td>5.363733</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>1.014751</td>\n",
       "      <td>1.014751</td>\n",
       "      <td>1.014751</td>\n",
       "      <td>0.152131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>1.015311</td>\n",
       "      <td>1.015311</td>\n",
       "      <td>1.015311</td>\n",
       "      <td>1.883151</td>\n",
       "      <td>...</td>\n",
       "      <td>1.015311</td>\n",
       "      <td>1.883151</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>4.552305</td>\n",
       "      <td>3.595859</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>1.874514</td>\n",
       "      <td>1.874080</td>\n",
       "      <td>4.476185</td>\n",
       "      <td>1.014614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30490 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id        F1        F2        F3        F4  \\\n",
       "0     HOBBIES_1_001_CA_1_validation  0.000059  0.000059  0.000052  1.880498   \n",
       "1     HOBBIES_1_002_CA_1_validation  0.000039  1.001732  0.000040  0.000039   \n",
       "2     HOBBIES_1_003_CA_1_validation  0.000047  0.000047  0.992314  1.002797   \n",
       "3     HOBBIES_1_004_CA_1_validation  0.000061  0.000063  1.012975  2.047757   \n",
       "4     HOBBIES_1_005_CA_1_validation  0.992628  0.000073  1.952486  3.041530   \n",
       "...                             ...       ...       ...       ...       ...   \n",
       "3044    FOODS_3_823_WI_3_validation  0.152131  0.152131  0.152131  1.878083   \n",
       "3045    FOODS_3_824_WI_3_validation  0.152131  1.014918  1.014918  1.014918   \n",
       "3046    FOODS_3_825_WI_3_validation  0.152131  0.152131  1.014943  1.014943   \n",
       "3047    FOODS_3_826_WI_3_validation  1.014605  2.841173  0.152131  1.014765   \n",
       "3048    FOODS_3_827_WI_3_validation  0.152131  0.152131  0.152131  0.152131   \n",
       "\n",
       "            F5        F6        F7        F8        F9  ...       F19  \\\n",
       "0     0.000051  3.030398  4.621647  0.000068  0.000068  ...  1.939531   \n",
       "1     0.000039  0.000038  0.000038  0.000039  0.000040  ...  0.000039   \n",
       "2     0.000047  1.992155  1.003484  0.000047  0.000047  ...  1.006051   \n",
       "3     3.996007  1.028895  5.874891  4.003906  0.000054  ...  0.992817   \n",
       "4     0.990624  0.000063  3.030260  2.007784  3.055126  ...  0.000073   \n",
       "...        ...       ...       ...       ...       ...  ...       ...   \n",
       "3044  1.878083  0.152131  0.152131  0.152131  1.878083  ...  1.014884   \n",
       "3045  0.152131  0.152131  0.152131  0.152131  1.014918  ...  0.152131   \n",
       "3046  0.152131  1.878205  1.014943  1.014943  0.152131  ...  0.152131   \n",
       "3047  1.876438  1.014768  0.152131  1.876932  1.014585  ...  1.014585   \n",
       "3048  0.152131  1.015311  1.015311  1.015311  1.883151  ...  1.015311   \n",
       "\n",
       "           F20       F21       F22       F23       F24       F25       F26  \\\n",
       "0     4.117524  0.000068  0.000061  0.000059  0.000059  3.042609  3.033335   \n",
       "1     1.003518  1.969140  1.001732  1.010278  0.000039  0.000039  0.000039   \n",
       "2     0.000046  1.977720  0.000047  0.000047  0.000047  1.993228  2.991651   \n",
       "3     1.022793  0.000046  3.868635  0.000047  1.015019  2.850651  0.000048   \n",
       "4     0.000063  0.000053  2.009975  1.008902  0.000047  0.000047  2.002091   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3044  0.152131  2.743079  0.152131  1.014884  1.014884  0.152131  0.152131   \n",
       "3045  0.152131  0.152131  0.152131  0.152131  0.152131  1.014918  0.152131   \n",
       "3046  0.152131  1.014943  1.877935  0.152131  1.014943  0.152131  1.014943   \n",
       "3047  1.014585  1.014585  3.617819  5.363733  0.152131  1.014751  1.014751   \n",
       "3048  1.883151  0.152131  4.552305  3.595859  0.152131  1.874514  1.874080   \n",
       "\n",
       "           F27       F28  \n",
       "0     0.000057  1.024084  \n",
       "1     0.000039  0.000039  \n",
       "2     0.000052  1.008778  \n",
       "3     2.037276  6.078503  \n",
       "4     1.012737  0.000052  \n",
       "...        ...       ...  \n",
       "3044  1.014884  1.014884  \n",
       "3045  1.014918  0.152131  \n",
       "3046  0.152131  1.878205  \n",
       "3047  1.014751  0.152131  \n",
       "3048  4.476185  1.014614  \n",
       "\n",
       "[30490 rows x 29 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict['id']= test_predict['id'].apply(lambda x: \"_\".join(x.split(\"_\")[:-1] + ['validation']))\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= pd.concat([test_predict, eval_predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv(\"LGBM.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2522607915944221"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrmsse(sales, test_predict, False) #calculating wrmsse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective= ['poisson', 'regression']\n",
    "learning_rate= [0.005, 0.075, 0.01, 0.1]\n",
    "num_iterations= [2000, 1400, 1200, 1000, 800, 600, 400]\n",
    "max_depth= [-1, 11, 9, 7, 5, 3]\n",
    "num_leaves= [100, 150, 200, 250, 300, 400, 500, 600, 700]\n",
    "min_data_in_leaf= [100, 200, 300, 500, 1000, 2000]\n",
    "max_bins= [100, 150, 200, 250, 300, 400, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.27165\tvalid_1's rmse: 2.17013\n",
      "[400]\ttraining's rmse: 1.46259\tvalid_1's rmse: 1.38496\n",
      "[600]\ttraining's rmse: 0.994862\tvalid_1's rmse: 0.928898\n",
      "[800]\ttraining's rmse: 0.738312\tvalid_1's rmse: 0.676714\n",
      "[1000]\ttraining's rmse: 0.606972\tvalid_1's rmse: 0.54839\n",
      "[1200]\ttraining's rmse: 0.54251\tvalid_1's rmse: 0.487736\n",
      "[1400]\ttraining's rmse: 0.509136\tvalid_1's rmse: 0.458059\n",
      "[1600]\ttraining's rmse: 0.489745\tvalid_1's rmse: 0.442417\n",
      "[1800]\ttraining's rmse: 0.476561\tvalid_1's rmse: 0.434027\n",
      "[2000]\ttraining's rmse: 0.465688\tvalid_1's rmse: 0.42767\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.465688\tvalid_1's rmse: 0.42767\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.79215\tvalid_1's rmse: 1.9076\n",
      "[400]\ttraining's rmse: 1.14751\tvalid_1's rmse: 1.19339\n",
      "[600]\ttraining's rmse: 0.767424\tvalid_1's rmse: 0.774271\n",
      "[800]\ttraining's rmse: 0.55484\tvalid_1's rmse: 0.545837\n",
      "[1000]\ttraining's rmse: 0.445021\tvalid_1's rmse: 0.435856\n",
      "[1200]\ttraining's rmse: 0.390383\tvalid_1's rmse: 0.389037\n",
      "[1400]\ttraining's rmse: 0.361176\tvalid_1's rmse: 0.3688\n",
      "[1600]\ttraining's rmse: 0.344943\tvalid_1's rmse: 0.360517\n",
      "[1800]\ttraining's rmse: 0.334318\tvalid_1's rmse: 0.356152\n",
      "[2000]\ttraining's rmse: 0.325705\tvalid_1's rmse: 0.353344\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.325705\tvalid_1's rmse: 0.353344\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.43447\tvalid_1's rmse: 3.12144\n",
      "[400]\ttraining's rmse: 2.23287\tvalid_1's rmse: 1.99612\n",
      "[600]\ttraining's rmse: 1.54308\tvalid_1's rmse: 1.36161\n",
      "[800]\ttraining's rmse: 1.16698\tvalid_1's rmse: 1.02845\n",
      "[1000]\ttraining's rmse: 0.973694\tvalid_1's rmse: 0.868273\n",
      "[1200]\ttraining's rmse: 0.878555\tvalid_1's rmse: 0.798134\n",
      "[1400]\ttraining's rmse: 0.827278\tvalid_1's rmse: 0.766625\n",
      "[1600]\ttraining's rmse: 0.795451\tvalid_1's rmse: 0.752196\n",
      "[1800]\ttraining's rmse: 0.772857\tvalid_1's rmse: 0.744236\n",
      "[2000]\ttraining's rmse: 0.753652\tvalid_1's rmse: 0.739377\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.753652\tvalid_1's rmse: 0.739377\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.19734\tvalid_1's rmse: 1.1614\n",
      "[400]\ttraining's rmse: 0.760628\tvalid_1's rmse: 0.722482\n",
      "[600]\ttraining's rmse: 0.503732\tvalid_1's rmse: 0.464892\n",
      "[800]\ttraining's rmse: 0.358723\tvalid_1's rmse: 0.321411\n",
      "[1000]\ttraining's rmse: 0.281339\tvalid_1's rmse: 0.249432\n",
      "[1200]\ttraining's rmse: 0.241717\tvalid_1's rmse: 0.217894\n",
      "[1400]\ttraining's rmse: 0.221549\tvalid_1's rmse: 0.205854\n",
      "[1600]\ttraining's rmse: 0.210066\tvalid_1's rmse: 0.201254\n",
      "[1800]\ttraining's rmse: 0.200146\tvalid_1's rmse: 0.199038\n",
      "[2000]\ttraining's rmse: 0.19265\tvalid_1's rmse: 0.197305\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.19265\tvalid_1's rmse: 0.197305\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.85577\tvalid_1's rmse: 1.89223\n",
      "[400]\ttraining's rmse: 1.1877\tvalid_1's rmse: 1.17774\n",
      "[600]\ttraining's rmse: 0.797917\tvalid_1's rmse: 0.756395\n",
      "[800]\ttraining's rmse: 0.582332\tvalid_1's rmse: 0.520836\n",
      "[1000]\ttraining's rmse: 0.469655\tvalid_1's rmse: 0.402248\n",
      "[1200]\ttraining's rmse: 0.411279\tvalid_1's rmse: 0.350495\n",
      "[1400]\ttraining's rmse: 0.379672\tvalid_1's rmse: 0.332339\n",
      "[1600]\ttraining's rmse: 0.360113\tvalid_1's rmse: 0.325018\n",
      "[1800]\ttraining's rmse: 0.34494\tvalid_1's rmse: 0.321398\n",
      "Early stopping, best iteration is:\n",
      "[1794]\ttraining's rmse: 0.345422\tvalid_1's rmse: 0.321321\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.39112\tvalid_1's rmse: 2.16312\n",
      "[400]\ttraining's rmse: 1.55877\tvalid_1's rmse: 1.34339\n",
      "[600]\ttraining's rmse: 1.07941\tvalid_1's rmse: 0.87082\n",
      "[800]\ttraining's rmse: 0.819056\tvalid_1's rmse: 0.621049\n",
      "[1000]\ttraining's rmse: 0.687074\tvalid_1's rmse: 0.50519\n",
      "[1200]\ttraining's rmse: 0.619868\tvalid_1's rmse: 0.458556\n",
      "[1400]\ttraining's rmse: 0.581867\tvalid_1's rmse: 0.441617\n",
      "[1600]\ttraining's rmse: 0.557112\tvalid_1's rmse: 0.436065\n",
      "[1800]\ttraining's rmse: 0.538078\tvalid_1's rmse: 0.433333\n",
      "[2000]\ttraining's rmse: 0.522432\tvalid_1's rmse: 0.431408\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.522432\tvalid_1's rmse: 0.431408\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.27487\tvalid_1's rmse: 2.02119\n",
      "[400]\ttraining's rmse: 1.46646\tvalid_1's rmse: 1.25998\n",
      "[600]\ttraining's rmse: 1.00161\tvalid_1's rmse: 0.822251\n",
      "[800]\ttraining's rmse: 0.750446\tvalid_1's rmse: 0.589628\n",
      "[1000]\ttraining's rmse: 0.624154\tvalid_1's rmse: 0.481191\n",
      "[1200]\ttraining's rmse: 0.562899\tvalid_1's rmse: 0.438023\n",
      "[1400]\ttraining's rmse: 0.531347\tvalid_1's rmse: 0.423313\n",
      "[1600]\ttraining's rmse: 0.512829\tvalid_1's rmse: 0.418639\n",
      "[1800]\ttraining's rmse: 0.500136\tvalid_1's rmse: 0.41736\n",
      "Early stopping, best iteration is:\n",
      "[1896]\ttraining's rmse: 0.494962\tvalid_1's rmse: 0.416872\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.59325\tvalid_1's rmse: 1.55417\n",
      "[400]\ttraining's rmse: 1.00254\tvalid_1's rmse: 0.963997\n",
      "[600]\ttraining's rmse: 0.652492\tvalid_1's rmse: 0.61295\n",
      "[800]\ttraining's rmse: 0.453264\tvalid_1's rmse: 0.413246\n",
      "[1000]\ttraining's rmse: 0.346876\tvalid_1's rmse: 0.308021\n",
      "[1200]\ttraining's rmse: 0.293737\tvalid_1's rmse: 0.25751\n",
      "[1400]\ttraining's rmse: 0.267643\tvalid_1's rmse: 0.234874\n",
      "[1600]\ttraining's rmse: 0.253869\tvalid_1's rmse: 0.224566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1800]\ttraining's rmse: 0.245424\tvalid_1's rmse: 0.219354\n",
      "[2000]\ttraining's rmse: 0.23942\tvalid_1's rmse: 0.216193\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.23942\tvalid_1's rmse: 0.216193\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.56081\tvalid_1's rmse: 3.02288\n",
      "[400]\ttraining's rmse: 1.63257\tvalid_1's rmse: 1.87363\n",
      "[600]\ttraining's rmse: 1.08518\tvalid_1's rmse: 1.21198\n",
      "[800]\ttraining's rmse: 0.776271\tvalid_1's rmse: 0.872922\n",
      "[1000]\ttraining's rmse: 0.611445\tvalid_1's rmse: 0.719887\n",
      "[1200]\ttraining's rmse: 0.527709\tvalid_1's rmse: 0.663532\n",
      "[1400]\ttraining's rmse: 0.485545\tvalid_1's rmse: 0.648948\n",
      "[1600]\ttraining's rmse: 0.461487\tvalid_1's rmse: 0.641203\n",
      "[1800]\ttraining's rmse: 0.4454\tvalid_1's rmse: 0.637639\n",
      "Early stopping, best iteration is:\n",
      "[1928]\ttraining's rmse: 0.437297\tvalid_1's rmse: 0.634743\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.19482\tvalid_1's rmse: 2.35889\n",
      "[400]\ttraining's rmse: 1.41593\tvalid_1's rmse: 1.4799\n",
      "[600]\ttraining's rmse: 0.967609\tvalid_1's rmse: 0.974543\n",
      "[800]\ttraining's rmse: 0.723028\tvalid_1's rmse: 0.706687\n",
      "[1000]\ttraining's rmse: 0.598527\tvalid_1's rmse: 0.581082\n",
      "[1200]\ttraining's rmse: 0.537214\tvalid_1's rmse: 0.531936\n",
      "[1400]\ttraining's rmse: 0.505091\tvalid_1's rmse: 0.514518\n",
      "[1600]\ttraining's rmse: 0.486424\tvalid_1's rmse: 0.509375\n",
      "Early stopping, best iteration is:\n",
      "[1609]\ttraining's rmse: 0.485789\tvalid_1's rmse: 0.509258\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 100, max_bins: 100, WRMSSE:0.06079583248891138\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 100, max_bins: 100, WRMSSE:0.06524191653785139\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "1\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.26129\tvalid_1's rmse: 2.17151\n",
      "[400]\ttraining's rmse: 1.44015\tvalid_1's rmse: 1.38441\n",
      "[600]\ttraining's rmse: 0.959496\tvalid_1's rmse: 0.923824\n",
      "[800]\ttraining's rmse: 0.690195\tvalid_1's rmse: 0.664182\n",
      "[1000]\ttraining's rmse: 0.549471\tvalid_1's rmse: 0.52711\n",
      "[1200]\ttraining's rmse: 0.479621\tvalid_1's rmse: 0.457546\n",
      "[1400]\ttraining's rmse: 0.444373\tvalid_1's rmse: 0.422838\n",
      "[1600]\ttraining's rmse: 0.424754\tvalid_1's rmse: 0.404586\n",
      "[1800]\ttraining's rmse: 0.41154\tvalid_1's rmse: 0.394538\n",
      "[2000]\ttraining's rmse: 0.40142\tvalid_1's rmse: 0.38824\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.40142\tvalid_1's rmse: 0.38824\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.78528\tvalid_1's rmse: 1.90323\n",
      "[400]\ttraining's rmse: 1.13354\tvalid_1's rmse: 1.18077\n",
      "[600]\ttraining's rmse: 0.744513\tvalid_1's rmse: 0.75145\n",
      "[800]\ttraining's rmse: 0.521653\tvalid_1's rmse: 0.508421\n",
      "[1000]\ttraining's rmse: 0.402758\tvalid_1's rmse: 0.381379\n",
      "[1200]\ttraining's rmse: 0.342335\tvalid_1's rmse: 0.321848\n",
      "[1400]\ttraining's rmse: 0.310936\tvalid_1's rmse: 0.29622\n",
      "[1600]\ttraining's rmse: 0.293293\tvalid_1's rmse: 0.284751\n",
      "[1800]\ttraining's rmse: 0.282568\tvalid_1's rmse: 0.279217\n",
      "[2000]\ttraining's rmse: 0.27442\tvalid_1's rmse: 0.27649\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.27442\tvalid_1's rmse: 0.27649\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.41888\tvalid_1's rmse: 3.09317\n",
      "[400]\ttraining's rmse: 2.19914\tvalid_1's rmse: 1.94516\n",
      "[600]\ttraining's rmse: 1.48886\tvalid_1's rmse: 1.28953\n",
      "[800]\ttraining's rmse: 1.09577\tvalid_1's rmse: 0.941626\n",
      "[1000]\ttraining's rmse: 0.890311\tvalid_1's rmse: 0.774439\n",
      "[1200]\ttraining's rmse: 0.788036\tvalid_1's rmse: 0.703765\n",
      "[1400]\ttraining's rmse: 0.734538\tvalid_1's rmse: 0.675879\n",
      "[1600]\ttraining's rmse: 0.702554\tvalid_1's rmse: 0.665826\n",
      "[1800]\ttraining's rmse: 0.681201\tvalid_1's rmse: 0.660303\n",
      "[2000]\ttraining's rmse: 0.664607\tvalid_1's rmse: 0.656518\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.664607\tvalid_1's rmse: 0.656518\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.19447\tvalid_1's rmse: 1.16327\n",
      "[400]\ttraining's rmse: 0.753885\tvalid_1's rmse: 0.723106\n",
      "[600]\ttraining's rmse: 0.492921\tvalid_1's rmse: 0.459962\n",
      "[800]\ttraining's rmse: 0.342966\tvalid_1's rmse: 0.307143\n",
      "[1000]\ttraining's rmse: 0.260794\tvalid_1's rmse: 0.223316\n",
      "[1200]\ttraining's rmse: 0.217289\tvalid_1's rmse: 0.181106\n",
      "[1400]\ttraining's rmse: 0.194566\tvalid_1's rmse: 0.161869\n",
      "[1600]\ttraining's rmse: 0.181983\tvalid_1's rmse: 0.153405\n",
      "[1800]\ttraining's rmse: 0.171283\tvalid_1's rmse: 0.149048\n",
      "[2000]\ttraining's rmse: 0.163365\tvalid_1's rmse: 0.146755\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.163365\tvalid_1's rmse: 0.146755\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.84779\tvalid_1's rmse: 1.88577\n",
      "[400]\ttraining's rmse: 1.17016\tvalid_1's rmse: 1.16624\n",
      "[600]\ttraining's rmse: 0.771143\tvalid_1's rmse: 0.742046\n",
      "[800]\ttraining's rmse: 0.545779\tvalid_1's rmse: 0.500838\n",
      "[1000]\ttraining's rmse: 0.42518\tvalid_1's rmse: 0.375524\n",
      "[1200]\ttraining's rmse: 0.361902\tvalid_1's rmse: 0.316377\n",
      "[1400]\ttraining's rmse: 0.327924\tvalid_1's rmse: 0.292631\n",
      "[1600]\ttraining's rmse: 0.307486\tvalid_1's rmse: 0.28221\n",
      "[1800]\ttraining's rmse: 0.291539\tvalid_1's rmse: 0.274646\n",
      "Early stopping, best iteration is:\n",
      "[1862]\ttraining's rmse: 0.287181\tvalid_1's rmse: 0.273828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.37531\tvalid_1's rmse: 2.17529\n",
      "[400]\ttraining's rmse: 1.52642\tvalid_1's rmse: 1.3541\n",
      "[600]\ttraining's rmse: 1.03008\tvalid_1's rmse: 0.872589\n",
      "[800]\ttraining's rmse: 0.754244\tvalid_1's rmse: 0.603798\n",
      "[1000]\ttraining's rmse: 0.609927\tvalid_1's rmse: 0.464277\n",
      "[1200]\ttraining's rmse: 0.535921\tvalid_1's rmse: 0.398893\n",
      "[1400]\ttraining's rmse: 0.494629\tvalid_1's rmse: 0.371096\n",
      "[1600]\ttraining's rmse: 0.468929\tvalid_1's rmse: 0.359483\n",
      "[1800]\ttraining's rmse: 0.44881\tvalid_1's rmse: 0.352687\n",
      "[2000]\ttraining's rmse: 0.433174\tvalid_1's rmse: 0.349726\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.433174\tvalid_1's rmse: 0.349726\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.25992\tvalid_1's rmse: 2.03065\n",
      "[400]\ttraining's rmse: 1.43422\tvalid_1's rmse: 1.27412\n",
      "[600]\ttraining's rmse: 0.948901\tvalid_1's rmse: 0.831182\n",
      "[800]\ttraining's rmse: 0.678705\tvalid_1's rmse: 0.587691\n",
      "[1000]\ttraining's rmse: 0.537623\tvalid_1's rmse: 0.46489\n",
      "[1200]\ttraining's rmse: 0.467616\tvalid_1's rmse: 0.408399\n",
      "[1400]\ttraining's rmse: 0.432492\tvalid_1's rmse: 0.38383\n",
      "[1600]\ttraining's rmse: 0.412834\tvalid_1's rmse: 0.373373\n",
      "[1800]\ttraining's rmse: 0.399811\tvalid_1's rmse: 0.368207\n",
      "[2000]\ttraining's rmse: 0.389867\tvalid_1's rmse: 0.365318\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.389867\tvalid_1's rmse: 0.365318\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.58928\tvalid_1's rmse: 1.5585\n",
      "[400]\ttraining's rmse: 0.993683\tvalid_1's rmse: 0.968862\n",
      "[600]\ttraining's rmse: 0.637968\tvalid_1's rmse: 0.616786\n",
      "[800]\ttraining's rmse: 0.43194\tvalid_1's rmse: 0.412739\n",
      "[1000]\ttraining's rmse: 0.318457\tvalid_1's rmse: 0.300243\n",
      "[1200]\ttraining's rmse: 0.259637\tvalid_1's rmse: 0.242749\n",
      "[1400]\ttraining's rmse: 0.229905\tvalid_1's rmse: 0.215021\n",
      "[1600]\ttraining's rmse: 0.214341\tvalid_1's rmse: 0.201833\n",
      "[1800]\ttraining's rmse: 0.205176\tvalid_1's rmse: 0.195325\n",
      "[2000]\ttraining's rmse: 0.198486\tvalid_1's rmse: 0.191331\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.198486\tvalid_1's rmse: 0.191331\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.55329\tvalid_1's rmse: 3.07659\n",
      "[400]\ttraining's rmse: 1.61537\tvalid_1's rmse: 1.94444\n",
      "[600]\ttraining's rmse: 1.05467\tvalid_1's rmse: 1.26517\n",
      "[800]\ttraining's rmse: 0.731027\tvalid_1's rmse: 0.879629\n",
      "[1000]\ttraining's rmse: 0.55316\tvalid_1's rmse: 0.674054\n",
      "[1200]\ttraining's rmse: 0.46071\tvalid_1's rmse: 0.573501\n",
      "[1400]\ttraining's rmse: 0.412796\tvalid_1's rmse: 0.526494\n",
      "[1600]\ttraining's rmse: 0.386829\tvalid_1's rmse: 0.504454\n",
      "[1800]\ttraining's rmse: 0.369887\tvalid_1's rmse: 0.493122\n",
      "[2000]\ttraining's rmse: 0.35746\tvalid_1's rmse: 0.486679\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.35746\tvalid_1's rmse: 0.486679\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.18307\tvalid_1's rmse: 2.37023\n",
      "[400]\ttraining's rmse: 1.3906\tvalid_1's rmse: 1.49033\n",
      "[600]\ttraining's rmse: 0.927791\tvalid_1's rmse: 0.972268\n",
      "[800]\ttraining's rmse: 0.669549\tvalid_1's rmse: 0.6816\n",
      "[1000]\ttraining's rmse: 0.534516\tvalid_1's rmse: 0.53171\n",
      "[1200]\ttraining's rmse: 0.467263\tvalid_1's rmse: 0.463063\n",
      "[1400]\ttraining's rmse: 0.432661\tvalid_1's rmse: 0.433552\n",
      "[1600]\ttraining's rmse: 0.412837\tvalid_1's rmse: 0.423002\n",
      "[1800]\ttraining's rmse: 0.39912\tvalid_1's rmse: 0.418151\n",
      "Early stopping, best iteration is:\n",
      "[1950]\ttraining's rmse: 0.390169\tvalid_1's rmse: 0.41644\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 100, max_bins: 150, WRMSSE:0.05131149215001155\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 100, max_bins: 150, WRMSSE:0.05365099919627782\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "2\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.25455\tvalid_1's rmse: 2.16048\n",
      "[400]\ttraining's rmse: 1.4258\tvalid_1's rmse: 1.36542\n",
      "[600]\ttraining's rmse: 0.934925\tvalid_1's rmse: 0.898715\n",
      "[800]\ttraining's rmse: 0.654921\tvalid_1's rmse: 0.634691\n",
      "[1000]\ttraining's rmse: 0.504757\tvalid_1's rmse: 0.495076\n",
      "[1200]\ttraining's rmse: 0.428469\tvalid_1's rmse: 0.426541\n",
      "[1400]\ttraining's rmse: 0.390185\tvalid_1's rmse: 0.393944\n",
      "[1600]\ttraining's rmse: 0.369562\tvalid_1's rmse: 0.37804\n",
      "[1800]\ttraining's rmse: 0.356277\tvalid_1's rmse: 0.370016\n",
      "[2000]\ttraining's rmse: 0.346344\tvalid_1's rmse: 0.364495\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.346344\tvalid_1's rmse: 0.364495\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.78069\tvalid_1's rmse: 1.90238\n",
      "[400]\ttraining's rmse: 1.12148\tvalid_1's rmse: 1.1715\n",
      "[600]\ttraining's rmse: 0.726027\tvalid_1's rmse: 0.731254\n",
      "[800]\ttraining's rmse: 0.49614\tvalid_1's rmse: 0.475942\n",
      "[1000]\ttraining's rmse: 0.370594\tvalid_1's rmse: 0.337568\n",
      "[1200]\ttraining's rmse: 0.305061\tvalid_1's rmse: 0.269727\n",
      "[1400]\ttraining's rmse: 0.270688\tvalid_1's rmse: 0.239891\n",
      "[1600]\ttraining's rmse: 0.251535\tvalid_1's rmse: 0.227735\n",
      "[1800]\ttraining's rmse: 0.239672\tvalid_1's rmse: 0.222514\n",
      "[2000]\ttraining's rmse: 0.231206\tvalid_1's rmse: 0.220101\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.231206\tvalid_1's rmse: 0.220101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.40955\tvalid_1's rmse: 3.09746\n",
      "[400]\ttraining's rmse: 2.17993\tvalid_1's rmse: 1.94793\n",
      "[600]\ttraining's rmse: 1.45756\tvalid_1's rmse: 1.28362\n",
      "[800]\ttraining's rmse: 1.05241\tvalid_1's rmse: 0.92082\n",
      "[1000]\ttraining's rmse: 0.837899\tvalid_1's rmse: 0.738128\n",
      "[1200]\ttraining's rmse: 0.729524\tvalid_1's rmse: 0.653311\n",
      "[1400]\ttraining's rmse: 0.673077\tvalid_1's rmse: 0.615594\n",
      "[1600]\ttraining's rmse: 0.640368\tvalid_1's rmse: 0.599379\n",
      "[1800]\ttraining's rmse: 0.61836\tvalid_1's rmse: 0.590607\n",
      "[2000]\ttraining's rmse: 0.602057\tvalid_1's rmse: 0.584843\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.602057\tvalid_1's rmse: 0.584843\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.19227\tvalid_1's rmse: 1.16207\n",
      "[400]\ttraining's rmse: 0.74897\tvalid_1's rmse: 0.719682\n",
      "[600]\ttraining's rmse: 0.484724\tvalid_1's rmse: 0.453892\n",
      "[800]\ttraining's rmse: 0.331072\tvalid_1's rmse: 0.297572\n",
      "[1000]\ttraining's rmse: 0.245619\tvalid_1's rmse: 0.210192\n",
      "[1200]\ttraining's rmse: 0.199883\tvalid_1's rmse: 0.164863\n",
      "[1400]\ttraining's rmse: 0.175768\tvalid_1's rmse: 0.143534\n",
      "[1600]\ttraining's rmse: 0.16214\tvalid_1's rmse: 0.13404\n",
      "[1800]\ttraining's rmse: 0.150165\tvalid_1's rmse: 0.129438\n",
      "[2000]\ttraining's rmse: 0.141296\tvalid_1's rmse: 0.126856\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.141296\tvalid_1's rmse: 0.126856\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.84296\tvalid_1's rmse: 1.88557\n",
      "[400]\ttraining's rmse: 1.16022\tvalid_1's rmse: 1.1642\n",
      "[600]\ttraining's rmse: 0.7548\tvalid_1's rmse: 0.732444\n",
      "[800]\ttraining's rmse: 0.521653\tvalid_1's rmse: 0.478301\n",
      "[1000]\ttraining's rmse: 0.394299\tvalid_1's rmse: 0.337298\n",
      "[1200]\ttraining's rmse: 0.326285\tvalid_1's rmse: 0.261966\n",
      "[1400]\ttraining's rmse: 0.289548\tvalid_1's rmse: 0.228214\n",
      "[1600]\ttraining's rmse: 0.267872\tvalid_1's rmse: 0.21253\n",
      "[1800]\ttraining's rmse: 0.251787\tvalid_1's rmse: 0.202257\n",
      "Early stopping, best iteration is:\n",
      "[1959]\ttraining's rmse: 0.241015\tvalid_1's rmse: 0.199232\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.36576\tvalid_1's rmse: 2.17452\n",
      "[400]\ttraining's rmse: 1.50698\tvalid_1's rmse: 1.34706\n",
      "[600]\ttraining's rmse: 0.999182\tvalid_1's rmse: 0.853915\n",
      "[800]\ttraining's rmse: 0.712236\tvalid_1's rmse: 0.57041\n",
      "[1000]\ttraining's rmse: 0.55901\tvalid_1's rmse: 0.41556\n",
      "[1200]\ttraining's rmse: 0.479688\tvalid_1's rmse: 0.33693\n",
      "[1400]\ttraining's rmse: 0.436112\tvalid_1's rmse: 0.299682\n",
      "[1600]\ttraining's rmse: 0.409543\tvalid_1's rmse: 0.282822\n",
      "[1800]\ttraining's rmse: 0.389512\tvalid_1's rmse: 0.274352\n",
      "[2000]\ttraining's rmse: 0.374086\tvalid_1's rmse: 0.270388\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.374086\tvalid_1's rmse: 0.270388\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.25286\tvalid_1's rmse: 2.02336\n",
      "[400]\ttraining's rmse: 1.41944\tvalid_1's rmse: 1.25833\n",
      "[600]\ttraining's rmse: 0.924395\tvalid_1's rmse: 0.805048\n",
      "[800]\ttraining's rmse: 0.64229\tvalid_1's rmse: 0.549499\n",
      "[1000]\ttraining's rmse: 0.491505\tvalid_1's rmse: 0.417452\n",
      "[1200]\ttraining's rmse: 0.415057\tvalid_1's rmse: 0.355926\n",
      "[1400]\ttraining's rmse: 0.376831\tvalid_1's rmse: 0.329327\n",
      "[1600]\ttraining's rmse: 0.356093\tvalid_1's rmse: 0.318329\n",
      "[1800]\ttraining's rmse: 0.343202\tvalid_1's rmse: 0.313349\n",
      "[2000]\ttraining's rmse: 0.3339\tvalid_1's rmse: 0.310905\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.3339\tvalid_1's rmse: 0.310905\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.58727\tvalid_1's rmse: 1.56162\n",
      "[400]\ttraining's rmse: 0.989097\tvalid_1's rmse: 0.972322\n",
      "[600]\ttraining's rmse: 0.630237\tvalid_1's rmse: 0.617866\n",
      "[800]\ttraining's rmse: 0.420313\tvalid_1's rmse: 0.407967\n",
      "[1000]\ttraining's rmse: 0.303052\tvalid_1's rmse: 0.287519\n",
      "[1200]\ttraining's rmse: 0.241306\tvalid_1's rmse: 0.222047\n",
      "[1400]\ttraining's rmse: 0.210036\tvalid_1's rmse: 0.188554\n",
      "[1600]\ttraining's rmse: 0.193821\tvalid_1's rmse: 0.171902\n",
      "[1800]\ttraining's rmse: 0.18455\tvalid_1's rmse: 0.163239\n",
      "[2000]\ttraining's rmse: 0.178052\tvalid_1's rmse: 0.158429\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.178052\tvalid_1's rmse: 0.158429\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.55232\tvalid_1's rmse: 3.07422\n",
      "[400]\ttraining's rmse: 1.61161\tvalid_1's rmse: 1.93437\n",
      "[600]\ttraining's rmse: 1.04539\tvalid_1's rmse: 1.242\n",
      "[800]\ttraining's rmse: 0.715846\tvalid_1's rmse: 0.842037\n",
      "[1000]\ttraining's rmse: 0.532388\tvalid_1's rmse: 0.624191\n",
      "[1200]\ttraining's rmse: 0.435579\tvalid_1's rmse: 0.515482\n",
      "[1400]\ttraining's rmse: 0.384829\tvalid_1's rmse: 0.46417\n",
      "[1600]\ttraining's rmse: 0.356916\tvalid_1's rmse: 0.440984\n",
      "[1800]\ttraining's rmse: 0.338677\tvalid_1's rmse: 0.429281\n",
      "[2000]\ttraining's rmse: 0.32584\tvalid_1's rmse: 0.423642\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.32584\tvalid_1's rmse: 0.423642\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.17436\tvalid_1's rmse: 2.36731\n",
      "[400]\ttraining's rmse: 1.37217\tvalid_1's rmse: 1.48262\n",
      "[600]\ttraining's rmse: 0.898531\tvalid_1's rmse: 0.954803\n",
      "[800]\ttraining's rmse: 0.62945\tvalid_1's rmse: 0.65152\n",
      "[1000]\ttraining's rmse: 0.485738\tvalid_1's rmse: 0.488831\n",
      "[1200]\ttraining's rmse: 0.413415\tvalid_1's rmse: 0.408871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1400]\ttraining's rmse: 0.377042\tvalid_1's rmse: 0.373837\n",
      "[1600]\ttraining's rmse: 0.356863\tvalid_1's rmse: 0.359664\n",
      "[1800]\ttraining's rmse: 0.343302\tvalid_1's rmse: 0.354083\n",
      "[2000]\ttraining's rmse: 0.332047\tvalid_1's rmse: 0.351705\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.332047\tvalid_1's rmse: 0.351705\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 100, max_bins: 200, WRMSSE:0.04372013449301825\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 100, max_bins: 200, WRMSSE:0.04657830721340488\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "3\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.25169\tvalid_1's rmse: 2.16003\n",
      "[400]\ttraining's rmse: 1.41742\tvalid_1's rmse: 1.3638\n",
      "[600]\ttraining's rmse: 0.921737\tvalid_1's rmse: 0.894156\n",
      "[800]\ttraining's rmse: 0.634673\tvalid_1's rmse: 0.623826\n",
      "[1000]\ttraining's rmse: 0.478389\tvalid_1's rmse: 0.478032\n",
      "[1200]\ttraining's rmse: 0.397559\tvalid_1's rmse: 0.404242\n",
      "[1400]\ttraining's rmse: 0.356491\tvalid_1's rmse: 0.368051\n",
      "[1600]\ttraining's rmse: 0.334419\tvalid_1's rmse: 0.350158\n",
      "[1800]\ttraining's rmse: 0.320011\tvalid_1's rmse: 0.339146\n",
      "[2000]\ttraining's rmse: 0.309099\tvalid_1's rmse: 0.331735\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.309099\tvalid_1's rmse: 0.331735\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.77788\tvalid_1's rmse: 1.897\n",
      "[400]\ttraining's rmse: 1.1162\tvalid_1's rmse: 1.16302\n",
      "[600]\ttraining's rmse: 0.716659\tvalid_1's rmse: 0.71608\n",
      "[800]\ttraining's rmse: 0.482693\tvalid_1's rmse: 0.456569\n",
      "[1000]\ttraining's rmse: 0.35282\tvalid_1's rmse: 0.315436\n",
      "[1200]\ttraining's rmse: 0.284259\tvalid_1's rmse: 0.24715\n",
      "[1400]\ttraining's rmse: 0.248722\tvalid_1's rmse: 0.219011\n",
      "[1600]\ttraining's rmse: 0.228597\tvalid_1's rmse: 0.208877\n",
      "[1800]\ttraining's rmse: 0.216191\tvalid_1's rmse: 0.205454\n",
      "Early stopping, best iteration is:\n",
      "[1928]\ttraining's rmse: 0.210371\tvalid_1's rmse: 0.204696\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.40602\tvalid_1's rmse: 3.08562\n",
      "[400]\ttraining's rmse: 2.17016\tvalid_1's rmse: 1.92611\n",
      "[600]\ttraining's rmse: 1.44139\tvalid_1's rmse: 1.25523\n",
      "[800]\ttraining's rmse: 1.03104\tvalid_1's rmse: 0.890799\n",
      "[1000]\ttraining's rmse: 0.811229\tvalid_1's rmse: 0.709893\n",
      "[1200]\ttraining's rmse: 0.699402\tvalid_1's rmse: 0.628868\n",
      "[1400]\ttraining's rmse: 0.640294\tvalid_1's rmse: 0.594171\n",
      "[1600]\ttraining's rmse: 0.606252\tvalid_1's rmse: 0.581006\n",
      "[1800]\ttraining's rmse: 0.583828\tvalid_1's rmse: 0.574028\n",
      "[2000]\ttraining's rmse: 0.567029\tvalid_1's rmse: 0.569337\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.567029\tvalid_1's rmse: 0.569337\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.19117\tvalid_1's rmse: 1.16023\n",
      "[400]\ttraining's rmse: 0.745249\tvalid_1's rmse: 0.716367\n",
      "[600]\ttraining's rmse: 0.478226\tvalid_1's rmse: 0.449789\n",
      "[800]\ttraining's rmse: 0.322004\tvalid_1's rmse: 0.293962\n",
      "[1000]\ttraining's rmse: 0.234109\tvalid_1's rmse: 0.207791\n",
      "[1200]\ttraining's rmse: 0.187014\tvalid_1's rmse: 0.165272\n",
      "[1400]\ttraining's rmse: 0.162029\tvalid_1's rmse: 0.146963\n",
      "[1600]\ttraining's rmse: 0.148407\tvalid_1's rmse: 0.139571\n",
      "[1800]\ttraining's rmse: 0.1377\tvalid_1's rmse: 0.136695\n",
      "[2000]\ttraining's rmse: 0.128858\tvalid_1's rmse: 0.135452\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.128858\tvalid_1's rmse: 0.135452\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.83965\tvalid_1's rmse: 1.88362\n",
      "[400]\ttraining's rmse: 1.15333\tvalid_1's rmse: 1.16197\n",
      "[600]\ttraining's rmse: 0.743304\tvalid_1's rmse: 0.72951\n",
      "[800]\ttraining's rmse: 0.504721\tvalid_1's rmse: 0.474274\n",
      "[1000]\ttraining's rmse: 0.371981\tvalid_1's rmse: 0.332114\n",
      "[1200]\ttraining's rmse: 0.30079\tvalid_1's rmse: 0.257559\n",
      "[1400]\ttraining's rmse: 0.262053\tvalid_1's rmse: 0.223815\n",
      "[1600]\ttraining's rmse: 0.23957\tvalid_1's rmse: 0.208887\n",
      "[1800]\ttraining's rmse: 0.223581\tvalid_1's rmse: 0.199475\n",
      "[2000]\ttraining's rmse: 0.210325\tvalid_1's rmse: 0.195802\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.210325\tvalid_1's rmse: 0.195802\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.36043\tvalid_1's rmse: 2.16441\n",
      "[400]\ttraining's rmse: 1.49421\tvalid_1's rmse: 1.33009\n",
      "[600]\ttraining's rmse: 0.977776\tvalid_1's rmse: 0.831161\n",
      "[800]\ttraining's rmse: 0.681414\tvalid_1's rmse: 0.543304\n",
      "[1000]\ttraining's rmse: 0.519163\tvalid_1's rmse: 0.38525\n",
      "[1200]\ttraining's rmse: 0.433434\tvalid_1's rmse: 0.306207\n",
      "[1400]\ttraining's rmse: 0.384959\tvalid_1's rmse: 0.2707\n",
      "[1600]\ttraining's rmse: 0.3563\tvalid_1's rmse: 0.25537\n",
      "[1800]\ttraining's rmse: 0.33543\tvalid_1's rmse: 0.248712\n",
      "[2000]\ttraining's rmse: 0.320099\tvalid_1's rmse: 0.245403\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.320099\tvalid_1's rmse: 0.245403\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.25358\tvalid_1's rmse: 2.02177\n",
      "[400]\ttraining's rmse: 1.41955\tvalid_1's rmse: 1.25393\n",
      "[600]\ttraining's rmse: 0.922711\tvalid_1's rmse: 0.796186\n",
      "[800]\ttraining's rmse: 0.638191\tvalid_1's rmse: 0.532045\n",
      "[1000]\ttraining's rmse: 0.483475\tvalid_1's rmse: 0.38883\n",
      "[1200]\ttraining's rmse: 0.402981\tvalid_1's rmse: 0.317755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1400]\ttraining's rmse: 0.361595\tvalid_1's rmse: 0.284911\n",
      "[1600]\ttraining's rmse: 0.337642\tvalid_1's rmse: 0.27028\n",
      "[1800]\ttraining's rmse: 0.321009\tvalid_1's rmse: 0.262859\n",
      "[2000]\ttraining's rmse: 0.30951\tvalid_1's rmse: 0.258753\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.30951\tvalid_1's rmse: 0.258753\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.58535\tvalid_1's rmse: 1.55202\n",
      "[400]\ttraining's rmse: 0.984935\tvalid_1's rmse: 0.956172\n",
      "[600]\ttraining's rmse: 0.62313\tvalid_1's rmse: 0.596191\n",
      "[800]\ttraining's rmse: 0.409387\tvalid_1's rmse: 0.381478\n",
      "[1000]\ttraining's rmse: 0.288119\tvalid_1's rmse: 0.257711\n",
      "[1200]\ttraining's rmse: 0.223099\tvalid_1's rmse: 0.190546\n",
      "[1400]\ttraining's rmse: 0.189788\tvalid_1's rmse: 0.157324\n",
      "[1600]\ttraining's rmse: 0.172587\tvalid_1's rmse: 0.14171\n",
      "[1800]\ttraining's rmse: 0.16283\tvalid_1's rmse: 0.134297\n",
      "[2000]\ttraining's rmse: 0.156059\tvalid_1's rmse: 0.13004\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.156059\tvalid_1's rmse: 0.13004\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.55079\tvalid_1's rmse: 3.07024\n",
      "[400]\ttraining's rmse: 1.60673\tvalid_1's rmse: 1.92306\n",
      "[600]\ttraining's rmse: 1.03706\tvalid_1's rmse: 1.22659\n",
      "[800]\ttraining's rmse: 0.702959\tvalid_1's rmse: 0.821005\n",
      "[1000]\ttraining's rmse: 0.514555\tvalid_1's rmse: 0.599409\n",
      "[1200]\ttraining's rmse: 0.414033\tvalid_1's rmse: 0.489949\n",
      "[1400]\ttraining's rmse: 0.361143\tvalid_1's rmse: 0.439248\n",
      "[1600]\ttraining's rmse: 0.331953\tvalid_1's rmse: 0.415989\n",
      "[1800]\ttraining's rmse: 0.313488\tvalid_1's rmse: 0.404353\n",
      "[2000]\ttraining's rmse: 0.300499\tvalid_1's rmse: 0.398332\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.300499\tvalid_1's rmse: 0.398332\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.17063\tvalid_1's rmse: 2.35226\n",
      "[400]\ttraining's rmse: 1.36345\tvalid_1's rmse: 1.45641\n",
      "[600]\ttraining's rmse: 0.884578\tvalid_1's rmse: 0.925125\n",
      "[800]\ttraining's rmse: 0.609436\tvalid_1's rmse: 0.622152\n",
      "[1000]\ttraining's rmse: 0.460205\tvalid_1's rmse: 0.463449\n",
      "[1200]\ttraining's rmse: 0.383744\tvalid_1's rmse: 0.388923\n",
      "[1400]\ttraining's rmse: 0.34532\tvalid_1's rmse: 0.3575\n",
      "[1600]\ttraining's rmse: 0.324482\tvalid_1's rmse: 0.343847\n",
      "[1800]\ttraining's rmse: 0.310981\tvalid_1's rmse: 0.338041\n",
      "[2000]\ttraining's rmse: 0.299987\tvalid_1's rmse: 0.335819\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.299987\tvalid_1's rmse: 0.335819\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 100, max_bins: 250, WRMSSE:0.03970942852931817\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 100, max_bins: 250, WRMSSE:0.0426305414405022\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "4\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.24997\tvalid_1's rmse: 2.15951\n",
      "[400]\ttraining's rmse: 1.41388\tvalid_1's rmse: 1.36195\n",
      "[600]\ttraining's rmse: 0.912738\tvalid_1's rmse: 0.88981\n",
      "[800]\ttraining's rmse: 0.619457\tvalid_1's rmse: 0.618989\n",
      "[1000]\ttraining's rmse: 0.457253\tvalid_1's rmse: 0.474207\n",
      "[1200]\ttraining's rmse: 0.372434\tvalid_1's rmse: 0.401976\n",
      "[1400]\ttraining's rmse: 0.328819\tvalid_1's rmse: 0.367065\n",
      "[1600]\ttraining's rmse: 0.304886\tvalid_1's rmse: 0.349334\n",
      "[1800]\ttraining's rmse: 0.287665\tvalid_1's rmse: 0.339161\n",
      "[2000]\ttraining's rmse: 0.275393\tvalid_1's rmse: 0.332528\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.275393\tvalid_1's rmse: 0.332528\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.77692\tvalid_1's rmse: 1.89972\n",
      "[400]\ttraining's rmse: 1.11396\tvalid_1's rmse: 1.16745\n",
      "[600]\ttraining's rmse: 0.713323\tvalid_1's rmse: 0.723646\n",
      "[800]\ttraining's rmse: 0.476795\tvalid_1's rmse: 0.462691\n",
      "[1000]\ttraining's rmse: 0.344646\tvalid_1's rmse: 0.318243\n",
      "[1200]\ttraining's rmse: 0.274168\tvalid_1's rmse: 0.245742\n",
      "[1400]\ttraining's rmse: 0.237087\tvalid_1's rmse: 0.214242\n",
      "[1600]\ttraining's rmse: 0.216162\tvalid_1's rmse: 0.201787\n",
      "[1800]\ttraining's rmse: 0.203304\tvalid_1's rmse: 0.196917\n",
      "Early stopping, best iteration is:\n",
      "[1951]\ttraining's rmse: 0.196285\tvalid_1's rmse: 0.195344\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.40286\tvalid_1's rmse: 3.08236\n",
      "[400]\ttraining's rmse: 2.16188\tvalid_1's rmse: 1.91731\n",
      "[600]\ttraining's rmse: 1.4261\tvalid_1's rmse: 1.23934\n",
      "[800]\ttraining's rmse: 1.00746\tvalid_1's rmse: 0.865773\n",
      "[1000]\ttraining's rmse: 0.780665\tvalid_1's rmse: 0.677301\n",
      "[1200]\ttraining's rmse: 0.664606\tvalid_1's rmse: 0.591149\n",
      "[1400]\ttraining's rmse: 0.604419\tvalid_1's rmse: 0.55365\n",
      "[1600]\ttraining's rmse: 0.569899\tvalid_1's rmse: 0.537938\n",
      "[1800]\ttraining's rmse: 0.547436\tvalid_1's rmse: 0.530545\n",
      "[2000]\ttraining's rmse: 0.530422\tvalid_1's rmse: 0.526176\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.530422\tvalid_1's rmse: 0.526176\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.19102\tvalid_1's rmse: 1.16155\n",
      "[400]\ttraining's rmse: 0.745323\tvalid_1's rmse: 0.718468\n",
      "[600]\ttraining's rmse: 0.477698\tvalid_1's rmse: 0.45212\n",
      "[800]\ttraining's rmse: 0.319334\tvalid_1's rmse: 0.295037\n",
      "[1000]\ttraining's rmse: 0.22875\tvalid_1's rmse: 0.206286\n",
      "[1200]\ttraining's rmse: 0.178399\tvalid_1's rmse: 0.158782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1400]\ttraining's rmse: 0.15148\tvalid_1's rmse: 0.135372\n",
      "[1600]\ttraining's rmse: 0.136712\tvalid_1's rmse: 0.124406\n",
      "[1800]\ttraining's rmse: 0.125022\tvalid_1's rmse: 0.11879\n",
      "[2000]\ttraining's rmse: 0.115435\tvalid_1's rmse: 0.115552\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.115435\tvalid_1's rmse: 0.115552\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.83918\tvalid_1's rmse: 1.88201\n",
      "[400]\ttraining's rmse: 1.14993\tvalid_1's rmse: 1.15755\n",
      "[600]\ttraining's rmse: 0.736297\tvalid_1's rmse: 0.721565\n",
      "[800]\ttraining's rmse: 0.493939\tvalid_1's rmse: 0.463461\n",
      "[1000]\ttraining's rmse: 0.357385\tvalid_1's rmse: 0.317469\n",
      "[1200]\ttraining's rmse: 0.282801\tvalid_1's rmse: 0.239314\n",
      "[1400]\ttraining's rmse: 0.241453\tvalid_1's rmse: 0.204012\n",
      "[1600]\ttraining's rmse: 0.217159\tvalid_1's rmse: 0.18803\n",
      "[1800]\ttraining's rmse: 0.199794\tvalid_1's rmse: 0.178173\n",
      "[2000]\ttraining's rmse: 0.18595\tvalid_1's rmse: 0.174256\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.18595\tvalid_1's rmse: 0.174256\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.35631\tvalid_1's rmse: 2.1715\n",
      "[400]\ttraining's rmse: 1.48584\tvalid_1's rmse: 1.33763\n",
      "[600]\ttraining's rmse: 0.964331\tvalid_1's rmse: 0.835155\n",
      "[800]\ttraining's rmse: 0.661867\tvalid_1's rmse: 0.539161\n",
      "[1000]\ttraining's rmse: 0.493904\tvalid_1's rmse: 0.370783\n",
      "[1200]\ttraining's rmse: 0.40436\tvalid_1's rmse: 0.28294\n",
      "[1400]\ttraining's rmse: 0.355122\tvalid_1's rmse: 0.241897\n",
      "[1600]\ttraining's rmse: 0.325761\tvalid_1's rmse: 0.22466\n",
      "[1800]\ttraining's rmse: 0.305555\tvalid_1's rmse: 0.218181\n",
      "[2000]\ttraining's rmse: 0.290037\tvalid_1's rmse: 0.215159\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.290037\tvalid_1's rmse: 0.215159\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.24851\tvalid_1's rmse: 2.02299\n",
      "[400]\ttraining's rmse: 1.4096\tvalid_1's rmse: 1.25441\n",
      "[600]\ttraining's rmse: 0.907604\tvalid_1's rmse: 0.794979\n",
      "[800]\ttraining's rmse: 0.618081\tvalid_1's rmse: 0.530544\n",
      "[1000]\ttraining's rmse: 0.459703\tvalid_1's rmse: 0.387937\n",
      "[1200]\ttraining's rmse: 0.377564\tvalid_1's rmse: 0.318043\n",
      "[1400]\ttraining's rmse: 0.336052\tvalid_1's rmse: 0.285706\n",
      "[1600]\ttraining's rmse: 0.313724\tvalid_1's rmse: 0.271385\n",
      "[1800]\ttraining's rmse: 0.300038\tvalid_1's rmse: 0.262981\n",
      "[2000]\ttraining's rmse: 0.290314\tvalid_1's rmse: 0.258901\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.290314\tvalid_1's rmse: 0.258901\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.58461\tvalid_1's rmse: 1.55747\n",
      "[400]\ttraining's rmse: 0.982598\tvalid_1's rmse: 0.96395\n",
      "[600]\ttraining's rmse: 0.6191\tvalid_1's rmse: 0.6054\n",
      "[800]\ttraining's rmse: 0.403365\tvalid_1's rmse: 0.392417\n",
      "[1000]\ttraining's rmse: 0.279743\tvalid_1's rmse: 0.268956\n",
      "[1200]\ttraining's rmse: 0.212182\tvalid_1's rmse: 0.20038\n",
      "[1400]\ttraining's rmse: 0.17681\tvalid_1's rmse: 0.164297\n",
      "[1600]\ttraining's rmse: 0.158243\tvalid_1's rmse: 0.145871\n",
      "[1800]\ttraining's rmse: 0.147896\tvalid_1's rmse: 0.136377\n",
      "[2000]\ttraining's rmse: 0.140766\tvalid_1's rmse: 0.131144\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.140766\tvalid_1's rmse: 0.131144\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.54942\tvalid_1's rmse: 3.07131\n",
      "[400]\ttraining's rmse: 1.60539\tvalid_1's rmse: 1.9306\n",
      "[600]\ttraining's rmse: 1.03382\tvalid_1's rmse: 1.23356\n",
      "[800]\ttraining's rmse: 0.696394\tvalid_1's rmse: 0.822442\n",
      "[1000]\ttraining's rmse: 0.504638\tvalid_1's rmse: 0.596072\n",
      "[1200]\ttraining's rmse: 0.401263\tvalid_1's rmse: 0.480269\n",
      "[1400]\ttraining's rmse: 0.346726\tvalid_1's rmse: 0.424604\n",
      "[1600]\ttraining's rmse: 0.316527\tvalid_1's rmse: 0.397526\n",
      "[1800]\ttraining's rmse: 0.296654\tvalid_1's rmse: 0.382958\n",
      "[2000]\ttraining's rmse: 0.282727\tvalid_1's rmse: 0.375054\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.282727\tvalid_1's rmse: 0.375054\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.16846\tvalid_1's rmse: 2.35698\n",
      "[400]\ttraining's rmse: 1.35833\tvalid_1's rmse: 1.46313\n",
      "[600]\ttraining's rmse: 0.875279\tvalid_1's rmse: 0.928864\n",
      "[800]\ttraining's rmse: 0.595399\tvalid_1's rmse: 0.620444\n",
      "[1000]\ttraining's rmse: 0.441178\tvalid_1's rmse: 0.453183\n",
      "[1200]\ttraining's rmse: 0.360567\tvalid_1's rmse: 0.37141\n",
      "[1400]\ttraining's rmse: 0.319392\tvalid_1's rmse: 0.334477\n",
      "[1600]\ttraining's rmse: 0.297123\tvalid_1's rmse: 0.318286\n",
      "[1800]\ttraining's rmse: 0.282966\tvalid_1's rmse: 0.311202\n",
      "[2000]\ttraining's rmse: 0.271685\tvalid_1's rmse: 0.307777\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.271685\tvalid_1's rmse: 0.307777\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 100, max_bins: 300, WRMSSE:0.03855186871266007\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 100, max_bins: 300, WRMSSE:0.041013157632076094\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "5\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.24709\tvalid_1's rmse: 2.15465\n",
      "[400]\ttraining's rmse: 1.40798\tvalid_1's rmse: 1.35453\n",
      "[600]\ttraining's rmse: 0.903651\tvalid_1's rmse: 0.880124\n",
      "[800]\ttraining's rmse: 0.60696\tvalid_1's rmse: 0.607066\n",
      "[1000]\ttraining's rmse: 0.440338\tvalid_1's rmse: 0.459424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200]\ttraining's rmse: 0.35139\tvalid_1's rmse: 0.384988\n",
      "[1400]\ttraining's rmse: 0.304608\tvalid_1's rmse: 0.348594\n",
      "[1600]\ttraining's rmse: 0.27865\tvalid_1's rmse: 0.330792\n",
      "[1800]\ttraining's rmse: 0.260038\tvalid_1's rmse: 0.320634\n",
      "[2000]\ttraining's rmse: 0.24682\tvalid_1's rmse: 0.313073\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.24682\tvalid_1's rmse: 0.313073\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.77545\tvalid_1's rmse: 1.90126\n",
      "[400]\ttraining's rmse: 1.10913\tvalid_1's rmse: 1.1666\n",
      "[600]\ttraining's rmse: 0.704185\tvalid_1's rmse: 0.718635\n",
      "[800]\ttraining's rmse: 0.462804\tvalid_1's rmse: 0.452464\n",
      "[1000]\ttraining's rmse: 0.325192\tvalid_1's rmse: 0.30065\n",
      "[1200]\ttraining's rmse: 0.249586\tvalid_1's rmse: 0.220321\n",
      "[1400]\ttraining's rmse: 0.208473\tvalid_1's rmse: 0.181729\n",
      "[1600]\ttraining's rmse: 0.184465\tvalid_1's rmse: 0.164817\n",
      "[1800]\ttraining's rmse: 0.169939\tvalid_1's rmse: 0.157705\n",
      "[2000]\ttraining's rmse: 0.160162\tvalid_1's rmse: 0.154876\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.160162\tvalid_1's rmse: 0.154876\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.39936\tvalid_1's rmse: 3.08233\n",
      "[400]\ttraining's rmse: 2.15026\tvalid_1's rmse: 1.91198\n",
      "[600]\ttraining's rmse: 1.40575\tvalid_1's rmse: 1.22648\n",
      "[800]\ttraining's rmse: 0.976915\tvalid_1's rmse: 0.842042\n",
      "[1000]\ttraining's rmse: 0.740332\tvalid_1's rmse: 0.638567\n",
      "[1200]\ttraining's rmse: 0.616266\tvalid_1's rmse: 0.540668\n",
      "[1400]\ttraining's rmse: 0.550234\tvalid_1's rmse: 0.495358\n",
      "[1600]\ttraining's rmse: 0.512762\tvalid_1's rmse: 0.474494\n",
      "[1800]\ttraining's rmse: 0.488213\tvalid_1's rmse: 0.463018\n",
      "[2000]\ttraining's rmse: 0.469808\tvalid_1's rmse: 0.455369\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.469808\tvalid_1's rmse: 0.455369\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.19068\tvalid_1's rmse: 1.16212\n",
      "[400]\ttraining's rmse: 0.744138\tvalid_1's rmse: 0.719391\n",
      "[600]\ttraining's rmse: 0.475353\tvalid_1's rmse: 0.452034\n",
      "[800]\ttraining's rmse: 0.316262\tvalid_1's rmse: 0.293621\n",
      "[1000]\ttraining's rmse: 0.224757\tvalid_1's rmse: 0.203342\n",
      "[1200]\ttraining's rmse: 0.173269\tvalid_1's rmse: 0.154307\n",
      "[1400]\ttraining's rmse: 0.144553\tvalid_1's rmse: 0.129125\n",
      "[1600]\ttraining's rmse: 0.128684\tvalid_1's rmse: 0.116855\n",
      "[1800]\ttraining's rmse: 0.116816\tvalid_1's rmse: 0.110825\n",
      "[2000]\ttraining's rmse: 0.107345\tvalid_1's rmse: 0.107361\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.107345\tvalid_1's rmse: 0.107361\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.83686\tvalid_1's rmse: 1.88179\n",
      "[400]\ttraining's rmse: 1.14668\tvalid_1's rmse: 1.1576\n",
      "[600]\ttraining's rmse: 0.731537\tvalid_1's rmse: 0.721518\n",
      "[800]\ttraining's rmse: 0.486321\tvalid_1's rmse: 0.463196\n",
      "[1000]\ttraining's rmse: 0.345533\tvalid_1's rmse: 0.315747\n",
      "[1200]\ttraining's rmse: 0.267454\tvalid_1's rmse: 0.233995\n",
      "[1400]\ttraining's rmse: 0.223884\tvalid_1's rmse: 0.194742\n",
      "[1600]\ttraining's rmse: 0.197781\tvalid_1's rmse: 0.175496\n",
      "[1800]\ttraining's rmse: 0.179656\tvalid_1's rmse: 0.162252\n",
      "[2000]\ttraining's rmse: 0.16467\tvalid_1's rmse: 0.155337\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.16467\tvalid_1's rmse: 0.155337\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.35538\tvalid_1's rmse: 2.17245\n",
      "[400]\ttraining's rmse: 1.479\tvalid_1's rmse: 1.33979\n",
      "[600]\ttraining's rmse: 0.948479\tvalid_1's rmse: 0.834694\n",
      "[800]\ttraining's rmse: 0.635698\tvalid_1's rmse: 0.533833\n",
      "[1000]\ttraining's rmse: 0.457656\tvalid_1's rmse: 0.359946\n",
      "[1200]\ttraining's rmse: 0.360344\tvalid_1's rmse: 0.264822\n",
      "[1400]\ttraining's rmse: 0.306316\tvalid_1's rmse: 0.215975\n",
      "[1600]\ttraining's rmse: 0.27479\tvalid_1's rmse: 0.192421\n",
      "[1800]\ttraining's rmse: 0.25343\tvalid_1's rmse: 0.180966\n",
      "[2000]\ttraining's rmse: 0.237844\tvalid_1's rmse: 0.174967\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.237844\tvalid_1's rmse: 0.174967\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.24559\tvalid_1's rmse: 2.02581\n",
      "[400]\ttraining's rmse: 1.40262\tvalid_1's rmse: 1.25796\n",
      "[600]\ttraining's rmse: 0.894287\tvalid_1's rmse: 0.795582\n",
      "[800]\ttraining's rmse: 0.595196\tvalid_1's rmse: 0.524142\n",
      "[1000]\ttraining's rmse: 0.426958\tvalid_1's rmse: 0.372542\n",
      "[1200]\ttraining's rmse: 0.33678\tvalid_1's rmse: 0.293348\n",
      "[1400]\ttraining's rmse: 0.289482\tvalid_1's rmse: 0.25395\n",
      "[1600]\ttraining's rmse: 0.26355\tvalid_1's rmse: 0.235133\n",
      "[1800]\ttraining's rmse: 0.247867\tvalid_1's rmse: 0.224901\n",
      "[2000]\ttraining's rmse: 0.236862\tvalid_1's rmse: 0.219411\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.236862\tvalid_1's rmse: 0.219411\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.58399\tvalid_1's rmse: 1.55746\n",
      "[400]\ttraining's rmse: 0.980918\tvalid_1's rmse: 0.96395\n",
      "[600]\ttraining's rmse: 0.615991\tvalid_1's rmse: 0.604948\n",
      "[800]\ttraining's rmse: 0.398229\tvalid_1's rmse: 0.391057\n",
      "[1000]\ttraining's rmse: 0.27229\tvalid_1's rmse: 0.266778\n",
      "[1200]\ttraining's rmse: 0.202549\tvalid_1's rmse: 0.197336\n",
      "[1400]\ttraining's rmse: 0.165687\tvalid_1's rmse: 0.160318\n",
      "[1600]\ttraining's rmse: 0.146263\tvalid_1's rmse: 0.14099\n",
      "[1800]\ttraining's rmse: 0.135576\tvalid_1's rmse: 0.13054\n",
      "[2000]\ttraining's rmse: 0.128271\tvalid_1's rmse: 0.12449\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.128271\tvalid_1's rmse: 0.12449\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.5479\tvalid_1's rmse: 3.06522\n",
      "[400]\ttraining's rmse: 1.60149\tvalid_1's rmse: 1.91635\n",
      "[600]\ttraining's rmse: 1.02762\tvalid_1's rmse: 1.21793\n",
      "[800]\ttraining's rmse: 0.687376\tvalid_1's rmse: 0.80631\n",
      "[1000]\ttraining's rmse: 0.492652\tvalid_1's rmse: 0.582439\n",
      "[1200]\ttraining's rmse: 0.387072\tvalid_1's rmse: 0.471308\n",
      "[1400]\ttraining's rmse: 0.330749\tvalid_1's rmse: 0.420351\n",
      "[1600]\ttraining's rmse: 0.299834\tvalid_1's rmse: 0.397238\n",
      "[1800]\ttraining's rmse: 0.278429\tvalid_1's rmse: 0.385821\n",
      "[2000]\ttraining's rmse: 0.2634\tvalid_1's rmse: 0.379674\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.2634\tvalid_1's rmse: 0.379674\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.16692\tvalid_1's rmse: 2.35577\n",
      "[400]\ttraining's rmse: 1.35245\tvalid_1's rmse: 1.45498\n",
      "[600]\ttraining's rmse: 0.863699\tvalid_1's rmse: 0.91272\n",
      "[800]\ttraining's rmse: 0.5765\tvalid_1's rmse: 0.592249\n",
      "[1000]\ttraining's rmse: 0.41529\tvalid_1's rmse: 0.411451\n",
      "[1200]\ttraining's rmse: 0.329069\tvalid_1's rmse: 0.31591\n",
      "[1400]\ttraining's rmse: 0.284141\tvalid_1's rmse: 0.268812\n",
      "[1600]\ttraining's rmse: 0.260051\tvalid_1's rmse: 0.246075\n",
      "[1800]\ttraining's rmse: 0.24536\tvalid_1's rmse: 0.236182\n",
      "[2000]\ttraining's rmse: 0.234229\tvalid_1's rmse: 0.230735\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.234229\tvalid_1's rmse: 0.230735\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 100, max_bins: 400, WRMSSE:0.03581075094864471\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 100, max_bins: 400, WRMSSE:0.03814202848927419\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "6\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.24429\tvalid_1's rmse: 2.14916\n",
      "[400]\ttraining's rmse: 1.40216\tvalid_1's rmse: 1.34429\n",
      "[600]\ttraining's rmse: 0.894677\tvalid_1's rmse: 0.865002\n",
      "[800]\ttraining's rmse: 0.594101\tvalid_1's rmse: 0.585539\n",
      "[1000]\ttraining's rmse: 0.423447\tvalid_1's rmse: 0.432262\n",
      "[1200]\ttraining's rmse: 0.330963\tvalid_1's rmse: 0.353923\n",
      "[1400]\ttraining's rmse: 0.282196\tvalid_1's rmse: 0.315822\n",
      "[1600]\ttraining's rmse: 0.255621\tvalid_1's rmse: 0.297282\n",
      "[1800]\ttraining's rmse: 0.238283\tvalid_1's rmse: 0.287044\n",
      "[2000]\ttraining's rmse: 0.224972\tvalid_1's rmse: 0.280895\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.224972\tvalid_1's rmse: 0.280895\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.7743\tvalid_1's rmse: 1.89625\n",
      "[400]\ttraining's rmse: 1.10739\tvalid_1's rmse: 1.16058\n",
      "[600]\ttraining's rmse: 0.700957\tvalid_1's rmse: 0.70902\n",
      "[800]\ttraining's rmse: 0.45767\tvalid_1's rmse: 0.441407\n",
      "[1000]\ttraining's rmse: 0.317104\tvalid_1's rmse: 0.288242\n",
      "[1200]\ttraining's rmse: 0.238817\tvalid_1's rmse: 0.206274\n",
      "[1400]\ttraining's rmse: 0.196799\tvalid_1's rmse: 0.166213\n",
      "[1600]\ttraining's rmse: 0.172694\tvalid_1's rmse: 0.147433\n",
      "[1800]\ttraining's rmse: 0.15755\tvalid_1's rmse: 0.139133\n",
      "[2000]\ttraining's rmse: 0.147613\tvalid_1's rmse: 0.135249\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.147613\tvalid_1's rmse: 0.135249\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.39563\tvalid_1's rmse: 3.07105\n",
      "[400]\ttraining's rmse: 2.14402\tvalid_1's rmse: 1.88989\n",
      "[600]\ttraining's rmse: 1.39599\tvalid_1's rmse: 1.19711\n",
      "[800]\ttraining's rmse: 0.955217\tvalid_1's rmse: 0.799166\n",
      "[1000]\ttraining's rmse: 0.701177\tvalid_1's rmse: 0.58623\n",
      "[1200]\ttraining's rmse: 0.564901\tvalid_1's rmse: 0.488551\n",
      "[1400]\ttraining's rmse: 0.491958\tvalid_1's rmse: 0.448233\n",
      "[1600]\ttraining's rmse: 0.450591\tvalid_1's rmse: 0.432822\n",
      "[1800]\ttraining's rmse: 0.42345\tvalid_1's rmse: 0.425477\n",
      "[2000]\ttraining's rmse: 0.403564\tvalid_1's rmse: 0.421873\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.403564\tvalid_1's rmse: 0.421873\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.18962\tvalid_1's rmse: 1.16066\n",
      "[400]\ttraining's rmse: 0.741274\tvalid_1's rmse: 0.715998\n",
      "[600]\ttraining's rmse: 0.470793\tvalid_1's rmse: 0.446735\n",
      "[800]\ttraining's rmse: 0.309971\tvalid_1's rmse: 0.286135\n",
      "[1000]\ttraining's rmse: 0.216969\tvalid_1's rmse: 0.192286\n",
      "[1200]\ttraining's rmse: 0.164791\tvalid_1's rmse: 0.139519\n",
      "[1400]\ttraining's rmse: 0.135871\tvalid_1's rmse: 0.111369\n",
      "[1600]\ttraining's rmse: 0.11957\tvalid_1's rmse: 0.0968166\n",
      "[1800]\ttraining's rmse: 0.107823\tvalid_1's rmse: 0.0891096\n",
      "[2000]\ttraining's rmse: 0.0987359\tvalid_1's rmse: 0.0846098\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.0987359\tvalid_1's rmse: 0.0846098\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.83679\tvalid_1's rmse: 1.88565\n",
      "[400]\ttraining's rmse: 1.14515\tvalid_1's rmse: 1.16371\n",
      "[600]\ttraining's rmse: 0.728006\tvalid_1's rmse: 0.727897\n",
      "[800]\ttraining's rmse: 0.481305\tvalid_1's rmse: 0.467243\n",
      "[1000]\ttraining's rmse: 0.339249\tvalid_1's rmse: 0.315415\n",
      "[1200]\ttraining's rmse: 0.259485\tvalid_1's rmse: 0.228155\n",
      "[1400]\ttraining's rmse: 0.214384\tvalid_1's rmse: 0.182418\n",
      "[1600]\ttraining's rmse: 0.187251\tvalid_1's rmse: 0.158917\n",
      "[1800]\ttraining's rmse: 0.167108\tvalid_1's rmse: 0.142153\n",
      "[2000]\ttraining's rmse: 0.150642\tvalid_1's rmse: 0.13213\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.150642\tvalid_1's rmse: 0.13213\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.35218\tvalid_1's rmse: 2.16935\n",
      "[400]\ttraining's rmse: 1.47339\tvalid_1's rmse: 1.33609\n",
      "[600]\ttraining's rmse: 0.94126\tvalid_1's rmse: 0.828434\n",
      "[800]\ttraining's rmse: 0.626151\tvalid_1's rmse: 0.525836\n",
      "[1000]\ttraining's rmse: 0.444912\tvalid_1's rmse: 0.350305\n",
      "[1200]\ttraining's rmse: 0.343025\tvalid_1's rmse: 0.253893\n",
      "[1400]\ttraining's rmse: 0.284147\tvalid_1's rmse: 0.204584\n",
      "[1600]\ttraining's rmse: 0.249662\tvalid_1's rmse: 0.180698\n",
      "[1800]\ttraining's rmse: 0.226888\tvalid_1's rmse: 0.169296\n",
      "[2000]\ttraining's rmse: 0.210218\tvalid_1's rmse: 0.163026\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.210218\tvalid_1's rmse: 0.163026\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.24447\tvalid_1's rmse: 2.0224\n",
      "[400]\ttraining's rmse: 1.39999\tvalid_1's rmse: 1.25149\n",
      "[600]\ttraining's rmse: 0.888664\tvalid_1's rmse: 0.786231\n",
      "[800]\ttraining's rmse: 0.585426\tvalid_1's rmse: 0.510042\n",
      "[1000]\ttraining's rmse: 0.412785\tvalid_1's rmse: 0.35179\n",
      "[1200]\ttraining's rmse: 0.318513\tvalid_1's rmse: 0.265724\n",
      "[1400]\ttraining's rmse: 0.268114\tvalid_1's rmse: 0.221102\n",
      "[1600]\ttraining's rmse: 0.239917\tvalid_1's rmse: 0.199282\n",
      "[1800]\ttraining's rmse: 0.222649\tvalid_1's rmse: 0.186665\n",
      "[2000]\ttraining's rmse: 0.21123\tvalid_1's rmse: 0.179358\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.21123\tvalid_1's rmse: 0.179358\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.58351\tvalid_1's rmse: 1.55122\n",
      "[400]\ttraining's rmse: 0.979474\tvalid_1's rmse: 0.954275\n",
      "[600]\ttraining's rmse: 0.612964\tvalid_1's rmse: 0.591352\n",
      "[800]\ttraining's rmse: 0.393269\tvalid_1's rmse: 0.372922\n",
      "[1000]\ttraining's rmse: 0.264594\tvalid_1's rmse: 0.244249\n",
      "[1200]\ttraining's rmse: 0.192147\tvalid_1's rmse: 0.171475\n",
      "[1400]\ttraining's rmse: 0.153183\tvalid_1's rmse: 0.132579\n",
      "[1600]\ttraining's rmse: 0.132807\tvalid_1's rmse: 0.112887\n",
      "[1800]\ttraining's rmse: 0.121627\tvalid_1's rmse: 0.102964\n",
      "[2000]\ttraining's rmse: 0.114454\tvalid_1's rmse: 0.0974525\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.114454\tvalid_1's rmse: 0.0974525\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.54696\tvalid_1's rmse: 3.06632\n",
      "[400]\ttraining's rmse: 1.59771\tvalid_1's rmse: 1.91676\n",
      "[600]\ttraining's rmse: 1.02103\tvalid_1's rmse: 1.21883\n",
      "[800]\ttraining's rmse: 0.677034\tvalid_1's rmse: 0.804802\n",
      "[1000]\ttraining's rmse: 0.477931\tvalid_1's rmse: 0.576773\n",
      "[1200]\ttraining's rmse: 0.367829\tvalid_1's rmse: 0.461811\n",
      "[1400]\ttraining's rmse: 0.308498\tvalid_1's rmse: 0.408224\n",
      "[1600]\ttraining's rmse: 0.274808\tvalid_1's rmse: 0.382988\n",
      "[1800]\ttraining's rmse: 0.252045\tvalid_1's rmse: 0.370274\n",
      "[2000]\ttraining's rmse: 0.235984\tvalid_1's rmse: 0.363273\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.235984\tvalid_1's rmse: 0.363273\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 100, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.1655\tvalid_1's rmse: 2.34868\n",
      "[400]\ttraining's rmse: 1.35034\tvalid_1's rmse: 1.4451\n",
      "[600]\ttraining's rmse: 0.859694\tvalid_1's rmse: 0.89961\n",
      "[800]\ttraining's rmse: 0.56963\tvalid_1's rmse: 0.573967\n",
      "[1000]\ttraining's rmse: 0.404218\tvalid_1's rmse: 0.38568\n",
      "[1200]\ttraining's rmse: 0.313927\tvalid_1's rmse: 0.283552\n",
      "[1400]\ttraining's rmse: 0.266444\tvalid_1's rmse: 0.231559\n",
      "[1600]\ttraining's rmse: 0.241301\tvalid_1's rmse: 0.207487\n",
      "[1800]\ttraining's rmse: 0.225868\tvalid_1's rmse: 0.195583\n",
      "[2000]\ttraining's rmse: 0.213692\tvalid_1's rmse: 0.18907\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.213692\tvalid_1's rmse: 0.18907\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 100, max_bins: 500, WRMSSE:0.03265946888085337\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 100, max_bins: 500, WRMSSE:0.034471441731839955\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "7\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.27527\tvalid_1's rmse: 2.1708\n",
      "[400]\ttraining's rmse: 1.46821\tvalid_1's rmse: 1.3859\n",
      "[600]\ttraining's rmse: 1.0044\tvalid_1's rmse: 0.932269\n",
      "[800]\ttraining's rmse: 0.753028\tvalid_1's rmse: 0.683987\n",
      "[1000]\ttraining's rmse: 0.625639\tvalid_1's rmse: 0.559199\n",
      "[1200]\ttraining's rmse: 0.563948\tvalid_1's rmse: 0.50079\n",
      "[1400]\ttraining's rmse: 0.532888\tvalid_1's rmse: 0.473888\n",
      "[1600]\ttraining's rmse: 0.515521\tvalid_1's rmse: 0.460243\n",
      "[1800]\ttraining's rmse: 0.503443\tvalid_1's rmse: 0.451983\n",
      "[2000]\ttraining's rmse: 0.494078\tvalid_1's rmse: 0.445992\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.494078\tvalid_1's rmse: 0.445992\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.79566\tvalid_1's rmse: 1.90899\n",
      "[400]\ttraining's rmse: 1.15496\tvalid_1's rmse: 1.19609\n",
      "[600]\ttraining's rmse: 0.781775\tvalid_1's rmse: 0.780187\n",
      "[800]\ttraining's rmse: 0.574814\tvalid_1's rmse: 0.552129\n",
      "[1000]\ttraining's rmse: 0.466946\tvalid_1's rmse: 0.441318\n",
      "[1200]\ttraining's rmse: 0.412287\tvalid_1's rmse: 0.393108\n",
      "[1400]\ttraining's rmse: 0.384186\tvalid_1's rmse: 0.374246\n",
      "[1600]\ttraining's rmse: 0.367687\tvalid_1's rmse: 0.367226\n",
      "[1800]\ttraining's rmse: 0.356531\tvalid_1's rmse: 0.361694\n",
      "[2000]\ttraining's rmse: 0.347928\tvalid_1's rmse: 0.358172\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.347928\tvalid_1's rmse: 0.358172\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.451\tvalid_1's rmse: 3.11633\n",
      "[400]\ttraining's rmse: 2.26028\tvalid_1's rmse: 1.987\n",
      "[600]\ttraining's rmse: 1.57408\tvalid_1's rmse: 1.35449\n",
      "[800]\ttraining's rmse: 1.20048\tvalid_1's rmse: 1.02642\n",
      "[1000]\ttraining's rmse: 1.0083\tvalid_1's rmse: 0.869375\n",
      "[1200]\ttraining's rmse: 0.914237\tvalid_1's rmse: 0.8015\n",
      "[1400]\ttraining's rmse: 0.86501\tvalid_1's rmse: 0.772966\n",
      "[1600]\ttraining's rmse: 0.835394\tvalid_1's rmse: 0.75843\n",
      "[1800]\ttraining's rmse: 0.815957\tvalid_1's rmse: 0.75078\n",
      "[2000]\ttraining's rmse: 0.800583\tvalid_1's rmse: 0.745808\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.800583\tvalid_1's rmse: 0.745808\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.20001\tvalid_1's rmse: 1.15831\n",
      "[400]\ttraining's rmse: 0.76622\tvalid_1's rmse: 0.719377\n",
      "[600]\ttraining's rmse: 0.513051\tvalid_1's rmse: 0.463233\n",
      "[800]\ttraining's rmse: 0.372522\tvalid_1's rmse: 0.322914\n",
      "[1000]\ttraining's rmse: 0.299055\tvalid_1's rmse: 0.253769\n",
      "[1200]\ttraining's rmse: 0.262304\tvalid_1's rmse: 0.223989\n",
      "[1400]\ttraining's rmse: 0.243796\tvalid_1's rmse: 0.212305\n",
      "[1600]\ttraining's rmse: 0.231984\tvalid_1's rmse: 0.20748\n",
      "[1800]\ttraining's rmse: 0.222976\tvalid_1's rmse: 0.204833\n",
      "[2000]\ttraining's rmse: 0.216482\tvalid_1's rmse: 0.202889\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.216482\tvalid_1's rmse: 0.202889\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.8621\tvalid_1's rmse: 1.89719\n",
      "[400]\ttraining's rmse: 1.19791\tvalid_1's rmse: 1.18338\n",
      "[600]\ttraining's rmse: 0.81228\tvalid_1's rmse: 0.761481\n",
      "[800]\ttraining's rmse: 0.600437\tvalid_1's rmse: 0.526974\n",
      "[1000]\ttraining's rmse: 0.491558\tvalid_1's rmse: 0.410082\n",
      "[1200]\ttraining's rmse: 0.436395\tvalid_1's rmse: 0.359057\n",
      "[1400]\ttraining's rmse: 0.407594\tvalid_1's rmse: 0.339643\n",
      "[1600]\ttraining's rmse: 0.390197\tvalid_1's rmse: 0.331683\n",
      "[1800]\ttraining's rmse: 0.376612\tvalid_1's rmse: 0.327533\n",
      "Early stopping, best iteration is:\n",
      "[1960]\ttraining's rmse: 0.367681\tvalid_1's rmse: 0.32648\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.39615\tvalid_1's rmse: 2.15953\n",
      "[400]\ttraining's rmse: 1.56966\tvalid_1's rmse: 1.33721\n",
      "[600]\ttraining's rmse: 1.09866\tvalid_1's rmse: 0.866881\n",
      "[800]\ttraining's rmse: 0.848301\tvalid_1's rmse: 0.619276\n",
      "[1000]\ttraining's rmse: 0.72471\tvalid_1's rmse: 0.504941\n",
      "[1200]\ttraining's rmse: 0.663375\tvalid_1's rmse: 0.461494\n",
      "[1400]\ttraining's rmse: 0.630763\tvalid_1's rmse: 0.447315\n",
      "[1600]\ttraining's rmse: 0.608661\tvalid_1's rmse: 0.443124\n",
      "[1800]\ttraining's rmse: 0.591693\tvalid_1's rmse: 0.441273\n",
      "Early stopping, best iteration is:\n",
      "[1810]\ttraining's rmse: 0.590991\tvalid_1's rmse: 0.441139\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.27751\tvalid_1's rmse: 2.02393\n",
      "[400]\ttraining's rmse: 1.47279\tvalid_1's rmse: 1.26631\n",
      "[600]\ttraining's rmse: 1.0128\tvalid_1's rmse: 0.833077\n",
      "[800]\ttraining's rmse: 0.766069\tvalid_1's rmse: 0.602956\n",
      "[1000]\ttraining's rmse: 0.643548\tvalid_1's rmse: 0.496211\n",
      "[1200]\ttraining's rmse: 0.584678\tvalid_1's rmse: 0.452728\n",
      "[1400]\ttraining's rmse: 0.55508\tvalid_1's rmse: 0.436476\n",
      "[1600]\ttraining's rmse: 0.53842\tvalid_1's rmse: 0.430303\n",
      "[1800]\ttraining's rmse: 0.527007\tvalid_1's rmse: 0.427154\n",
      "[2000]\ttraining's rmse: 0.517752\tvalid_1's rmse: 0.425575\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.517752\tvalid_1's rmse: 0.425575\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.59553\tvalid_1's rmse: 1.55469\n",
      "[400]\ttraining's rmse: 1.00699\tvalid_1's rmse: 0.965662\n",
      "[600]\ttraining's rmse: 0.659717\tvalid_1's rmse: 0.616603\n",
      "[800]\ttraining's rmse: 0.46292\tvalid_1's rmse: 0.417517\n",
      "[1000]\ttraining's rmse: 0.358671\tvalid_1's rmse: 0.313593\n",
      "[1200]\ttraining's rmse: 0.307012\tvalid_1's rmse: 0.264909\n",
      "[1400]\ttraining's rmse: 0.281751\tvalid_1's rmse: 0.243539\n",
      "[1600]\ttraining's rmse: 0.268555\tvalid_1's rmse: 0.234191\n",
      "[1800]\ttraining's rmse: 0.26076\tvalid_1's rmse: 0.229363\n",
      "[2000]\ttraining's rmse: 0.255141\tvalid_1's rmse: 0.22607\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.255141\tvalid_1's rmse: 0.22607\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.57149\tvalid_1's rmse: 3.04457\n",
      "[400]\ttraining's rmse: 1.65036\tvalid_1's rmse: 1.91316\n",
      "[600]\ttraining's rmse: 1.11222\tvalid_1's rmse: 1.26013\n",
      "[800]\ttraining's rmse: 0.812661\tvalid_1's rmse: 0.9232\n",
      "[1000]\ttraining's rmse: 0.653412\tvalid_1's rmse: 0.77339\n",
      "[1200]\ttraining's rmse: 0.572027\tvalid_1's rmse: 0.719786\n",
      "[1400]\ttraining's rmse: 0.529589\tvalid_1's rmse: 0.702324\n",
      "[1600]\ttraining's rmse: 0.505139\tvalid_1's rmse: 0.694415\n",
      "[1800]\ttraining's rmse: 0.488368\tvalid_1's rmse: 0.689738\n",
      "[2000]\ttraining's rmse: 0.475234\tvalid_1's rmse: 0.684496\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.475234\tvalid_1's rmse: 0.684496\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.19934\tvalid_1's rmse: 2.36734\n",
      "[400]\ttraining's rmse: 1.42527\tvalid_1's rmse: 1.48997\n",
      "[600]\ttraining's rmse: 0.982308\tvalid_1's rmse: 0.985485\n",
      "[800]\ttraining's rmse: 0.743391\tvalid_1's rmse: 0.717468\n",
      "[1000]\ttraining's rmse: 0.624565\tvalid_1's rmse: 0.591074\n",
      "[1200]\ttraining's rmse: 0.56703\tvalid_1's rmse: 0.540149\n",
      "[1400]\ttraining's rmse: 0.537953\tvalid_1's rmse: 0.52167\n",
      "[1600]\ttraining's rmse: 0.521179\tvalid_1's rmse: 0.514576\n",
      "[1800]\ttraining's rmse: 0.508447\tvalid_1's rmse: 0.511737\n",
      "Early stopping, best iteration is:\n",
      "[1785]\ttraining's rmse: 0.509323\tvalid_1's rmse: 0.511654\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 200, max_bins: 100, WRMSSE:0.06177330952779357\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 200, max_bins: 100, WRMSSE:0.06540562577546787\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.2658\tvalid_1's rmse: 2.16781\n",
      "[400]\ttraining's rmse: 1.44735\tvalid_1's rmse: 1.37935\n",
      "[600]\ttraining's rmse: 0.970853\tvalid_1's rmse: 0.918617\n",
      "[800]\ttraining's rmse: 0.706659\tvalid_1's rmse: 0.661257\n",
      "[1000]\ttraining's rmse: 0.569734\tvalid_1's rmse: 0.527541\n",
      "[1200]\ttraining's rmse: 0.502946\tvalid_1's rmse: 0.461834\n",
      "[1400]\ttraining's rmse: 0.470002\tvalid_1's rmse: 0.430429\n",
      "[1600]\ttraining's rmse: 0.45218\tvalid_1's rmse: 0.413777\n",
      "[1800]\ttraining's rmse: 0.440348\tvalid_1's rmse: 0.404119\n",
      "[2000]\ttraining's rmse: 0.43075\tvalid_1's rmse: 0.397723\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.43075\tvalid_1's rmse: 0.397723\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.78842\tvalid_1's rmse: 1.90333\n",
      "[400]\ttraining's rmse: 1.14044\tvalid_1's rmse: 1.1807\n",
      "[600]\ttraining's rmse: 0.758675\tvalid_1's rmse: 0.750055\n",
      "[800]\ttraining's rmse: 0.542822\tvalid_1's rmse: 0.505174\n",
      "[1000]\ttraining's rmse: 0.427182\tvalid_1's rmse: 0.379522\n",
      "[1200]\ttraining's rmse: 0.367868\tvalid_1's rmse: 0.322696\n",
      "[1400]\ttraining's rmse: 0.336792\tvalid_1's rmse: 0.300023\n",
      "[1600]\ttraining's rmse: 0.319167\tvalid_1's rmse: 0.291904\n",
      "[1800]\ttraining's rmse: 0.307634\tvalid_1's rmse: 0.287134\n",
      "[2000]\ttraining's rmse: 0.29832\tvalid_1's rmse: 0.283631\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.29832\tvalid_1's rmse: 0.283631\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.43724\tvalid_1's rmse: 3.08678\n",
      "[400]\ttraining's rmse: 2.22972\tvalid_1's rmse: 1.93683\n",
      "[600]\ttraining's rmse: 1.52455\tvalid_1's rmse: 1.28206\n",
      "[800]\ttraining's rmse: 1.13356\tvalid_1's rmse: 0.938336\n",
      "[1000]\ttraining's rmse: 0.927996\tvalid_1's rmse: 0.774148\n",
      "[1200]\ttraining's rmse: 0.826021\tvalid_1's rmse: 0.70519\n",
      "[1400]\ttraining's rmse: 0.772866\tvalid_1's rmse: 0.67841\n",
      "[1600]\ttraining's rmse: 0.741774\tvalid_1's rmse: 0.668049\n",
      "[1800]\ttraining's rmse: 0.722311\tvalid_1's rmse: 0.662792\n",
      "[2000]\ttraining's rmse: 0.707027\tvalid_1's rmse: 0.65996\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.707027\tvalid_1's rmse: 0.65996\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.19776\tvalid_1's rmse: 1.15835\n",
      "[400]\ttraining's rmse: 0.75994\tvalid_1's rmse: 0.717778\n",
      "[600]\ttraining's rmse: 0.502235\tvalid_1's rmse: 0.455468\n",
      "[800]\ttraining's rmse: 0.356412\tvalid_1's rmse: 0.305202\n",
      "[1000]\ttraining's rmse: 0.278225\tvalid_1's rmse: 0.22453\n",
      "[1200]\ttraining's rmse: 0.238086\tvalid_1's rmse: 0.184606\n",
      "[1400]\ttraining's rmse: 0.217297\tvalid_1's rmse: 0.166455\n",
      "[1600]\ttraining's rmse: 0.204492\tvalid_1's rmse: 0.158087\n",
      "[1800]\ttraining's rmse: 0.194524\tvalid_1's rmse: 0.153439\n",
      "[2000]\ttraining's rmse: 0.18712\tvalid_1's rmse: 0.150916\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.18712\tvalid_1's rmse: 0.150916\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.85382\tvalid_1's rmse: 1.8868\n",
      "[400]\ttraining's rmse: 1.18041\tvalid_1's rmse: 1.16498\n",
      "[600]\ttraining's rmse: 0.785217\tvalid_1's rmse: 0.737069\n",
      "[800]\ttraining's rmse: 0.563313\tvalid_1's rmse: 0.495368\n",
      "[1000]\ttraining's rmse: 0.445906\tvalid_1's rmse: 0.371119\n",
      "[1200]\ttraining's rmse: 0.385838\tvalid_1's rmse: 0.314461\n",
      "[1400]\ttraining's rmse: 0.354757\tvalid_1's rmse: 0.290847\n",
      "[1600]\ttraining's rmse: 0.335955\tvalid_1's rmse: 0.279793\n",
      "[1800]\ttraining's rmse: 0.321314\tvalid_1's rmse: 0.271677\n",
      "[2000]\ttraining's rmse: 0.309752\tvalid_1's rmse: 0.267896\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.309752\tvalid_1's rmse: 0.267896\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.38036\tvalid_1's rmse: 2.16951\n",
      "[400]\ttraining's rmse: 1.53586\tvalid_1's rmse: 1.34322\n",
      "[600]\ttraining's rmse: 1.04785\tvalid_1's rmse: 0.858578\n",
      "[800]\ttraining's rmse: 0.781682\tvalid_1's rmse: 0.588447\n",
      "[1000]\ttraining's rmse: 0.646708\tvalid_1's rmse: 0.450314\n",
      "[1200]\ttraining's rmse: 0.57879\tvalid_1's rmse: 0.386321\n",
      "[1400]\ttraining's rmse: 0.543023\tvalid_1's rmse: 0.358763\n",
      "[1600]\ttraining's rmse: 0.519683\tvalid_1's rmse: 0.346504\n",
      "[1800]\ttraining's rmse: 0.500984\tvalid_1's rmse: 0.341411\n",
      "[2000]\ttraining's rmse: 0.485872\tvalid_1's rmse: 0.338871\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.485872\tvalid_1's rmse: 0.338871\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.26221\tvalid_1's rmse: 2.03144\n",
      "[400]\ttraining's rmse: 1.44003\tvalid_1's rmse: 1.27404\n",
      "[600]\ttraining's rmse: 0.959551\tvalid_1's rmse: 0.832701\n",
      "[800]\ttraining's rmse: 0.693955\tvalid_1's rmse: 0.589002\n",
      "[1000]\ttraining's rmse: 0.556945\tvalid_1's rmse: 0.465463\n",
      "[1200]\ttraining's rmse: 0.490254\tvalid_1's rmse: 0.408101\n",
      "[1400]\ttraining's rmse: 0.457097\tvalid_1's rmse: 0.38248\n",
      "[1600]\ttraining's rmse: 0.438738\tvalid_1's rmse: 0.370807\n",
      "[1800]\ttraining's rmse: 0.426816\tvalid_1's rmse: 0.363989\n",
      "[2000]\ttraining's rmse: 0.416847\tvalid_1's rmse: 0.360106\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.416847\tvalid_1's rmse: 0.360106\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.59134\tvalid_1's rmse: 1.55689\n",
      "[400]\ttraining's rmse: 0.997831\tvalid_1's rmse: 0.966987\n",
      "[600]\ttraining's rmse: 0.644929\tvalid_1's rmse: 0.615514\n",
      "[800]\ttraining's rmse: 0.441059\tvalid_1's rmse: 0.410286\n",
      "[1000]\ttraining's rmse: 0.329823\tvalid_1's rmse: 0.297962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200]\ttraining's rmse: 0.273209\tvalid_1's rmse: 0.242142\n",
      "[1400]\ttraining's rmse: 0.245\tvalid_1's rmse: 0.216147\n",
      "[1600]\ttraining's rmse: 0.230281\tvalid_1's rmse: 0.203721\n",
      "[1800]\ttraining's rmse: 0.221408\tvalid_1's rmse: 0.196981\n",
      "[2000]\ttraining's rmse: 0.215046\tvalid_1's rmse: 0.192097\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.215046\tvalid_1's rmse: 0.192097\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.56433\tvalid_1's rmse: 3.08191\n",
      "[400]\ttraining's rmse: 1.63381\tvalid_1's rmse: 1.95482\n",
      "[600]\ttraining's rmse: 1.08391\tvalid_1's rmse: 1.27976\n",
      "[800]\ttraining's rmse: 0.771472\tvalid_1's rmse: 0.894035\n",
      "[1000]\ttraining's rmse: 0.60089\tvalid_1's rmse: 0.689245\n",
      "[1200]\ttraining's rmse: 0.511166\tvalid_1's rmse: 0.58825\n",
      "[1400]\ttraining's rmse: 0.463545\tvalid_1's rmse: 0.53918\n",
      "[1600]\ttraining's rmse: 0.436599\tvalid_1's rmse: 0.51397\n",
      "[1800]\ttraining's rmse: 0.417794\tvalid_1's rmse: 0.499237\n",
      "[2000]\ttraining's rmse: 0.402943\tvalid_1's rmse: 0.486356\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.402943\tvalid_1's rmse: 0.486356\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.18695\tvalid_1's rmse: 2.3745\n",
      "[400]\ttraining's rmse: 1.39872\tvalid_1's rmse: 1.49438\n",
      "[600]\ttraining's rmse: 0.941941\tvalid_1's rmse: 0.979401\n",
      "[800]\ttraining's rmse: 0.688976\tvalid_1's rmse: 0.69155\n",
      "[1000]\ttraining's rmse: 0.559431\tvalid_1's rmse: 0.544596\n",
      "[1200]\ttraining's rmse: 0.496624\tvalid_1's rmse: 0.475983\n",
      "[1400]\ttraining's rmse: 0.465165\tvalid_1's rmse: 0.447239\n",
      "[1600]\ttraining's rmse: 0.447392\tvalid_1's rmse: 0.434571\n",
      "[1800]\ttraining's rmse: 0.434874\tvalid_1's rmse: 0.428558\n",
      "Early stopping, best iteration is:\n",
      "[1907]\ttraining's rmse: 0.429192\tvalid_1's rmse: 0.427479\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 200, max_bins: 150, WRMSSE:0.050510362531282285\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 200, max_bins: 150, WRMSSE:0.05337329636224353\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "9\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.26062\tvalid_1's rmse: 2.15785\n",
      "[400]\ttraining's rmse: 1.43293\tvalid_1's rmse: 1.36251\n",
      "[600]\ttraining's rmse: 0.946537\tvalid_1's rmse: 0.897764\n",
      "[800]\ttraining's rmse: 0.672304\tvalid_1's rmse: 0.638058\n",
      "[1000]\ttraining's rmse: 0.52601\tvalid_1's rmse: 0.503424\n",
      "[1200]\ttraining's rmse: 0.452808\tvalid_1's rmse: 0.438754\n",
      "[1400]\ttraining's rmse: 0.416283\tvalid_1's rmse: 0.408358\n",
      "[1600]\ttraining's rmse: 0.396862\tvalid_1's rmse: 0.393571\n",
      "[1800]\ttraining's rmse: 0.384509\tvalid_1's rmse: 0.385436\n",
      "[2000]\ttraining's rmse: 0.375153\tvalid_1's rmse: 0.379656\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.375153\tvalid_1's rmse: 0.379656\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.78362\tvalid_1's rmse: 1.90295\n",
      "[400]\ttraining's rmse: 1.12936\tvalid_1's rmse: 1.176\n",
      "[600]\ttraining's rmse: 0.74029\tvalid_1's rmse: 0.738121\n",
      "[800]\ttraining's rmse: 0.516666\tvalid_1's rmse: 0.484022\n",
      "[1000]\ttraining's rmse: 0.394767\tvalid_1's rmse: 0.348049\n",
      "[1200]\ttraining's rmse: 0.331246\tvalid_1's rmse: 0.284979\n",
      "[1400]\ttraining's rmse: 0.297935\tvalid_1's rmse: 0.26039\n",
      "[1600]\ttraining's rmse: 0.278602\tvalid_1's rmse: 0.251769\n",
      "[1800]\ttraining's rmse: 0.265768\tvalid_1's rmse: 0.246565\n",
      "[2000]\ttraining's rmse: 0.255754\tvalid_1's rmse: 0.242952\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.255754\tvalid_1's rmse: 0.242952\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.42813\tvalid_1's rmse: 3.09011\n",
      "[400]\ttraining's rmse: 2.20934\tvalid_1's rmse: 1.93669\n",
      "[600]\ttraining's rmse: 1.49165\tvalid_1's rmse: 1.27433\n",
      "[800]\ttraining's rmse: 1.08656\tvalid_1's rmse: 0.918177\n",
      "[1000]\ttraining's rmse: 0.871911\tvalid_1's rmse: 0.738944\n",
      "[1200]\ttraining's rmse: 0.764438\tvalid_1's rmse: 0.65683\n",
      "[1400]\ttraining's rmse: 0.709077\tvalid_1's rmse: 0.621188\n",
      "[1600]\ttraining's rmse: 0.677585\tvalid_1's rmse: 0.605164\n",
      "[1800]\ttraining's rmse: 0.657542\tvalid_1's rmse: 0.596901\n",
      "[2000]\ttraining's rmse: 0.64278\tvalid_1's rmse: 0.592219\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.64278\tvalid_1's rmse: 0.592219\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.1971\tvalid_1's rmse: 1.15826\n",
      "[400]\ttraining's rmse: 0.756995\tvalid_1's rmse: 0.716039\n",
      "[600]\ttraining's rmse: 0.495832\tvalid_1's rmse: 0.45197\n",
      "[800]\ttraining's rmse: 0.346206\tvalid_1's rmse: 0.298614\n",
      "[1000]\ttraining's rmse: 0.264861\tvalid_1's rmse: 0.215417\n",
      "[1200]\ttraining's rmse: 0.222667\tvalid_1's rmse: 0.174057\n",
      "[1400]\ttraining's rmse: 0.200785\tvalid_1's rmse: 0.155035\n",
      "[1600]\ttraining's rmse: 0.186878\tvalid_1's rmse: 0.145926\n",
      "[1800]\ttraining's rmse: 0.17597\tvalid_1's rmse: 0.140486\n",
      "[2000]\ttraining's rmse: 0.168104\tvalid_1's rmse: 0.137225\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.168104\tvalid_1's rmse: 0.137225\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.84823\tvalid_1's rmse: 1.89008\n",
      "[400]\ttraining's rmse: 1.16921\tvalid_1's rmse: 1.16649\n",
      "[600]\ttraining's rmse: 0.768258\tvalid_1's rmse: 0.732003\n",
      "[800]\ttraining's rmse: 0.539938\tvalid_1's rmse: 0.478277\n",
      "[1000]\ttraining's rmse: 0.416759\tvalid_1's rmse: 0.338466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200]\ttraining's rmse: 0.352933\tvalid_1's rmse: 0.267404\n",
      "[1400]\ttraining's rmse: 0.319499\tvalid_1's rmse: 0.234286\n",
      "[1600]\ttraining's rmse: 0.300156\tvalid_1's rmse: 0.218486\n",
      "[1800]\ttraining's rmse: 0.284878\tvalid_1's rmse: 0.207191\n",
      "[2000]\ttraining's rmse: 0.272571\tvalid_1's rmse: 0.202128\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.272571\tvalid_1's rmse: 0.202128\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.37111\tvalid_1's rmse: 2.17158\n",
      "[400]\ttraining's rmse: 1.51667\tvalid_1's rmse: 1.34055\n",
      "[600]\ttraining's rmse: 1.0163\tvalid_1's rmse: 0.846299\n",
      "[800]\ttraining's rmse: 0.738575\tvalid_1's rmse: 0.56237\n",
      "[1000]\ttraining's rmse: 0.594287\tvalid_1's rmse: 0.408803\n",
      "[1200]\ttraining's rmse: 0.520757\tvalid_1's rmse: 0.332414\n",
      "[1400]\ttraining's rmse: 0.482613\tvalid_1's rmse: 0.2976\n",
      "[1600]\ttraining's rmse: 0.459027\tvalid_1's rmse: 0.281516\n",
      "[1800]\ttraining's rmse: 0.439406\tvalid_1's rmse: 0.273392\n",
      "[2000]\ttraining's rmse: 0.423833\tvalid_1's rmse: 0.269212\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.423833\tvalid_1's rmse: 0.269212\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.26007\tvalid_1's rmse: 2.01939\n",
      "[400]\ttraining's rmse: 1.42826\tvalid_1's rmse: 1.2569\n",
      "[600]\ttraining's rmse: 0.935402\tvalid_1's rmse: 0.809739\n",
      "[800]\ttraining's rmse: 0.657875\tvalid_1's rmse: 0.557668\n",
      "[1000]\ttraining's rmse: 0.511726\tvalid_1's rmse: 0.428091\n",
      "[1200]\ttraining's rmse: 0.438859\tvalid_1's rmse: 0.367887\n",
      "[1400]\ttraining's rmse: 0.402217\tvalid_1's rmse: 0.341737\n",
      "[1600]\ttraining's rmse: 0.382394\tvalid_1's rmse: 0.329847\n",
      "[1800]\ttraining's rmse: 0.369795\tvalid_1's rmse: 0.322706\n",
      "[2000]\ttraining's rmse: 0.360162\tvalid_1's rmse: 0.318735\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.360162\tvalid_1's rmse: 0.318735\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.58951\tvalid_1's rmse: 1.55921\n",
      "[400]\ttraining's rmse: 0.993095\tvalid_1's rmse: 0.969369\n",
      "[600]\ttraining's rmse: 0.636825\tvalid_1's rmse: 0.614774\n",
      "[800]\ttraining's rmse: 0.429528\tvalid_1's rmse: 0.404253\n",
      "[1000]\ttraining's rmse: 0.314796\tvalid_1's rmse: 0.283972\n",
      "[1200]\ttraining's rmse: 0.255335\tvalid_1's rmse: 0.219636\n",
      "[1400]\ttraining's rmse: 0.225511\tvalid_1's rmse: 0.186506\n",
      "[1600]\ttraining's rmse: 0.210001\tvalid_1's rmse: 0.169871\n",
      "[1800]\ttraining's rmse: 0.201115\tvalid_1's rmse: 0.161067\n",
      "[2000]\ttraining's rmse: 0.19465\tvalid_1's rmse: 0.154893\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.19465\tvalid_1's rmse: 0.154893\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.56339\tvalid_1's rmse: 3.08016\n",
      "[400]\ttraining's rmse: 1.62986\tvalid_1's rmse: 1.94826\n",
      "[600]\ttraining's rmse: 1.07644\tvalid_1's rmse: 1.27041\n",
      "[800]\ttraining's rmse: 0.757922\tvalid_1's rmse: 0.87405\n",
      "[1000]\ttraining's rmse: 0.582155\tvalid_1's rmse: 0.657803\n",
      "[1200]\ttraining's rmse: 0.488318\tvalid_1's rmse: 0.548847\n",
      "[1400]\ttraining's rmse: 0.438238\tvalid_1's rmse: 0.495691\n",
      "[1600]\ttraining's rmse: 0.409387\tvalid_1's rmse: 0.467819\n",
      "[1800]\ttraining's rmse: 0.389309\tvalid_1's rmse: 0.450826\n",
      "[2000]\ttraining's rmse: 0.37382\tvalid_1's rmse: 0.437663\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.37382\tvalid_1's rmse: 0.437663\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.17879\tvalid_1's rmse: 2.37154\n",
      "[400]\ttraining's rmse: 1.38144\tvalid_1's rmse: 1.48699\n",
      "[600]\ttraining's rmse: 0.913457\tvalid_1's rmse: 0.960219\n",
      "[800]\ttraining's rmse: 0.64987\tvalid_1's rmse: 0.656996\n",
      "[1000]\ttraining's rmse: 0.512175\tvalid_1's rmse: 0.495549\n",
      "[1200]\ttraining's rmse: 0.444738\tvalid_1's rmse: 0.417202\n",
      "[1400]\ttraining's rmse: 0.411373\tvalid_1's rmse: 0.382051\n",
      "[1600]\ttraining's rmse: 0.393314\tvalid_1's rmse: 0.366635\n",
      "[1800]\ttraining's rmse: 0.380971\tvalid_1's rmse: 0.358992\n",
      "Early stopping, best iteration is:\n",
      "[1937]\ttraining's rmse: 0.373479\tvalid_1's rmse: 0.356809\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 200, max_bins: 200, WRMSSE:0.04394347805115416\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 200, max_bins: 200, WRMSSE:0.047130209091075036\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "10\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.25975\tvalid_1's rmse: 2.15949\n",
      "[400]\ttraining's rmse: 1.43065\tvalid_1's rmse: 1.36466\n",
      "[600]\ttraining's rmse: 0.938339\tvalid_1's rmse: 0.897273\n",
      "[800]\ttraining's rmse: 0.656155\tvalid_1's rmse: 0.632669\n",
      "[1000]\ttraining's rmse: 0.503691\tvalid_1's rmse: 0.492577\n",
      "[1200]\ttraining's rmse: 0.425817\tvalid_1's rmse: 0.42264\n",
      "[1400]\ttraining's rmse: 0.386364\tvalid_1's rmse: 0.388262\n",
      "[1600]\ttraining's rmse: 0.365184\tvalid_1's rmse: 0.369996\n",
      "[1800]\ttraining's rmse: 0.351527\tvalid_1's rmse: 0.359725\n",
      "[2000]\ttraining's rmse: 0.341356\tvalid_1's rmse: 0.352613\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.341356\tvalid_1's rmse: 0.352613\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.78065\tvalid_1's rmse: 1.89764\n",
      "[400]\ttraining's rmse: 1.12379\tvalid_1's rmse: 1.16795\n",
      "[600]\ttraining's rmse: 0.732102\tvalid_1's rmse: 0.727181\n",
      "[800]\ttraining's rmse: 0.50394\tvalid_1's rmse: 0.46779\n",
      "[1000]\ttraining's rmse: 0.378151\tvalid_1's rmse: 0.328308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200]\ttraining's rmse: 0.311818\tvalid_1's rmse: 0.264177\n",
      "[1400]\ttraining's rmse: 0.276583\tvalid_1's rmse: 0.240246\n",
      "[1600]\ttraining's rmse: 0.256037\tvalid_1's rmse: 0.231003\n",
      "[1800]\ttraining's rmse: 0.24256\tvalid_1's rmse: 0.225878\n",
      "[2000]\ttraining's rmse: 0.231907\tvalid_1's rmse: 0.223494\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.231907\tvalid_1's rmse: 0.223494\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.425\tvalid_1's rmse: 3.07624\n",
      "[400]\ttraining's rmse: 2.19954\tvalid_1's rmse: 1.91031\n",
      "[600]\ttraining's rmse: 1.47687\tvalid_1's rmse: 1.23855\n",
      "[800]\ttraining's rmse: 1.06969\tvalid_1's rmse: 0.877788\n",
      "[1000]\ttraining's rmse: 0.850803\tvalid_1's rmse: 0.700957\n",
      "[1200]\ttraining's rmse: 0.739558\tvalid_1's rmse: 0.623248\n",
      "[1400]\ttraining's rmse: 0.681994\tvalid_1's rmse: 0.592435\n",
      "[1600]\ttraining's rmse: 0.649266\tvalid_1's rmse: 0.581471\n",
      "[1800]\ttraining's rmse: 0.628908\tvalid_1's rmse: 0.576765\n",
      "Early stopping, best iteration is:\n",
      "[1909]\ttraining's rmse: 0.620245\tvalid_1's rmse: 0.575211\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.19586\tvalid_1's rmse: 1.15691\n",
      "[400]\ttraining's rmse: 0.754491\tvalid_1's rmse: 0.713813\n",
      "[600]\ttraining's rmse: 0.492675\tvalid_1's rmse: 0.449147\n",
      "[800]\ttraining's rmse: 0.341777\tvalid_1's rmse: 0.29479\n",
      "[1000]\ttraining's rmse: 0.258698\tvalid_1's rmse: 0.210759\n",
      "[1200]\ttraining's rmse: 0.215016\tvalid_1's rmse: 0.169284\n",
      "[1400]\ttraining's rmse: 0.192348\tvalid_1's rmse: 0.150874\n",
      "[1600]\ttraining's rmse: 0.17799\tvalid_1's rmse: 0.142592\n",
      "[1800]\ttraining's rmse: 0.166657\tvalid_1's rmse: 0.137851\n",
      "[2000]\ttraining's rmse: 0.158242\tvalid_1's rmse: 0.135237\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.158242\tvalid_1's rmse: 0.135237\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.84721\tvalid_1's rmse: 1.89007\n",
      "[400]\ttraining's rmse: 1.16382\tvalid_1's rmse: 1.16438\n",
      "[600]\ttraining's rmse: 0.757648\tvalid_1's rmse: 0.729786\n",
      "[800]\ttraining's rmse: 0.524657\tvalid_1's rmse: 0.476953\n",
      "[1000]\ttraining's rmse: 0.397332\tvalid_1's rmse: 0.336864\n",
      "[1200]\ttraining's rmse: 0.32983\tvalid_1's rmse: 0.265352\n",
      "[1400]\ttraining's rmse: 0.294439\tvalid_1's rmse: 0.232359\n",
      "[1600]\ttraining's rmse: 0.274038\tvalid_1's rmse: 0.216707\n",
      "[1800]\ttraining's rmse: 0.257924\tvalid_1's rmse: 0.205983\n",
      "[2000]\ttraining's rmse: 0.245295\tvalid_1's rmse: 0.200858\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.245295\tvalid_1's rmse: 0.200858\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.36567\tvalid_1's rmse: 2.15841\n",
      "[400]\ttraining's rmse: 1.50476\tvalid_1's rmse: 1.31925\n",
      "[600]\ttraining's rmse: 0.996988\tvalid_1's rmse: 0.81884\n",
      "[800]\ttraining's rmse: 0.711236\tvalid_1's rmse: 0.531605\n",
      "[1000]\ttraining's rmse: 0.560313\tvalid_1's rmse: 0.376026\n",
      "[1200]\ttraining's rmse: 0.482101\tvalid_1's rmse: 0.300388\n",
      "[1400]\ttraining's rmse: 0.440929\tvalid_1's rmse: 0.267847\n",
      "[1600]\ttraining's rmse: 0.415185\tvalid_1's rmse: 0.254086\n",
      "[1800]\ttraining's rmse: 0.39327\tvalid_1's rmse: 0.247299\n",
      "[2000]\ttraining's rmse: 0.376543\tvalid_1's rmse: 0.243763\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.376543\tvalid_1's rmse: 0.243763\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.2569\tvalid_1's rmse: 2.027\n",
      "[400]\ttraining's rmse: 1.42619\tvalid_1's rmse: 1.26297\n",
      "[600]\ttraining's rmse: 0.934258\tvalid_1's rmse: 0.81047\n",
      "[800]\ttraining's rmse: 0.655082\tvalid_1's rmse: 0.550636\n",
      "[1000]\ttraining's rmse: 0.50513\tvalid_1's rmse: 0.409612\n",
      "[1200]\ttraining's rmse: 0.428464\tvalid_1's rmse: 0.338682\n",
      "[1400]\ttraining's rmse: 0.388428\tvalid_1's rmse: 0.304933\n",
      "[1600]\ttraining's rmse: 0.366259\tvalid_1's rmse: 0.289292\n",
      "[1800]\ttraining's rmse: 0.351528\tvalid_1's rmse: 0.279821\n",
      "[2000]\ttraining's rmse: 0.339731\tvalid_1's rmse: 0.274244\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.339731\tvalid_1's rmse: 0.274244\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.58812\tvalid_1's rmse: 1.55304\n",
      "[400]\ttraining's rmse: 0.98953\tvalid_1's rmse: 0.96016\n",
      "[600]\ttraining's rmse: 0.630819\tvalid_1's rmse: 0.603763\n",
      "[800]\ttraining's rmse: 0.420152\tvalid_1's rmse: 0.39166\n",
      "[1000]\ttraining's rmse: 0.302256\tvalid_1's rmse: 0.271818\n",
      "[1200]\ttraining's rmse: 0.240062\tvalid_1's rmse: 0.208372\n",
      "[1400]\ttraining's rmse: 0.20859\tvalid_1's rmse: 0.176815\n",
      "[1600]\ttraining's rmse: 0.192147\tvalid_1's rmse: 0.160885\n",
      "[1800]\ttraining's rmse: 0.182595\tvalid_1's rmse: 0.152333\n",
      "[2000]\ttraining's rmse: 0.175711\tvalid_1's rmse: 0.146019\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.175711\tvalid_1's rmse: 0.146019\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.56151\tvalid_1's rmse: 3.07863\n",
      "[400]\ttraining's rmse: 1.62621\tvalid_1's rmse: 1.94836\n",
      "[600]\ttraining's rmse: 1.07082\tvalid_1's rmse: 1.26901\n",
      "[800]\ttraining's rmse: 0.750309\tvalid_1's rmse: 0.870755\n",
      "[1000]\ttraining's rmse: 0.57117\tvalid_1's rmse: 0.649899\n",
      "[1200]\ttraining's rmse: 0.475374\tvalid_1's rmse: 0.537581\n",
      "[1400]\ttraining's rmse: 0.423146\tvalid_1's rmse: 0.481242\n",
      "[1600]\ttraining's rmse: 0.393252\tvalid_1's rmse: 0.452196\n",
      "[1800]\ttraining's rmse: 0.371522\tvalid_1's rmse: 0.433822\n",
      "[2000]\ttraining's rmse: 0.354837\tvalid_1's rmse: 0.419515\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.354837\tvalid_1's rmse: 0.419515\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.17446\tvalid_1's rmse: 2.35726\n",
      "[400]\ttraining's rmse: 1.37084\tvalid_1's rmse: 1.45957\n",
      "[600]\ttraining's rmse: 0.897134\tvalid_1's rmse: 0.928083\n",
      "[800]\ttraining's rmse: 0.62684\tvalid_1's rmse: 0.622392\n",
      "[1000]\ttraining's rmse: 0.483903\tvalid_1's rmse: 0.464013\n",
      "[1200]\ttraining's rmse: 0.412534\tvalid_1's rmse: 0.389523\n",
      "[1400]\ttraining's rmse: 0.377071\tvalid_1's rmse: 0.357941\n",
      "[1600]\ttraining's rmse: 0.358055\tvalid_1's rmse: 0.344301\n",
      "[1800]\ttraining's rmse: 0.345506\tvalid_1's rmse: 0.338054\n",
      "[2000]\ttraining's rmse: 0.334961\tvalid_1's rmse: 0.334254\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.334961\tvalid_1's rmse: 0.334254\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 200, max_bins: 250, WRMSSE:0.040875309392276474\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 200, max_bins: 250, WRMSSE:0.04352314938947553\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "11\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.25628\tvalid_1's rmse: 2.15808\n",
      "[400]\ttraining's rmse: 1.4242\tvalid_1's rmse: 1.35921\n",
      "[600]\ttraining's rmse: 0.930158\tvalid_1's rmse: 0.888075\n",
      "[800]\ttraining's rmse: 0.644972\tvalid_1's rmse: 0.620419\n",
      "[1000]\ttraining's rmse: 0.487964\tvalid_1's rmse: 0.478887\n",
      "[1200]\ttraining's rmse: 0.406108\tvalid_1's rmse: 0.408781\n",
      "[1400]\ttraining's rmse: 0.363269\tvalid_1's rmse: 0.374519\n",
      "[1600]\ttraining's rmse: 0.339295\tvalid_1's rmse: 0.357543\n",
      "[1800]\ttraining's rmse: 0.322792\tvalid_1's rmse: 0.347781\n",
      "[2000]\ttraining's rmse: 0.309932\tvalid_1's rmse: 0.341154\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.309932\tvalid_1's rmse: 0.341154\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.78102\tvalid_1's rmse: 1.90239\n",
      "[400]\ttraining's rmse: 1.12193\tvalid_1's rmse: 1.17323\n",
      "[600]\ttraining's rmse: 0.728185\tvalid_1's rmse: 0.730892\n",
      "[800]\ttraining's rmse: 0.498376\tvalid_1's rmse: 0.469771\n",
      "[1000]\ttraining's rmse: 0.370499\tvalid_1's rmse: 0.326923\n",
      "[1200]\ttraining's rmse: 0.302647\tvalid_1's rmse: 0.257874\n",
      "[1400]\ttraining's rmse: 0.266399\tvalid_1's rmse: 0.230002\n",
      "[1600]\ttraining's rmse: 0.245151\tvalid_1's rmse: 0.219319\n",
      "[1800]\ttraining's rmse: 0.230908\tvalid_1's rmse: 0.213837\n",
      "[2000]\ttraining's rmse: 0.21974\tvalid_1's rmse: 0.210169\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.21974\tvalid_1's rmse: 0.210169\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.42026\tvalid_1's rmse: 3.07271\n",
      "[400]\ttraining's rmse: 2.18615\tvalid_1's rmse: 1.89818\n",
      "[600]\ttraining's rmse: 1.45545\tvalid_1's rmse: 1.21962\n",
      "[800]\ttraining's rmse: 1.04049\tvalid_1's rmse: 0.85315\n",
      "[1000]\ttraining's rmse: 0.813855\tvalid_1's rmse: 0.67094\n",
      "[1200]\ttraining's rmse: 0.698199\tvalid_1's rmse: 0.589209\n",
      "[1400]\ttraining's rmse: 0.638953\tvalid_1's rmse: 0.554494\n",
      "[1600]\ttraining's rmse: 0.606471\tvalid_1's rmse: 0.53992\n",
      "[1800]\ttraining's rmse: 0.585793\tvalid_1's rmse: 0.533117\n",
      "[2000]\ttraining's rmse: 0.570686\tvalid_1's rmse: 0.529148\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.570686\tvalid_1's rmse: 0.529148\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.19553\tvalid_1's rmse: 1.15815\n",
      "[400]\ttraining's rmse: 0.753212\tvalid_1's rmse: 0.715783\n",
      "[600]\ttraining's rmse: 0.489779\tvalid_1's rmse: 0.450838\n",
      "[800]\ttraining's rmse: 0.337103\tvalid_1's rmse: 0.296243\n",
      "[1000]\ttraining's rmse: 0.252187\tvalid_1's rmse: 0.21117\n",
      "[1200]\ttraining's rmse: 0.2064\tvalid_1's rmse: 0.167271\n",
      "[1400]\ttraining's rmse: 0.182145\tvalid_1's rmse: 0.145769\n",
      "[1600]\ttraining's rmse: 0.167418\tvalid_1's rmse: 0.135313\n",
      "[1800]\ttraining's rmse: 0.15558\tvalid_1's rmse: 0.128549\n",
      "[2000]\ttraining's rmse: 0.14733\tvalid_1's rmse: 0.124729\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.14733\tvalid_1's rmse: 0.124729\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.84597\tvalid_1's rmse: 1.88652\n",
      "[400]\ttraining's rmse: 1.16211\tvalid_1's rmse: 1.15984\n",
      "[600]\ttraining's rmse: 0.752279\tvalid_1's rmse: 0.722489\n",
      "[800]\ttraining's rmse: 0.513984\tvalid_1's rmse: 0.466639\n",
      "[1000]\ttraining's rmse: 0.382166\tvalid_1's rmse: 0.324237\n",
      "[1200]\ttraining's rmse: 0.311187\tvalid_1's rmse: 0.25035\n",
      "[1400]\ttraining's rmse: 0.273462\tvalid_1's rmse: 0.216468\n",
      "[1600]\ttraining's rmse: 0.251727\tvalid_1's rmse: 0.200213\n",
      "[1800]\ttraining's rmse: 0.235124\tvalid_1's rmse: 0.190304\n",
      "[2000]\ttraining's rmse: 0.222083\tvalid_1's rmse: 0.185212\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.222083\tvalid_1's rmse: 0.185212\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.36075\tvalid_1's rmse: 2.16564\n",
      "[400]\ttraining's rmse: 1.49478\tvalid_1's rmse: 1.33003\n",
      "[600]\ttraining's rmse: 0.979754\tvalid_1's rmse: 0.827292\n",
      "[800]\ttraining's rmse: 0.687697\tvalid_1's rmse: 0.532526\n",
      "[1000]\ttraining's rmse: 0.531537\tvalid_1's rmse: 0.367475\n",
      "[1200]\ttraining's rmse: 0.44996\tvalid_1's rmse: 0.282585\n",
      "[1400]\ttraining's rmse: 0.406701\tvalid_1's rmse: 0.243676\n",
      "[1600]\ttraining's rmse: 0.380375\tvalid_1's rmse: 0.226369\n",
      "[1800]\ttraining's rmse: 0.35904\tvalid_1's rmse: 0.21869\n",
      "[2000]\ttraining's rmse: 0.342015\tvalid_1's rmse: 0.215737\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.342015\tvalid_1's rmse: 0.215737\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.2545\tvalid_1's rmse: 2.02297\n",
      "[400]\ttraining's rmse: 1.41674\tvalid_1's rmse: 1.25944\n",
      "[600]\ttraining's rmse: 0.918855\tvalid_1's rmse: 0.806303\n",
      "[800]\ttraining's rmse: 0.633507\tvalid_1's rmse: 0.545607\n",
      "[1000]\ttraining's rmse: 0.479358\tvalid_1's rmse: 0.405349\n",
      "[1200]\ttraining's rmse: 0.400794\tvalid_1's rmse: 0.336021\n",
      "[1400]\ttraining's rmse: 0.360796\tvalid_1's rmse: 0.304559\n",
      "[1600]\ttraining's rmse: 0.339142\tvalid_1's rmse: 0.290348\n",
      "[1800]\ttraining's rmse: 0.325715\tvalid_1's rmse: 0.281259\n",
      "[2000]\ttraining's rmse: 0.315336\tvalid_1's rmse: 0.276144\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.315336\tvalid_1's rmse: 0.276144\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.58828\tvalid_1's rmse: 1.55804\n",
      "[400]\ttraining's rmse: 0.98825\tvalid_1's rmse: 0.964876\n",
      "[600]\ttraining's rmse: 0.62659\tvalid_1's rmse: 0.605542\n",
      "[800]\ttraining's rmse: 0.413114\tvalid_1's rmse: 0.39145\n",
      "[1000]\ttraining's rmse: 0.291792\tvalid_1's rmse: 0.268148\n",
      "[1200]\ttraining's rmse: 0.226839\tvalid_1's rmse: 0.201708\n",
      "[1400]\ttraining's rmse: 0.193494\tvalid_1's rmse: 0.167196\n",
      "[1600]\ttraining's rmse: 0.175941\tvalid_1's rmse: 0.149246\n",
      "[1800]\ttraining's rmse: 0.166\tvalid_1's rmse: 0.139565\n",
      "[2000]\ttraining's rmse: 0.15906\tvalid_1's rmse: 0.132982\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.15906\tvalid_1's rmse: 0.132982\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.56093\tvalid_1's rmse: 3.08039\n",
      "[400]\ttraining's rmse: 1.62442\tvalid_1's rmse: 1.94836\n",
      "[600]\ttraining's rmse: 1.06696\tvalid_1's rmse: 1.26702\n",
      "[800]\ttraining's rmse: 0.743592\tvalid_1's rmse: 0.865735\n",
      "[1000]\ttraining's rmse: 0.562053\tvalid_1's rmse: 0.642296\n",
      "[1200]\ttraining's rmse: 0.463918\tvalid_1's rmse: 0.525842\n",
      "[1400]\ttraining's rmse: 0.410088\tvalid_1's rmse: 0.464945\n",
      "[1600]\ttraining's rmse: 0.378682\tvalid_1's rmse: 0.431302\n",
      "[1800]\ttraining's rmse: 0.354723\tvalid_1's rmse: 0.407519\n",
      "[2000]\ttraining's rmse: 0.337362\tvalid_1's rmse: 0.390563\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.337362\tvalid_1's rmse: 0.390563\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 300\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.17327\tvalid_1's rmse: 2.36346\n",
      "[400]\ttraining's rmse: 1.36684\tvalid_1's rmse: 1.4667\n",
      "[600]\ttraining's rmse: 0.889076\tvalid_1's rmse: 0.931607\n",
      "[800]\ttraining's rmse: 0.614061\tvalid_1's rmse: 0.619963\n",
      "[1000]\ttraining's rmse: 0.466834\tvalid_1's rmse: 0.453254\n",
      "[1200]\ttraining's rmse: 0.392586\tvalid_1's rmse: 0.371876\n",
      "[1400]\ttraining's rmse: 0.355355\tvalid_1's rmse: 0.335013\n",
      "[1600]\ttraining's rmse: 0.335139\tvalid_1's rmse: 0.318229\n",
      "[1800]\ttraining's rmse: 0.321732\tvalid_1's rmse: 0.310066\n",
      "[2000]\ttraining's rmse: 0.310223\tvalid_1's rmse: 0.305785\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.310223\tvalid_1's rmse: 0.305785\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 200, max_bins: 300, WRMSSE:0.03860734243049355\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 200, max_bins: 300, WRMSSE:0.041153497978145326\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "12\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.25242\tvalid_1's rmse: 2.15434\n",
      "[400]\ttraining's rmse: 1.41795\tvalid_1's rmse: 1.3531\n",
      "[600]\ttraining's rmse: 0.919678\tvalid_1's rmse: 0.87877\n",
      "[800]\ttraining's rmse: 0.629116\tvalid_1's rmse: 0.606975\n",
      "[1000]\ttraining's rmse: 0.467466\tvalid_1's rmse: 0.46227\n",
      "[1200]\ttraining's rmse: 0.382628\tvalid_1's rmse: 0.390655\n",
      "[1400]\ttraining's rmse: 0.33849\tvalid_1's rmse: 0.355883\n",
      "[1600]\ttraining's rmse: 0.313816\tvalid_1's rmse: 0.338401\n",
      "[1800]\ttraining's rmse: 0.296421\tvalid_1's rmse: 0.328003\n",
      "[2000]\ttraining's rmse: 0.283077\tvalid_1's rmse: 0.322078\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.283077\tvalid_1's rmse: 0.322078\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.77976\tvalid_1's rmse: 1.90248\n",
      "[400]\ttraining's rmse: 1.11941\tvalid_1's rmse: 1.17235\n",
      "[600]\ttraining's rmse: 0.721703\tvalid_1's rmse: 0.726391\n",
      "[800]\ttraining's rmse: 0.486004\tvalid_1's rmse: 0.459147\n",
      "[1000]\ttraining's rmse: 0.352322\tvalid_1's rmse: 0.309187\n",
      "[1200]\ttraining's rmse: 0.279582\tvalid_1's rmse: 0.233348\n",
      "[1400]\ttraining's rmse: 0.239789\tvalid_1's rmse: 0.201203\n",
      "[1600]\ttraining's rmse: 0.215952\tvalid_1's rmse: 0.188213\n",
      "[1800]\ttraining's rmse: 0.199691\tvalid_1's rmse: 0.181187\n",
      "[2000]\ttraining's rmse: 0.186692\tvalid_1's rmse: 0.176112\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.186692\tvalid_1's rmse: 0.176112\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.42085\tvalid_1's rmse: 3.07874\n",
      "[400]\ttraining's rmse: 2.18456\tvalid_1's rmse: 1.90898\n",
      "[600]\ttraining's rmse: 1.44452\tvalid_1's rmse: 1.22074\n",
      "[800]\ttraining's rmse: 1.01567\tvalid_1's rmse: 0.833524\n",
      "[1000]\ttraining's rmse: 0.778452\tvalid_1's rmse: 0.629794\n",
      "[1200]\ttraining's rmse: 0.655119\tvalid_1's rmse: 0.531325\n",
      "[1400]\ttraining's rmse: 0.59039\tvalid_1's rmse: 0.485771\n",
      "[1600]\ttraining's rmse: 0.554029\tvalid_1's rmse: 0.464038\n",
      "[1800]\ttraining's rmse: 0.530782\tvalid_1's rmse: 0.451443\n",
      "[2000]\ttraining's rmse: 0.513098\tvalid_1's rmse: 0.442915\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.513098\tvalid_1's rmse: 0.442915\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.19544\tvalid_1's rmse: 1.15893\n",
      "[400]\ttraining's rmse: 0.752748\tvalid_1's rmse: 0.716566\n",
      "[600]\ttraining's rmse: 0.488509\tvalid_1's rmse: 0.450389\n",
      "[800]\ttraining's rmse: 0.335064\tvalid_1's rmse: 0.29375\n",
      "[1000]\ttraining's rmse: 0.249209\tvalid_1's rmse: 0.205578\n",
      "[1200]\ttraining's rmse: 0.202552\tvalid_1's rmse: 0.158508\n",
      "[1400]\ttraining's rmse: 0.177448\tvalid_1's rmse: 0.134804\n",
      "[1600]\ttraining's rmse: 0.16217\tvalid_1's rmse: 0.122906\n",
      "[1800]\ttraining's rmse: 0.149361\tvalid_1's rmse: 0.115747\n",
      "[2000]\ttraining's rmse: 0.140573\tvalid_1's rmse: 0.111292\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.140573\tvalid_1's rmse: 0.111292\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.84423\tvalid_1's rmse: 1.88959\n",
      "[400]\ttraining's rmse: 1.1579\tvalid_1's rmse: 1.16282\n",
      "[600]\ttraining's rmse: 0.747022\tvalid_1's rmse: 0.725606\n",
      "[800]\ttraining's rmse: 0.507826\tvalid_1's rmse: 0.468738\n",
      "[1000]\ttraining's rmse: 0.374\tvalid_1's rmse: 0.323379\n",
      "[1200]\ttraining's rmse: 0.30052\tvalid_1's rmse: 0.24771\n",
      "[1400]\ttraining's rmse: 0.260511\tvalid_1's rmse: 0.211059\n",
      "[1600]\ttraining's rmse: 0.236455\tvalid_1's rmse: 0.192401\n",
      "[1800]\ttraining's rmse: 0.217817\tvalid_1's rmse: 0.179264\n",
      "[2000]\ttraining's rmse: 0.203356\tvalid_1's rmse: 0.170855\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.203356\tvalid_1's rmse: 0.170855\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.35948\tvalid_1's rmse: 2.16647\n",
      "[400]\ttraining's rmse: 1.49088\tvalid_1's rmse: 1.33098\n",
      "[600]\ttraining's rmse: 0.970847\tvalid_1's rmse: 0.82431\n",
      "[800]\ttraining's rmse: 0.670554\tvalid_1's rmse: 0.524783\n",
      "[1000]\ttraining's rmse: 0.503341\tvalid_1's rmse: 0.35207\n",
      "[1200]\ttraining's rmse: 0.412323\tvalid_1's rmse: 0.257532\n",
      "[1400]\ttraining's rmse: 0.363632\tvalid_1's rmse: 0.210235\n",
      "[1600]\ttraining's rmse: 0.3345\tvalid_1's rmse: 0.187694\n",
      "[1800]\ttraining's rmse: 0.310949\tvalid_1's rmse: 0.176106\n",
      "[2000]\ttraining's rmse: 0.292832\tvalid_1's rmse: 0.170617\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.292832\tvalid_1's rmse: 0.170617\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.25068\tvalid_1's rmse: 2.02648\n",
      "[400]\ttraining's rmse: 1.4128\tvalid_1's rmse: 1.26058\n",
      "[600]\ttraining's rmse: 0.908654\tvalid_1's rmse: 0.802742\n",
      "[800]\ttraining's rmse: 0.614945\tvalid_1's rmse: 0.534656\n",
      "[1000]\ttraining's rmse: 0.452865\tvalid_1's rmse: 0.384663\n",
      "[1200]\ttraining's rmse: 0.367227\tvalid_1's rmse: 0.304756\n",
      "[1400]\ttraining's rmse: 0.321149\tvalid_1's rmse: 0.264334\n",
      "[1600]\ttraining's rmse: 0.295655\tvalid_1's rmse: 0.243518\n",
      "[1800]\ttraining's rmse: 0.278914\tvalid_1's rmse: 0.229872\n",
      "[2000]\ttraining's rmse: 0.266332\tvalid_1's rmse: 0.221699\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.266332\tvalid_1's rmse: 0.221699\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.58727\tvalid_1's rmse: 1.55713\n",
      "[400]\ttraining's rmse: 0.985948\tvalid_1's rmse: 0.963355\n",
      "[600]\ttraining's rmse: 0.622832\tvalid_1's rmse: 0.603685\n",
      "[800]\ttraining's rmse: 0.407513\tvalid_1's rmse: 0.388763\n",
      "[1000]\ttraining's rmse: 0.283901\tvalid_1's rmse: 0.263999\n",
      "[1200]\ttraining's rmse: 0.216577\tvalid_1's rmse: 0.195741\n",
      "[1400]\ttraining's rmse: 0.181609\tvalid_1's rmse: 0.160504\n",
      "[1600]\ttraining's rmse: 0.1631\tvalid_1's rmse: 0.142319\n",
      "[1800]\ttraining's rmse: 0.152635\tvalid_1's rmse: 0.132409\n",
      "[2000]\ttraining's rmse: 0.145474\tvalid_1's rmse: 0.125626\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.145474\tvalid_1's rmse: 0.125626\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.55905\tvalid_1's rmse: 3.07384\n",
      "[400]\ttraining's rmse: 1.62043\tvalid_1's rmse: 1.93632\n",
      "[600]\ttraining's rmse: 1.06092\tvalid_1's rmse: 1.2519\n",
      "[800]\ttraining's rmse: 0.734401\tvalid_1's rmse: 0.846382\n",
      "[1000]\ttraining's rmse: 0.549567\tvalid_1's rmse: 0.619771\n",
      "[1200]\ttraining's rmse: 0.448412\tvalid_1's rmse: 0.502149\n",
      "[1400]\ttraining's rmse: 0.393457\tvalid_1's rmse: 0.441961\n",
      "[1600]\ttraining's rmse: 0.361959\tvalid_1's rmse: 0.411569\n",
      "[1800]\ttraining's rmse: 0.338392\tvalid_1's rmse: 0.391626\n",
      "[2000]\ttraining's rmse: 0.320897\tvalid_1's rmse: 0.377642\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.320897\tvalid_1's rmse: 0.377642\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 400\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.17164\tvalid_1's rmse: 2.35788\n",
      "[400]\ttraining's rmse: 1.36395\tvalid_1's rmse: 1.45763\n",
      "[600]\ttraining's rmse: 0.882432\tvalid_1's rmse: 0.915317\n",
      "[800]\ttraining's rmse: 0.600385\tvalid_1's rmse: 0.591079\n",
      "[1000]\ttraining's rmse: 0.44449\tvalid_1's rmse: 0.408256\n",
      "[1200]\ttraining's rmse: 0.363767\tvalid_1's rmse: 0.313733\n",
      "[1400]\ttraining's rmse: 0.322839\tvalid_1's rmse: 0.269133\n",
      "[1600]\ttraining's rmse: 0.300654\tvalid_1's rmse: 0.24825\n",
      "[1800]\ttraining's rmse: 0.286597\tvalid_1's rmse: 0.238852\n",
      "[2000]\ttraining's rmse: 0.274728\tvalid_1's rmse: 0.233841\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.274728\tvalid_1's rmse: 0.233841\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 200, max_bins: 400, WRMSSE:0.0348957261137427\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 200, max_bins: 400, WRMSSE:0.03781561785170306\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "13\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.2508\tvalid_1's rmse: 2.14967\n",
      "[400]\ttraining's rmse: 1.41344\tvalid_1's rmse: 1.34465\n",
      "[600]\ttraining's rmse: 0.911726\tvalid_1's rmse: 0.86687\n",
      "[800]\ttraining's rmse: 0.615742\tvalid_1's rmse: 0.59128\n",
      "[1000]\ttraining's rmse: 0.449688\tvalid_1's rmse: 0.44204\n",
      "[1200]\ttraining's rmse: 0.361791\tvalid_1's rmse: 0.366643\n",
      "[1400]\ttraining's rmse: 0.315861\tvalid_1's rmse: 0.330278\n",
      "[1600]\ttraining's rmse: 0.290682\tvalid_1's rmse: 0.312542\n",
      "[1800]\ttraining's rmse: 0.2744\tvalid_1's rmse: 0.302725\n",
      "[2000]\ttraining's rmse: 0.262232\tvalid_1's rmse: 0.296481\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.262232\tvalid_1's rmse: 0.296481\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.77842\tvalid_1's rmse: 1.90093\n",
      "[400]\ttraining's rmse: 1.1171\tvalid_1's rmse: 1.17174\n",
      "[600]\ttraining's rmse: 0.718252\tvalid_1's rmse: 0.72568\n",
      "[800]\ttraining's rmse: 0.480488\tvalid_1's rmse: 0.456637\n",
      "[1000]\ttraining's rmse: 0.344858\tvalid_1's rmse: 0.304585\n",
      "[1200]\ttraining's rmse: 0.270308\tvalid_1's rmse: 0.226265\n",
      "[1400]\ttraining's rmse: 0.22904\tvalid_1's rmse: 0.191379\n",
      "[1600]\ttraining's rmse: 0.204107\tvalid_1's rmse: 0.176489\n",
      "[1800]\ttraining's rmse: 0.187401\tvalid_1's rmse: 0.167412\n",
      "[2000]\ttraining's rmse: 0.174225\tvalid_1's rmse: 0.160608\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.174225\tvalid_1's rmse: 0.160608\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.41619\tvalid_1's rmse: 3.06529\n",
      "[400]\ttraining's rmse: 2.17176\tvalid_1's rmse: 1.87587\n",
      "[600]\ttraining's rmse: 1.42961\tvalid_1's rmse: 1.18251\n",
      "[800]\ttraining's rmse: 0.998864\tvalid_1's rmse: 0.797519\n",
      "[1000]\ttraining's rmse: 0.758196\tvalid_1's rmse: 0.602474\n",
      "[1200]\ttraining's rmse: 0.630385\tvalid_1's rmse: 0.512432\n",
      "[1400]\ttraining's rmse: 0.562168\tvalid_1's rmse: 0.472892\n",
      "[1600]\ttraining's rmse: 0.522327\tvalid_1's rmse: 0.455657\n",
      "[1800]\ttraining's rmse: 0.48754\tvalid_1's rmse: 0.440509\n",
      "[2000]\ttraining's rmse: 0.463266\tvalid_1's rmse: 0.431293\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.463266\tvalid_1's rmse: 0.431293\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.1949\tvalid_1's rmse: 1.15827\n",
      "[400]\ttraining's rmse: 0.751417\tvalid_1's rmse: 0.715076\n",
      "[600]\ttraining's rmse: 0.486024\tvalid_1's rmse: 0.448461\n",
      "[800]\ttraining's rmse: 0.330233\tvalid_1's rmse: 0.290166\n",
      "[1000]\ttraining's rmse: 0.241296\tvalid_1's rmse: 0.199391\n",
      "[1200]\ttraining's rmse: 0.192357\tvalid_1's rmse: 0.150115\n",
      "[1400]\ttraining's rmse: 0.165892\tvalid_1's rmse: 0.12485\n",
      "[1600]\ttraining's rmse: 0.149702\tvalid_1's rmse: 0.111614\n",
      "[1800]\ttraining's rmse: 0.136959\tvalid_1's rmse: 0.102984\n",
      "[2000]\ttraining's rmse: 0.127752\tvalid_1's rmse: 0.0976559\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.127752\tvalid_1's rmse: 0.0976559\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.84345\tvalid_1's rmse: 1.88928\n",
      "[400]\ttraining's rmse: 1.15685\tvalid_1's rmse: 1.16426\n",
      "[600]\ttraining's rmse: 0.744973\tvalid_1's rmse: 0.727133\n",
      "[800]\ttraining's rmse: 0.503351\tvalid_1's rmse: 0.4683\n",
      "[1000]\ttraining's rmse: 0.367198\tvalid_1's rmse: 0.319033\n",
      "[1200]\ttraining's rmse: 0.291705\tvalid_1's rmse: 0.237112\n",
      "[1400]\ttraining's rmse: 0.24992\tvalid_1's rmse: 0.194874\n",
      "[1600]\ttraining's rmse: 0.225102\tvalid_1's rmse: 0.172115\n",
      "[1800]\ttraining's rmse: 0.205312\tvalid_1's rmse: 0.155299\n",
      "[2000]\ttraining's rmse: 0.189733\tvalid_1's rmse: 0.144719\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.189733\tvalid_1's rmse: 0.144719\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.358\tvalid_1's rmse: 2.16391\n",
      "[400]\ttraining's rmse: 1.48655\tvalid_1's rmse: 1.32755\n",
      "[600]\ttraining's rmse: 0.959729\tvalid_1's rmse: 0.820916\n",
      "[800]\ttraining's rmse: 0.651871\tvalid_1's rmse: 0.519825\n",
      "[1000]\ttraining's rmse: 0.480043\tvalid_1's rmse: 0.344384\n",
      "[1200]\ttraining's rmse: 0.386435\tvalid_1's rmse: 0.247489\n",
      "[1400]\ttraining's rmse: 0.335622\tvalid_1's rmse: 0.198233\n",
      "[1600]\ttraining's rmse: 0.30539\tvalid_1's rmse: 0.174878\n",
      "[1800]\ttraining's rmse: 0.280309\tvalid_1's rmse: 0.161545\n",
      "[2000]\ttraining's rmse: 0.260683\tvalid_1's rmse: 0.15422\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.260683\tvalid_1's rmse: 0.15422\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.24854\tvalid_1's rmse: 2.02651\n",
      "[400]\ttraining's rmse: 1.40632\tvalid_1's rmse: 1.26085\n",
      "[600]\ttraining's rmse: 0.900542\tvalid_1's rmse: 0.799044\n",
      "[800]\ttraining's rmse: 0.604613\tvalid_1's rmse: 0.525808\n",
      "[1000]\ttraining's rmse: 0.438696\tvalid_1's rmse: 0.371478\n",
      "[1200]\ttraining's rmse: 0.348511\tvalid_1's rmse: 0.287546\n",
      "[1400]\ttraining's rmse: 0.299644\tvalid_1's rmse: 0.245071\n",
      "[1600]\ttraining's rmse: 0.271404\tvalid_1's rmse: 0.222756\n",
      "[1800]\ttraining's rmse: 0.251171\tvalid_1's rmse: 0.207842\n",
      "[2000]\ttraining's rmse: 0.237396\tvalid_1's rmse: 0.198585\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.237396\tvalid_1's rmse: 0.198585\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.58683\tvalid_1's rmse: 1.55449\n",
      "[400]\ttraining's rmse: 0.984471\tvalid_1's rmse: 0.961325\n",
      "[600]\ttraining's rmse: 0.620411\tvalid_1's rmse: 0.601663\n",
      "[800]\ttraining's rmse: 0.403333\tvalid_1's rmse: 0.384854\n",
      "[1000]\ttraining's rmse: 0.277564\tvalid_1's rmse: 0.258488\n",
      "[1200]\ttraining's rmse: 0.208212\tvalid_1's rmse: 0.188951\n",
      "[1400]\ttraining's rmse: 0.171726\tvalid_1's rmse: 0.152689\n",
      "[1600]\ttraining's rmse: 0.152581\tvalid_1's rmse: 0.134131\n",
      "[1800]\ttraining's rmse: 0.141655\tvalid_1's rmse: 0.124178\n",
      "[2000]\ttraining's rmse: 0.134092\tvalid_1's rmse: 0.117101\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.134092\tvalid_1's rmse: 0.117101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.55708\tvalid_1's rmse: 3.07043\n",
      "[400]\ttraining's rmse: 1.61602\tvalid_1's rmse: 1.92975\n",
      "[600]\ttraining's rmse: 1.05432\tvalid_1's rmse: 1.24786\n",
      "[800]\ttraining's rmse: 0.726031\tvalid_1's rmse: 0.843973\n",
      "[1000]\ttraining's rmse: 0.538593\tvalid_1's rmse: 0.617875\n",
      "[1200]\ttraining's rmse: 0.435121\tvalid_1's rmse: 0.50112\n",
      "[1400]\ttraining's rmse: 0.378611\tvalid_1's rmse: 0.440386\n",
      "[1600]\ttraining's rmse: 0.345742\tvalid_1's rmse: 0.409608\n",
      "[1800]\ttraining's rmse: 0.32081\tvalid_1's rmse: 0.387803\n",
      "[2000]\ttraining's rmse: 0.301712\tvalid_1's rmse: 0.37178\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.301712\tvalid_1's rmse: 0.37178\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 200, max_bins: 500\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.17028\tvalid_1's rmse: 2.35582\n",
      "[400]\ttraining's rmse: 1.36081\tvalid_1's rmse: 1.45283\n",
      "[600]\ttraining's rmse: 0.875525\tvalid_1's rmse: 0.90613\n",
      "[800]\ttraining's rmse: 0.589402\tvalid_1's rmse: 0.577619\n",
      "[1000]\ttraining's rmse: 0.430991\tvalid_1's rmse: 0.393658\n",
      "[1200]\ttraining's rmse: 0.347517\tvalid_1's rmse: 0.296342\n",
      "[1400]\ttraining's rmse: 0.304165\tvalid_1's rmse: 0.248533\n",
      "[1600]\ttraining's rmse: 0.280256\tvalid_1's rmse: 0.225298\n",
      "[1800]\ttraining's rmse: 0.264973\tvalid_1's rmse: 0.212895\n",
      "[2000]\ttraining's rmse: 0.25271\tvalid_1's rmse: 0.204904\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.25271\tvalid_1's rmse: 0.204904\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 200, max_bins: 500, WRMSSE:0.03296689781720029\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 200, max_bins: 500, WRMSSE:0.03540687097390909\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "14\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.27997\tvalid_1's rmse: 2.17046\n",
      "[400]\ttraining's rmse: 1.47513\tvalid_1's rmse: 1.38818\n",
      "[600]\ttraining's rmse: 1.01526\tvalid_1's rmse: 0.938121\n",
      "[800]\ttraining's rmse: 0.766844\tvalid_1's rmse: 0.692994\n",
      "[1000]\ttraining's rmse: 0.641463\tvalid_1's rmse: 0.571181\n",
      "[1200]\ttraining's rmse: 0.581484\tvalid_1's rmse: 0.515281\n",
      "[1400]\ttraining's rmse: 0.551734\tvalid_1's rmse: 0.489983\n",
      "[1600]\ttraining's rmse: 0.535524\tvalid_1's rmse: 0.477882\n",
      "[1800]\ttraining's rmse: 0.523738\tvalid_1's rmse: 0.4713\n",
      "[2000]\ttraining's rmse: 0.514638\tvalid_1's rmse: 0.465861\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.514638\tvalid_1's rmse: 0.465861\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.79933\tvalid_1's rmse: 1.91389\n",
      "[400]\ttraining's rmse: 1.16079\tvalid_1's rmse: 1.20266\n",
      "[600]\ttraining's rmse: 0.791584\tvalid_1's rmse: 0.790394\n",
      "[800]\ttraining's rmse: 0.589562\tvalid_1's rmse: 0.566446\n",
      "[1000]\ttraining's rmse: 0.484719\tvalid_1's rmse: 0.455984\n",
      "[1200]\ttraining's rmse: 0.431867\tvalid_1's rmse: 0.406837\n",
      "[1400]\ttraining's rmse: 0.403671\tvalid_1's rmse: 0.385745\n",
      "[1600]\ttraining's rmse: 0.385316\tvalid_1's rmse: 0.376096\n",
      "[1800]\ttraining's rmse: 0.37359\tvalid_1's rmse: 0.370523\n",
      "[2000]\ttraining's rmse: 0.364847\tvalid_1's rmse: 0.366822\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.364847\tvalid_1's rmse: 0.366822\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.46076\tvalid_1's rmse: 3.11953\n",
      "[400]\ttraining's rmse: 2.28624\tvalid_1's rmse: 1.98635\n",
      "[600]\ttraining's rmse: 1.61413\tvalid_1's rmse: 1.35427\n",
      "[800]\ttraining's rmse: 1.2447\tvalid_1's rmse: 1.02866\n",
      "[1000]\ttraining's rmse: 1.05298\tvalid_1's rmse: 0.877581\n",
      "[1200]\ttraining's rmse: 0.954532\tvalid_1's rmse: 0.815581\n",
      "[1400]\ttraining's rmse: 0.903499\tvalid_1's rmse: 0.789826\n",
      "[1600]\ttraining's rmse: 0.873965\tvalid_1's rmse: 0.777748\n",
      "[1800]\ttraining's rmse: 0.854504\tvalid_1's rmse: 0.772221\n",
      "[2000]\ttraining's rmse: 0.838523\tvalid_1's rmse: 0.768659\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.838523\tvalid_1's rmse: 0.768659\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.2028\tvalid_1's rmse: 1.16225\n",
      "[400]\ttraining's rmse: 0.77116\tvalid_1's rmse: 0.725177\n",
      "[600]\ttraining's rmse: 0.520228\tvalid_1's rmse: 0.470101\n",
      "[800]\ttraining's rmse: 0.382529\tvalid_1's rmse: 0.331069\n",
      "[1000]\ttraining's rmse: 0.311518\tvalid_1's rmse: 0.262466\n",
      "[1200]\ttraining's rmse: 0.276039\tvalid_1's rmse: 0.232349\n",
      "[1400]\ttraining's rmse: 0.257838\tvalid_1's rmse: 0.220184\n",
      "[1600]\ttraining's rmse: 0.246105\tvalid_1's rmse: 0.214442\n",
      "[1800]\ttraining's rmse: 0.237938\tvalid_1's rmse: 0.211819\n",
      "[2000]\ttraining's rmse: 0.231578\tvalid_1's rmse: 0.210295\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.231578\tvalid_1's rmse: 0.210295\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.86566\tvalid_1's rmse: 1.89951\n",
      "[400]\ttraining's rmse: 1.20569\tvalid_1's rmse: 1.18789\n",
      "[600]\ttraining's rmse: 0.823387\tvalid_1's rmse: 0.768046\n",
      "[800]\ttraining's rmse: 0.61303\tvalid_1's rmse: 0.535909\n",
      "[1000]\ttraining's rmse: 0.504758\tvalid_1's rmse: 0.420171\n",
      "[1200]\ttraining's rmse: 0.451346\tvalid_1's rmse: 0.370011\n",
      "[1400]\ttraining's rmse: 0.424188\tvalid_1's rmse: 0.350647\n",
      "[1600]\ttraining's rmse: 0.407137\tvalid_1's rmse: 0.341712\n",
      "[1800]\ttraining's rmse: 0.394522\tvalid_1's rmse: 0.336864\n",
      "[2000]\ttraining's rmse: 0.384503\tvalid_1's rmse: 0.334612\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.384503\tvalid_1's rmse: 0.334612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.39943\tvalid_1's rmse: 2.1602\n",
      "[400]\ttraining's rmse: 1.57557\tvalid_1's rmse: 1.33676\n",
      "[600]\ttraining's rmse: 1.10815\tvalid_1's rmse: 0.86511\n",
      "[800]\ttraining's rmse: 0.861919\tvalid_1's rmse: 0.617725\n",
      "[1000]\ttraining's rmse: 0.740914\tvalid_1's rmse: 0.505948\n",
      "[1200]\ttraining's rmse: 0.682292\tvalid_1's rmse: 0.464403\n",
      "[1400]\ttraining's rmse: 0.652258\tvalid_1's rmse: 0.451554\n",
      "[1600]\ttraining's rmse: 0.631032\tvalid_1's rmse: 0.447437\n",
      "Early stopping, best iteration is:\n",
      "[1732]\ttraining's rmse: 0.620865\tvalid_1's rmse: 0.445986\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.28055\tvalid_1's rmse: 2.02419\n",
      "[400]\ttraining's rmse: 1.47938\tvalid_1's rmse: 1.2692\n",
      "[600]\ttraining's rmse: 1.02286\tvalid_1's rmse: 0.838474\n",
      "[800]\ttraining's rmse: 0.779049\tvalid_1's rmse: 0.609409\n",
      "[1000]\ttraining's rmse: 0.658631\tvalid_1's rmse: 0.501894\n",
      "[1200]\ttraining's rmse: 0.601053\tvalid_1's rmse: 0.456806\n",
      "[1400]\ttraining's rmse: 0.572574\tvalid_1's rmse: 0.439957\n",
      "[1600]\ttraining's rmse: 0.556766\tvalid_1's rmse: 0.432448\n",
      "[1800]\ttraining's rmse: 0.545673\tvalid_1's rmse: 0.428193\n",
      "[2000]\ttraining's rmse: 0.536761\tvalid_1's rmse: 0.425624\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.536761\tvalid_1's rmse: 0.425624\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.59855\tvalid_1's rmse: 1.55617\n",
      "[400]\ttraining's rmse: 1.01174\tvalid_1's rmse: 0.967711\n",
      "[600]\ttraining's rmse: 0.666183\tvalid_1's rmse: 0.620065\n",
      "[800]\ttraining's rmse: 0.470543\tvalid_1's rmse: 0.420755\n",
      "[1000]\ttraining's rmse: 0.366976\tvalid_1's rmse: 0.316887\n",
      "[1200]\ttraining's rmse: 0.315331\tvalid_1's rmse: 0.269095\n",
      "[1400]\ttraining's rmse: 0.290146\tvalid_1's rmse: 0.248964\n",
      "[1600]\ttraining's rmse: 0.277207\tvalid_1's rmse: 0.240741\n",
      "[1800]\ttraining's rmse: 0.269486\tvalid_1's rmse: 0.236595\n",
      "[2000]\ttraining's rmse: 0.264082\tvalid_1's rmse: 0.233614\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.264082\tvalid_1's rmse: 0.233614\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.58069\tvalid_1's rmse: 3.06618\n",
      "[400]\ttraining's rmse: 1.66414\tvalid_1's rmse: 1.93584\n",
      "[600]\ttraining's rmse: 1.1336\tvalid_1's rmse: 1.2874\n",
      "[800]\ttraining's rmse: 0.839377\tvalid_1's rmse: 0.951323\n",
      "[1000]\ttraining's rmse: 0.684173\tvalid_1's rmse: 0.798252\n",
      "[1200]\ttraining's rmse: 0.603103\tvalid_1's rmse: 0.739441\n",
      "[1400]\ttraining's rmse: 0.560044\tvalid_1's rmse: 0.717198\n",
      "[1600]\ttraining's rmse: 0.534777\tvalid_1's rmse: 0.707828\n",
      "[1800]\ttraining's rmse: 0.517006\tvalid_1's rmse: 0.70315\n",
      "[2000]\ttraining's rmse: 0.503072\tvalid_1's rmse: 0.697573\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.503072\tvalid_1's rmse: 0.697573\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 100\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.20534\tvalid_1's rmse: 2.37998\n",
      "[400]\ttraining's rmse: 1.43504\tvalid_1's rmse: 1.50698\n",
      "[600]\ttraining's rmse: 0.994609\tvalid_1's rmse: 1.00324\n",
      "[800]\ttraining's rmse: 0.758043\tvalid_1's rmse: 0.734397\n",
      "[1000]\ttraining's rmse: 0.640403\tvalid_1's rmse: 0.607013\n",
      "[1200]\ttraining's rmse: 0.58446\tvalid_1's rmse: 0.553836\n",
      "[1400]\ttraining's rmse: 0.556795\tvalid_1's rmse: 0.532449\n",
      "[1600]\ttraining's rmse: 0.540744\tvalid_1's rmse: 0.522848\n",
      "[1800]\ttraining's rmse: 0.528912\tvalid_1's rmse: 0.518933\n",
      "Early stopping, best iteration is:\n",
      "[1782]\ttraining's rmse: 0.529918\tvalid_1's rmse: 0.518919\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 300, max_bins: 100, WRMSSE:0.06276831983182378\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 300, max_bins: 100, WRMSSE:0.06679145250247306\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "15\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.27072\tvalid_1's rmse: 2.16753\n",
      "[400]\ttraining's rmse: 1.45375\tvalid_1's rmse: 1.38146\n",
      "[600]\ttraining's rmse: 0.979861\tvalid_1's rmse: 0.923711\n",
      "[800]\ttraining's rmse: 0.718249\tvalid_1's rmse: 0.668202\n",
      "[1000]\ttraining's rmse: 0.582755\tvalid_1's rmse: 0.535153\n",
      "[1200]\ttraining's rmse: 0.51714\tvalid_1's rmse: 0.47034\n",
      "[1400]\ttraining's rmse: 0.484736\tvalid_1's rmse: 0.43856\n",
      "[1600]\ttraining's rmse: 0.467326\tvalid_1's rmse: 0.422027\n",
      "[1800]\ttraining's rmse: 0.455836\tvalid_1's rmse: 0.412192\n",
      "[2000]\ttraining's rmse: 0.447026\tvalid_1's rmse: 0.405663\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.447026\tvalid_1's rmse: 0.405663\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.79102\tvalid_1's rmse: 1.90427\n",
      "[400]\ttraining's rmse: 1.1454\tvalid_1's rmse: 1.18165\n",
      "[600]\ttraining's rmse: 0.768463\tvalid_1's rmse: 0.754962\n",
      "[800]\ttraining's rmse: 0.558354\tvalid_1's rmse: 0.51431\n",
      "[1000]\ttraining's rmse: 0.446779\tvalid_1's rmse: 0.389613\n",
      "[1200]\ttraining's rmse: 0.389203\tvalid_1's rmse: 0.332799\n",
      "[1400]\ttraining's rmse: 0.358647\tvalid_1's rmse: 0.309719\n",
      "[1600]\ttraining's rmse: 0.338598\tvalid_1's rmse: 0.301471\n",
      "[1800]\ttraining's rmse: 0.325758\tvalid_1's rmse: 0.298102\n",
      "[2000]\ttraining's rmse: 0.31612\tvalid_1's rmse: 0.295675\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.31612\tvalid_1's rmse: 0.295675\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.44741\tvalid_1's rmse: 3.08771\n",
      "[400]\ttraining's rmse: 2.25394\tvalid_1's rmse: 1.93155\n",
      "[600]\ttraining's rmse: 1.56175\tvalid_1's rmse: 1.27724\n",
      "[800]\ttraining's rmse: 1.17524\tvalid_1's rmse: 0.93807\n",
      "[1000]\ttraining's rmse: 0.969949\tvalid_1's rmse: 0.780047\n",
      "[1200]\ttraining's rmse: 0.864583\tvalid_1's rmse: 0.716472\n",
      "[1400]\ttraining's rmse: 0.809058\tvalid_1's rmse: 0.692284\n",
      "[1600]\ttraining's rmse: 0.778267\tvalid_1's rmse: 0.682114\n",
      "[1800]\ttraining's rmse: 0.758467\tvalid_1's rmse: 0.677042\n",
      "[2000]\ttraining's rmse: 0.742816\tvalid_1's rmse: 0.673497\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.742816\tvalid_1's rmse: 0.673497\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.20248\tvalid_1's rmse: 1.16006\n",
      "[400]\ttraining's rmse: 0.766703\tvalid_1's rmse: 0.720666\n",
      "[600]\ttraining's rmse: 0.510356\tvalid_1's rmse: 0.460246\n",
      "[800]\ttraining's rmse: 0.367542\tvalid_1's rmse: 0.312406\n",
      "[1000]\ttraining's rmse: 0.292535\tvalid_1's rmse: 0.233454\n",
      "[1200]\ttraining's rmse: 0.254564\tvalid_1's rmse: 0.194154\n",
      "[1400]\ttraining's rmse: 0.235185\tvalid_1's rmse: 0.17595\n",
      "[1600]\ttraining's rmse: 0.222437\tvalid_1's rmse: 0.166703\n",
      "[1800]\ttraining's rmse: 0.212998\tvalid_1's rmse: 0.161289\n",
      "[2000]\ttraining's rmse: 0.205759\tvalid_1's rmse: 0.158114\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.205759\tvalid_1's rmse: 0.158114\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.85821\tvalid_1's rmse: 1.88923\n",
      "[400]\ttraining's rmse: 1.18862\tvalid_1's rmse: 1.16688\n",
      "[600]\ttraining's rmse: 0.796931\tvalid_1's rmse: 0.737059\n",
      "[800]\ttraining's rmse: 0.577259\tvalid_1's rmse: 0.494205\n",
      "[1000]\ttraining's rmse: 0.461019\tvalid_1's rmse: 0.369612\n",
      "[1200]\ttraining's rmse: 0.402737\tvalid_1's rmse: 0.312929\n",
      "[1400]\ttraining's rmse: 0.373135\tvalid_1's rmse: 0.290012\n",
      "[1600]\ttraining's rmse: 0.354838\tvalid_1's rmse: 0.278745\n",
      "[1800]\ttraining's rmse: 0.341175\tvalid_1's rmse: 0.271154\n",
      "[2000]\ttraining's rmse: 0.330624\tvalid_1's rmse: 0.266829\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.330624\tvalid_1's rmse: 0.266829\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.38483\tvalid_1's rmse: 2.16428\n",
      "[400]\ttraining's rmse: 1.54434\tvalid_1's rmse: 1.33711\n",
      "[600]\ttraining's rmse: 1.06008\tvalid_1's rmse: 0.851887\n",
      "[800]\ttraining's rmse: 0.798633\tvalid_1's rmse: 0.582315\n",
      "[1000]\ttraining's rmse: 0.667011\tvalid_1's rmse: 0.445332\n",
      "[1200]\ttraining's rmse: 0.60215\tvalid_1's rmse: 0.38254\n",
      "[1400]\ttraining's rmse: 0.569049\tvalid_1's rmse: 0.356342\n",
      "[1600]\ttraining's rmse: 0.54725\tvalid_1's rmse: 0.344899\n",
      "[1800]\ttraining's rmse: 0.531491\tvalid_1's rmse: 0.340466\n",
      "[2000]\ttraining's rmse: 0.518897\tvalid_1's rmse: 0.33843\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.518897\tvalid_1's rmse: 0.33843\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.26563\tvalid_1's rmse: 2.04347\n",
      "[400]\ttraining's rmse: 1.44643\tvalid_1's rmse: 1.28947\n",
      "[600]\ttraining's rmse: 0.970255\tvalid_1's rmse: 0.847785\n",
      "[800]\ttraining's rmse: 0.707568\tvalid_1's rmse: 0.601874\n",
      "[1000]\ttraining's rmse: 0.573292\tvalid_1's rmse: 0.47568\n",
      "[1200]\ttraining's rmse: 0.507757\tvalid_1's rmse: 0.416593\n",
      "[1400]\ttraining's rmse: 0.475176\tvalid_1's rmse: 0.389919\n",
      "[1600]\ttraining's rmse: 0.457395\tvalid_1's rmse: 0.377058\n",
      "[1800]\ttraining's rmse: 0.445432\tvalid_1's rmse: 0.369943\n",
      "[2000]\ttraining's rmse: 0.435741\tvalid_1's rmse: 0.365223\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.435741\tvalid_1's rmse: 0.365223\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.59398\tvalid_1's rmse: 1.55859\n",
      "[400]\ttraining's rmse: 1.00212\tvalid_1's rmse: 0.970026\n",
      "[600]\ttraining's rmse: 0.650826\tvalid_1's rmse: 0.619641\n",
      "[800]\ttraining's rmse: 0.448156\tvalid_1's rmse: 0.414587\n",
      "[1000]\ttraining's rmse: 0.338192\tvalid_1's rmse: 0.302797\n",
      "[1200]\ttraining's rmse: 0.282266\tvalid_1's rmse: 0.247714\n",
      "[1400]\ttraining's rmse: 0.254338\tvalid_1's rmse: 0.222658\n",
      "[1600]\ttraining's rmse: 0.239974\tvalid_1's rmse: 0.211043\n",
      "[1800]\ttraining's rmse: 0.231156\tvalid_1's rmse: 0.204791\n",
      "[2000]\ttraining's rmse: 0.224813\tvalid_1's rmse: 0.200218\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.224813\tvalid_1's rmse: 0.200218\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.57543\tvalid_1's rmse: 3.09795\n",
      "[400]\ttraining's rmse: 1.65053\tvalid_1's rmse: 1.97177\n",
      "[600]\ttraining's rmse: 1.10979\tvalid_1's rmse: 1.30294\n",
      "[800]\ttraining's rmse: 0.804971\tvalid_1's rmse: 0.923497\n",
      "[1000]\ttraining's rmse: 0.6387\tvalid_1's rmse: 0.720632\n",
      "[1200]\ttraining's rmse: 0.550152\tvalid_1's rmse: 0.618798\n",
      "[1400]\ttraining's rmse: 0.502136\tvalid_1's rmse: 0.5671\n",
      "[1600]\ttraining's rmse: 0.473787\tvalid_1's rmse: 0.539927\n",
      "[1800]\ttraining's rmse: 0.453712\tvalid_1's rmse: 0.522034\n",
      "[2000]\ttraining's rmse: 0.437817\tvalid_1's rmse: 0.507109\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.437817\tvalid_1's rmse: 0.507109\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 150\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.1923\tvalid_1's rmse: 2.3826\n",
      "[400]\ttraining's rmse: 1.4073\tvalid_1's rmse: 1.5079\n",
      "[600]\ttraining's rmse: 0.952917\tvalid_1's rmse: 0.995076\n",
      "[800]\ttraining's rmse: 0.702806\tvalid_1's rmse: 0.710033\n",
      "[1000]\ttraining's rmse: 0.575803\tvalid_1's rmse: 0.564142\n",
      "[1200]\ttraining's rmse: 0.514386\tvalid_1's rmse: 0.495539\n",
      "[1400]\ttraining's rmse: 0.4838\tvalid_1's rmse: 0.465078\n",
      "[1600]\ttraining's rmse: 0.466921\tvalid_1's rmse: 0.449934\n",
      "[1800]\ttraining's rmse: 0.454639\tvalid_1's rmse: 0.442463\n",
      "[2000]\ttraining's rmse: 0.444657\tvalid_1's rmse: 0.439542\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.444657\tvalid_1's rmse: 0.439542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 300, max_bins: 150, WRMSSE:0.050949670400875856\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 300, max_bins: 150, WRMSSE:0.05402997097639289\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "16\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.26659\tvalid_1's rmse: 2.16073\n",
      "[400]\ttraining's rmse: 1.44283\tvalid_1's rmse: 1.36868\n",
      "[600]\ttraining's rmse: 0.959048\tvalid_1's rmse: 0.905779\n",
      "[800]\ttraining's rmse: 0.686176\tvalid_1's rmse: 0.64737\n",
      "[1000]\ttraining's rmse: 0.541792\tvalid_1's rmse: 0.514492\n",
      "[1200]\ttraining's rmse: 0.469824\tvalid_1's rmse: 0.451009\n",
      "[1400]\ttraining's rmse: 0.433387\tvalid_1's rmse: 0.420934\n",
      "[1600]\ttraining's rmse: 0.414081\tvalid_1's rmse: 0.406127\n",
      "[1800]\ttraining's rmse: 0.402054\tvalid_1's rmse: 0.397791\n",
      "[2000]\ttraining's rmse: 0.392863\tvalid_1's rmse: 0.392379\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.392863\tvalid_1's rmse: 0.392379\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 2: CA_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.78662\tvalid_1's rmse: 1.90528\n",
      "[400]\ttraining's rmse: 1.1344\tvalid_1's rmse: 1.17951\n",
      "[600]\ttraining's rmse: 0.750642\tvalid_1's rmse: 0.746442\n",
      "[800]\ttraining's rmse: 0.53322\tvalid_1's rmse: 0.496296\n",
      "[1000]\ttraining's rmse: 0.415364\tvalid_1's rmse: 0.362154\n",
      "[1200]\ttraining's rmse: 0.354762\tvalid_1's rmse: 0.299622\n",
      "[1400]\ttraining's rmse: 0.321951\tvalid_1's rmse: 0.273476\n",
      "[1600]\ttraining's rmse: 0.300112\tvalid_1's rmse: 0.262865\n",
      "[1800]\ttraining's rmse: 0.286219\tvalid_1's rmse: 0.259011\n",
      "[2000]\ttraining's rmse: 0.276027\tvalid_1's rmse: 0.256972\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.276027\tvalid_1's rmse: 0.256972\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 3: CA_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 3.43946\tvalid_1's rmse: 3.09595\n",
      "[400]\ttraining's rmse: 2.23652\tvalid_1's rmse: 1.93554\n",
      "[600]\ttraining's rmse: 1.5334\tvalid_1's rmse: 1.26923\n",
      "[800]\ttraining's rmse: 1.13481\tvalid_1's rmse: 0.912824\n",
      "[1000]\ttraining's rmse: 0.920634\tvalid_1's rmse: 0.736298\n",
      "[1200]\ttraining's rmse: 0.808628\tvalid_1's rmse: 0.656858\n",
      "[1400]\ttraining's rmse: 0.748977\tvalid_1's rmse: 0.622866\n",
      "[1600]\ttraining's rmse: 0.715549\tvalid_1's rmse: 0.607848\n",
      "[1800]\ttraining's rmse: 0.694903\tvalid_1's rmse: 0.599611\n",
      "[2000]\ttraining's rmse: 0.679552\tvalid_1's rmse: 0.594662\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.679552\tvalid_1's rmse: 0.594662\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 4: CA_4, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.20009\tvalid_1's rmse: 1.16072\n",
      "[400]\ttraining's rmse: 0.761843\tvalid_1's rmse: 0.720271\n",
      "[600]\ttraining's rmse: 0.503876\tvalid_1's rmse: 0.457951\n",
      "[800]\ttraining's rmse: 0.357676\tvalid_1's rmse: 0.306508\n",
      "[1000]\ttraining's rmse: 0.279399\tvalid_1's rmse: 0.224454\n",
      "[1200]\ttraining's rmse: 0.239111\tvalid_1's rmse: 0.1834\n",
      "[1400]\ttraining's rmse: 0.218297\tvalid_1's rmse: 0.164439\n",
      "[1600]\ttraining's rmse: 0.204397\tvalid_1's rmse: 0.154417\n",
      "[1800]\ttraining's rmse: 0.194422\tvalid_1's rmse: 0.14866\n",
      "[2000]\ttraining's rmse: 0.187014\tvalid_1's rmse: 0.145284\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.187014\tvalid_1's rmse: 0.145284\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 5: TX_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.85417\tvalid_1's rmse: 1.89192\n",
      "[400]\ttraining's rmse: 1.17823\tvalid_1's rmse: 1.16863\n",
      "[600]\ttraining's rmse: 0.779121\tvalid_1's rmse: 0.733832\n",
      "[800]\ttraining's rmse: 0.550642\tvalid_1's rmse: 0.481724\n",
      "[1000]\ttraining's rmse: 0.427789\tvalid_1's rmse: 0.344829\n",
      "[1200]\ttraining's rmse: 0.365059\tvalid_1's rmse: 0.277042\n",
      "[1400]\ttraining's rmse: 0.333102\tvalid_1's rmse: 0.247059\n",
      "[1600]\ttraining's rmse: 0.314727\tvalid_1's rmse: 0.232695\n",
      "[1800]\ttraining's rmse: 0.300533\tvalid_1's rmse: 0.221463\n",
      "[2000]\ttraining's rmse: 0.28954\tvalid_1's rmse: 0.215285\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.28954\tvalid_1's rmse: 0.215285\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 6: TX_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.37433\tvalid_1's rmse: 2.17191\n",
      "[400]\ttraining's rmse: 1.52327\tvalid_1's rmse: 1.34129\n",
      "[600]\ttraining's rmse: 1.02764\tvalid_1's rmse: 0.846473\n",
      "[800]\ttraining's rmse: 0.755012\tvalid_1's rmse: 0.562885\n",
      "[1000]\ttraining's rmse: 0.615009\tvalid_1's rmse: 0.410308\n",
      "[1200]\ttraining's rmse: 0.544956\tvalid_1's rmse: 0.33568\n",
      "[1400]\ttraining's rmse: 0.509258\tvalid_1's rmse: 0.302934\n",
      "[1600]\ttraining's rmse: 0.486426\tvalid_1's rmse: 0.287987\n",
      "[1800]\ttraining's rmse: 0.469134\tvalid_1's rmse: 0.280222\n",
      "[2000]\ttraining's rmse: 0.456031\tvalid_1's rmse: 0.276483\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.456031\tvalid_1's rmse: 0.276483\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 7: TX_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.26433\tvalid_1's rmse: 2.02165\n",
      "[400]\ttraining's rmse: 1.43804\tvalid_1's rmse: 1.26019\n",
      "[600]\ttraining's rmse: 0.948189\tvalid_1's rmse: 0.815905\n",
      "[800]\ttraining's rmse: 0.672284\tvalid_1's rmse: 0.567579\n",
      "[1000]\ttraining's rmse: 0.527745\tvalid_1's rmse: 0.439832\n",
      "[1200]\ttraining's rmse: 0.455674\tvalid_1's rmse: 0.379662\n",
      "[1400]\ttraining's rmse: 0.419776\tvalid_1's rmse: 0.353568\n",
      "[1600]\ttraining's rmse: 0.400462\tvalid_1's rmse: 0.341458\n",
      "[1800]\ttraining's rmse: 0.387267\tvalid_1's rmse: 0.334515\n",
      "[2000]\ttraining's rmse: 0.377245\tvalid_1's rmse: 0.329982\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.377245\tvalid_1's rmse: 0.329982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 8: WI_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 1.59269\tvalid_1's rmse: 1.55826\n",
      "[400]\ttraining's rmse: 0.997778\tvalid_1's rmse: 0.969712\n",
      "[600]\ttraining's rmse: 0.643719\tvalid_1's rmse: 0.616476\n",
      "[800]\ttraining's rmse: 0.438079\tvalid_1's rmse: 0.406384\n",
      "[1000]\ttraining's rmse: 0.325016\tvalid_1's rmse: 0.287409\n",
      "[1200]\ttraining's rmse: 0.266739\tvalid_1's rmse: 0.225204\n",
      "[1400]\ttraining's rmse: 0.237432\tvalid_1's rmse: 0.194427\n",
      "[1600]\ttraining's rmse: 0.222198\tvalid_1's rmse: 0.178904\n",
      "[1800]\ttraining's rmse: 0.21325\tvalid_1's rmse: 0.170282\n",
      "[2000]\ttraining's rmse: 0.206674\tvalid_1's rmse: 0.164481\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.206674\tvalid_1's rmse: 0.164481\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 9: WI_2, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.57458\tvalid_1's rmse: 3.09463\n",
      "[400]\ttraining's rmse: 1.64684\tvalid_1's rmse: 1.9642\n",
      "[600]\ttraining's rmse: 1.10404\tvalid_1's rmse: 1.29196\n",
      "[800]\ttraining's rmse: 0.795489\tvalid_1's rmse: 0.904073\n",
      "[1000]\ttraining's rmse: 0.624824\tvalid_1's rmse: 0.695633\n",
      "[1200]\ttraining's rmse: 0.532773\tvalid_1's rmse: 0.589101\n",
      "[1400]\ttraining's rmse: 0.482233\tvalid_1's rmse: 0.534381\n",
      "[1600]\ttraining's rmse: 0.451926\tvalid_1's rmse: 0.504386\n",
      "[1800]\ttraining's rmse: 0.430044\tvalid_1's rmse: 0.485104\n",
      "[2000]\ttraining's rmse: 0.413457\tvalid_1's rmse: 0.470384\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.413457\tvalid_1's rmse: 0.470384\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 10: WI_3, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 200\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.18559\tvalid_1's rmse: 2.37964\n",
      "[400]\ttraining's rmse: 1.39111\tvalid_1's rmse: 1.49665\n",
      "[600]\ttraining's rmse: 0.927236\tvalid_1's rmse: 0.971939\n",
      "[800]\ttraining's rmse: 0.666818\tvalid_1's rmse: 0.670801\n",
      "[1000]\ttraining's rmse: 0.531041\tvalid_1's rmse: 0.510043\n",
      "[1200]\ttraining's rmse: 0.464422\tvalid_1's rmse: 0.432097\n",
      "[1400]\ttraining's rmse: 0.431499\tvalid_1's rmse: 0.395614\n",
      "[1600]\ttraining's rmse: 0.413715\tvalid_1's rmse: 0.378643\n",
      "[1800]\ttraining's rmse: 0.401801\tvalid_1's rmse: 0.370191\n",
      "[2000]\ttraining's rmse: 0.391961\tvalid_1's rmse: 0.366859\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.391961\tvalid_1's rmse: 0.366859\n",
      "calculating WRMSSE\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "for validation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 300, max_bins: 200, WRMSSE:0.04459577908263117\n",
      "for evaluation= \n",
      " eta: 0.005, num_iterations: <built-in function iter>, num_leaves: 100, min_data_in_leaf: 300, max_bins: 200, WRMSSE:0.04806374730875084\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "-+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-\n",
      "\n",
      "\n",
      "17\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "store 1: CA_1, eta: 0.005, num_iterations: 2000, max_depth: -1, num_leaves: 100, min_data_in_leaf: 300, max_bins: 250\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[200]\ttraining's rmse: 2.26621\tvalid_1's rmse: 2.16041\n"
     ]
    }
   ],
   "source": [
    "models=[] #will store models for all iterations\n",
    "predicted_values_validation_grid=[]\n",
    "inde= 0\n",
    "\n",
    "for eta in learning_rate:\n",
    "    for iterations in num_iterations:\n",
    "        for depth in max_depth:\n",
    "            for leaves in num_leaves:\n",
    "                for min_data in min_data_in_leaf:\n",
    "                    for bins in max_bins:\n",
    "                        \n",
    "                        print(inde)\n",
    "                        inde+=1\n",
    "                        \n",
    "                        mod=[] #will store models for this iteration\n",
    "                        validation_prediction= pd.DataFrame(columns= ['id']+ f_cols)\n",
    "                        test_prediction= pd.DataFrame(columns= ['id']+ f_cols)\n",
    "\n",
    "                        params={\n",
    "                              'objective':'poisson', #tweedie\n",
    "                              'metric':'rmse',\n",
    "                              'force_row_wise':True,\n",
    "                              'learning_rate': eta,\n",
    "                              'max_bin': bins,\n",
    "                              'verbosity': -1,  #with this it stops giving warnings\n",
    "                              'num_iterations':iterations, \n",
    "                              'num_leaves': leaves, \n",
    "                              'min_data_in_leaf': min_data,\n",
    "                              'max_depth': depth,\n",
    "                              'n_jobs': -1\n",
    "                            }\n",
    "                            \n",
    "                        for store in list(df_df.store_id.unique()):\n",
    "\n",
    "                            print(\"-\"*110)\n",
    "                            print(f\"store {store + 1}: {store_dict[store]}, eta: {eta}, num_iterations: {iterations}, max_depth: {depth}, num_leaves: {leaves}, min_data_in_leaf: {min_data}, max_bins: {bins}\")\n",
    "                            print(\"-\"*110)\n",
    "\n",
    "                            data= df_df[df_df['store_id']== store] #getting data by store\n",
    "\n",
    "                            #creating train and test datasets\n",
    "                            train= data[data['d'] <= 1885].drop(['id','d'], axis= 1)\n",
    "                            valid= data[(data['d'] >1885) & (data['d']<1914)].drop('d', axis= 1)\n",
    "                            test= data[(data['d']>= 1914) & (data['d'] <= 1941)].drop('d', axis= 1)\n",
    "\n",
    "                            #getting the ids of valid and test datasets so as to sort them afterwords\n",
    "                            valid_id= list(valid['id'].values)\n",
    "                            test_id= list(test['id'].values)\n",
    "\n",
    "                            #dropping id now \n",
    "                            valid.drop('id', axis= 1, inplace= True)\n",
    "                            test.drop('id', axis= 1, inplace= True)\n",
    "\n",
    "                            X_train, y_train= train.drop('sales', axis= 1), train['sales']\n",
    "                            X_valid, y_valid= valid.drop('sales', axis= 1), valid['sales']\n",
    "                            X_test, y_test= test.drop('sales', axis= 1), test['sales']\n",
    "                    #         X_eval, y_eval= evaluation.drop('sales', axis= 1), evaluation['sales']\n",
    "\n",
    "\n",
    "                            # Defining categorical features\n",
    "                            categories = ['item_id', 'dept_id','store_id', 'cat_id', 'state_id'] + \\\n",
    "                                       [\"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\"]\n",
    "\n",
    "                            trainData = lgb.Dataset(X_train, label = y_train, categorical_feature = categories, free_raw_data = False)\n",
    "                            validData = lgb.Dataset(X_valid, label = y_valid, categorical_feature = categories, free_raw_data = False)\n",
    "\n",
    "                            #training model\n",
    "                            model = lgb.train(params, trainData, valid_sets = [trainData, validData], verbose_eval = 200, early_stopping_rounds=20)\n",
    "                            mod.append(model) #appending model\n",
    "\n",
    "                            #predicting validation and test data\n",
    "                            valid_predict= model.predict(X_valid).reshape(-1,28)\n",
    "                            valid_predict= pd.DataFrame(valid_predict, columns= f_cols)\n",
    "                            valid_predict['id']= valid_id[::28] #adding ids\n",
    "                            cols= ['id'] + f_cols\n",
    "                            valid_predict= valid_predict[cols]\n",
    "\n",
    "                            #concatinating it with larger dataset for computing WRMSSE\n",
    "                            validation_prediction= pd.concat([validation_prediction, valid_predict]) \n",
    "\n",
    "\n",
    "                            test_predict= model.predict(X_test).reshape(-1,28)\n",
    "                            test_predict= pd.DataFrame(test_predict, columns= f_cols)\n",
    "                            test_predict['id']= test_id[::28] #adding ids\n",
    "                            cols= ['id'] + f_cols\n",
    "                            test_predict= test_predict[cols]\n",
    "\n",
    "                            #concatinating it with larger dataset for computing WRMSSE\n",
    "                            test_prediction= pd.concat([test_prediction, test_predict]) \n",
    "\n",
    "                        models.append(mod)#appending all models in this iteration\n",
    "\n",
    "                        #sorting them by ids \n",
    "                    #     validation_prediction= validation_prediction.sort_values(by= 'id')\n",
    "                        validation_prediction['id']= validation_prediction['id'].apply(lambda x: id_dict[x])\n",
    "\n",
    "                    #     test_prediction= test_prediction.sort_values(by= 'id')\n",
    "                        test_prediction['id']= test_prediction['id'].apply(lambda x: id_dict[x])\n",
    "                        \n",
    "                        test_prediction= uid_df.merge(test_prediction, on= 'id', how= 'left')\n",
    "    \n",
    "                        predicted_values_validation_grid.append(test_prediction)\n",
    "\n",
    "                        print('calculating WRMSSE')\n",
    "                        #calculating validation and evaluation wrmsse\n",
    "                        valid_wrmsse= wrmsse(sales, validation_prediction, True)\n",
    "\n",
    "                        eval_wrmsse= wrmsse(sales, test_prediction, False)\n",
    "\n",
    "                        print('\\n')\n",
    "                        print(\"#\"*100)\n",
    "                        print(f\"for validation= \\n eta: {eta}, num_iterations: {iter}, num_leaves: {leaves}, min_data_in_leaf: {min_data}, max_bins: {bins}, WRMSSE:{valid_wrmsse}\")\n",
    "                        print(f\"for evaluation= \\n eta: {eta}, num_iterations: {iter}, num_leaves: {leaves}, min_data_in_leaf: {min_data}, max_bins: {bins}, WRMSSE:{eval_wrmsse}\")\n",
    "                        print(\"#\"*100)\n",
    "                        print('\\n')\n",
    "                        print(\"-+-\"*35)\n",
    "                        print(\"-+-\"*35)\n",
    "                        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we are building different models for each store.\n",
    "- From above hyperparams tuning we can see that the best values for validation and test datasets are around 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "M5 lightGBM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
